{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7744187e-9a74-440b-95b8-557b723fc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import fastai \n",
    "from torchvision.transforms import ToTensor\n",
    "# from fastai.data.core import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.vision.all import Learner, Metric\n",
    "from fastai import optimizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5849ab-a4ca-4515-97b5-35c90615be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c4d276-b524-46c7-b31a-8324a4b2b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([256, 1, 28, 28])\n",
      "Shape of y: torch.Size([256]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b180ad30-e4fe-4af6-9367-d3e5b03bc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af6c2a9-8714-4c3f-bf16-44b3b964ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 5\n",
    "train_size = len(training_data)\n",
    "# indices = list(range(train_size))\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED)\n",
    "indices = torch.randperm(train_size).tolist()\n",
    "\n",
    "subset_size = train_size // num_clients\n",
    "client_subsets = [] \n",
    "for i in range(num_clients):\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = start_idx + subset_size\n",
    "\n",
    "    if i == num_clients - 1:\n",
    "        end_idx = train_size\n",
    "\n",
    "    subset_indices = indices[start_idx:end_idx]\n",
    "    client_subsets.append(Subset(training_data, subset_indices))\n",
    "\n",
    "client_loaders = [DataLoader(sub, batch_size=batch_size, shuffle=True) for sub in client_subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "831d6af4-3ad3-4d67-8681-472ba8624385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits \n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "original_shapes = []\n",
    "for p in model.parameters():\n",
    "    original_shapes.append(p.shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1ab18bf1-90d6-4bde-a5fc-3ebb2766e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have 5 different datasets, each with some sort of representation of the data that is unknown, ie, we have no \n",
    "# statistical information on the data that each of these clients would have\n",
    "# We now need to implement variations of the 3 protocols, namely, the encoding protocol, the communication protocol and the decoding protocol\n",
    "\n",
    "# For communication protocol for fixed size encoder, we set the seed. So the seed is communicated with the values. \n",
    "SEED = 41\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Encoders\n",
    "def variable_size_encoder(grad_vectors, mu, p=0.1):\n",
    "    # Lets take p = 0.1\n",
    "    new_grad_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(grad_vectors)):\n",
    "            mask = torch.rand_like(grad_vectors[i], device=grad_vectors[i].device) < p\n",
    "            Y = torch.empty_like(grad_vectors[i], device=grad_vectors[i].device)\n",
    "            Y[mask] = (grad_vectors[i][mask] - mu[i] * (1-p))/p\n",
    "            Y[~mask] = mu[i]\n",
    "            new_grad_vectors.append(Y)\n",
    "    return new_grad_vectors\n",
    "\n",
    "def fixed_size_encoder(grad_vectors, mu, k=1000):\n",
    "    # k can vary\n",
    "    orig = k\n",
    "    torch.manual_seed(SEED) \n",
    "    new_grad_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(grad_vectors)):\n",
    "            k = orig\n",
    "            shape = grad_vectors[i].shape\n",
    "            # Flattening the parameters to permutate over them\n",
    "            flat_grad = grad_vectors[i].view(-1)\n",
    "            C = shape[-1]\n",
    "            # Get the length of the flat_grad array\n",
    "            d = flat_grad.numel()\n",
    "            k = min(k, d)\n",
    "            # print(k, d, C)\n",
    "            # Shuffle the list [1, 2, ... d] and get the first k elements\n",
    "            indices = torch.randperm(d, device=flat_grad.device)[:k]\n",
    "             \n",
    "            mask = torch.zeros(d, dtype=torch.bool, device=flat_grad.device)\n",
    "            mask[indices] = True\n",
    "            \n",
    "            Y = torch.empty_like(flat_grad)\n",
    "            # Encode the parameters\n",
    "            chosen_vals = (d/k)*flat_grad[mask] - ((d-k)/k)*mu[i]\n",
    "            Y[mask] = chosen_vals\n",
    "            Y[~mask] = mu[i]\n",
    "            Y = Y.view(shape)\n",
    "            new_grad_vectors.append(Y)\n",
    "    return new_grad_vectors\n",
    "            \n",
    "            \n",
    "# Decoders : I wont be making use of this later on\n",
    "def averaging_decoder(grad_vectors_list):\n",
    "    if isinstance(grad_vectors_list, list):\n",
    "        grad_vectors_list = torch.stack(grad_vectors_list, dim=0)\n",
    "    return torch.mean(grad_vectors_list, dim=0)\n",
    "\n",
    "# Communication protocols\n",
    "def sparse_for_variable_size_encoder(encoded_vectors, mu):\n",
    "    final_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(encoded_vectors)):\n",
    "            flat_vector = encoded_vectors[i].view(-1)\n",
    "            mask = flat_vector != mu[i]\n",
    "            # vals = encoded_vectors[i][mask]\n",
    "            indices = torch.nonzero(mask, as_tuple=False).view(-1)\n",
    "            values = flat_vector[mask]\n",
    "            final_vectors.append(list(zip(indices, values)))\n",
    "\n",
    "    \n",
    "    return final_vectors, mu\n",
    "    \n",
    "def sparse_for_fixed_size_encoder(encoded_vectors, mu):\n",
    "    final_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(encoded_vectors)):\n",
    "            flat_vector = encoded_vectors[i].view(-1)\n",
    "            mask = torch.zeros(len(flat_vector), dtype=torch.bool, device=flat_vector.device)\n",
    "            mask[flat_vector != mu[i]] = True\n",
    "            values = flat_vector[mask]\n",
    "            final_vectors.append(values)\n",
    "\n",
    "    return final_vectors, mu, SEED\n",
    "\n",
    "def rebuild_from_protocol_1(final_vectors, mu, original_shapes):\n",
    "    rebuilt_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i, vec_data in enumerate(final_vectors):\n",
    "            num_elements = 1\n",
    "            \n",
    "            for dim_size in original_shapes[i]:\n",
    "                num_elements *= dim_size\n",
    "    \n",
    "            \n",
    "            Y_flat = torch.full((num_elements,), mu[i], dtype=torch.float32, device=mu[i].device)\n",
    "    \n",
    "            indices = torch.tensor([pair[0] for pair in vec_data], dtype=torch.long, device=Y_flat.device)\n",
    "            values = torch.tensor([pair[1] for pair in vec_data], dtype=Y_flat.dtype, device=Y_flat.device)\n",
    "            Y_flat[indices] = values\n",
    "            Y = Y_flat.view(original_shapes[i])\n",
    "            rebuilt_vectors.append(Y)\n",
    "    return rebuilt_vectors\n",
    "\n",
    "def rebuild_from_protocol_2(final_vectors, mu, SEED, original_shapes):\n",
    "    rebuilt_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i, values in enumerate(final_vectors):\n",
    "            \n",
    "            num_elements = 1\n",
    "            for dim_size in original_shapes[i]:\n",
    "                num_elements *= dim_size\n",
    "    \n",
    "            torch.manual_seed(SEED)\n",
    "            k = len(values)  # number of chosen elements\n",
    "            d = num_elements\n",
    "            indices = torch.randperm(d, device=device)[:k]\n",
    "    \n",
    "            Y_flat = torch.full((num_elements,), float(mu[i]), dtype=torch.float32, device=mu[i].device)\n",
    "            Y_flat[indices] = values\n",
    "    \n",
    "            # Now we have Y, we must invert to get X\n",
    "            # mask for chosen elements: Y != mu[i]\n",
    "            chosen_mask = (Y_flat != mu[i])\n",
    "\n",
    "            # Apply X = (k/d)*Y + ((d-k)/d)*mu if chosen\n",
    "            X_flat = torch.empty_like(Y_flat)\n",
    "            X_flat[chosen_mask] = (k/d)*Y_flat[chosen_mask] + ((d-k)/d)*mu[i]\n",
    "            X_flat[~chosen_mask] = mu[i]\n",
    "            \n",
    "            X = X_flat.view(original_shapes[i])\n",
    "            rebuilt_vectors.append(X)\n",
    "    return rebuilt_vectors\n",
    "\n",
    "\n",
    "parameters = list(model.parameters())\n",
    "mu_1 = []\n",
    "with torch.no_grad():\n",
    "    for p in parameters:\n",
    "        mu_1.append(torch.mean(p))\n",
    "\n",
    "encoded_vectors = fixed_size_encoder(parameters, mu_1)\n",
    "final_vectors, mu, SEED = sparse_for_fixed_size_encoder(encoded_vectors, mu_1)\n",
    "rebuilt_vectors = rebuild_from_protocol_2(final_vectors, mu_1, SEED, original_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "42365a41-b414-4908-9ef4-f811d928fc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
       "         [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
       "         [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
       "         ...,\n",
       "         [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
       "         [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049],\n",
       "         [-0.0049, -0.0049, -0.0049,  ..., -0.0049, -0.0049, -0.0049]],\n",
       "        device='cuda:0'),\n",
       " tensor([-4.5572e-02, -4.6445e-04, -1.9688e-02, -5.2854e-03, -4.6341e-02,\n",
       "         -4.0416e-02, -1.3053e-03,  8.8912e-04, -4.5348e-02, -4.6200e-02,\n",
       "         -2.7820e-02, -2.3195e-02, -3.8668e-04, -3.0886e-02, -4.3926e-02,\n",
       "          4.9793e-04, -3.3293e-02, -7.5375e-02, -2.8687e-02, -3.1260e-02,\n",
       "         -3.6790e-02, -1.1273e-01, -4.8944e-03, -2.7433e-02, -3.5393e-02,\n",
       "         -1.5347e-02, -5.0623e-02,  1.2642e-02,  1.6567e-02, -8.0175e-02,\n",
       "         -3.8870e-02, -5.3798e-02, -1.4552e-02,  1.2231e-03, -5.8537e-03,\n",
       "         -2.6924e-02,  1.3301e-03,  4.5799e-03,  1.6032e-02, -1.3208e-01,\n",
       "          1.3640e-02, -4.0100e-02, -3.7288e-02, -6.1123e-02, -9.1748e-02,\n",
       "         -9.0792e-02, -3.2054e-03,  3.0358e-02, -5.2414e-02, -3.3629e-02,\n",
       "         -5.4024e-02, -1.2341e-01,  1.4287e-02, -2.2284e-02, -3.0880e-03,\n",
       "          7.6510e-05, -3.1094e-02, -5.8117e-03, -5.0244e-02, -1.0530e-01,\n",
       "          2.4757e-02,  4.0102e-03,  1.6263e-02,  6.3768e-03, -3.3356e-02,\n",
       "         -7.6008e-02, -7.0746e-02,  7.2308e-04, -1.0740e-02,  0.0000e+00,\n",
       "         -6.1212e-02, -1.1539e-02,  2.0655e-02, -4.4710e-02, -9.6872e-02,\n",
       "         -9.5817e-03, -3.3045e-02, -1.7416e-02,  1.8413e-02, -5.5355e-02,\n",
       "         -2.2965e-02, -8.5900e-02, -3.3983e-02, -3.7880e-02, -8.1039e-03,\n",
       "         -4.6089e-03, -7.5548e-03, -3.2987e-02, -1.3468e-01, -2.1653e-02,\n",
       "          2.9335e-02, -2.8769e-02, -5.9396e-05, -7.1919e-02, -2.5506e-02,\n",
       "         -2.9378e-02, -2.1139e-02, -5.1625e-02, -3.8221e-02, -4.8280e-03,\n",
       "         -1.8977e-01, -2.7205e-02, -1.0149e-01, -4.1017e-02,  2.0632e-02,\n",
       "          2.0009e-02, -1.1662e-02, -3.2331e-02, -1.0953e-02, -3.5304e-02,\n",
       "         -5.3827e-02, -8.2529e-02, -8.7785e-02, -3.8313e-03, -5.7501e-02,\n",
       "          1.9370e-04, -8.4109e-02, -4.7380e-02, -6.5306e-02, -2.8085e-02,\n",
       "         -1.0669e-01, -1.3131e-02, -8.5592e-02, -2.3784e-02, -8.3108e-02,\n",
       "         -8.9720e-02, -1.0625e-01, -1.0149e-01, -9.0909e-03,  1.7566e-02,\n",
       "          2.8281e-03,  1.2662e-02, -4.6847e-02, -1.0486e-03, -4.2866e-02,\n",
       "         -5.3470e-02, -1.0203e-01, -2.4909e-02, -7.9267e-02, -4.4112e-02,\n",
       "         -7.1773e-02, -7.6409e-02,  2.0865e-02, -3.3918e-02, -8.2367e-03,\n",
       "         -4.2448e-02, -7.4409e-02, -2.1381e-02,  2.4740e-03, -9.9448e-03,\n",
       "          9.2020e-03, -1.3470e-02, -5.8334e-02, -4.4515e-02, -2.9579e-02,\n",
       "         -1.9498e-02,  4.5145e-04, -6.2195e-02, -1.7456e-02, -2.4992e-02,\n",
       "          1.1567e-02, -3.7401e-02, -3.0260e-02,  1.2414e-02, -1.9596e-03,\n",
       "         -1.8757e-03, -8.5342e-02, -6.5557e-02,  1.1683e-02, -9.3255e-03,\n",
       "         -2.0906e-02, -2.2425e-03, -1.5278e-02,  5.6534e-03,  2.7092e-02,\n",
       "         -4.3651e-02, -2.8307e-02, -6.5891e-02, -9.7635e-02, -5.7912e-02,\n",
       "         -3.2253e-02, -5.0952e-02, -1.8852e-02, -5.6548e-02, -5.1170e-02,\n",
       "         -6.3181e-02,  1.5833e-02, -5.8258e-03, -3.7504e-02, -3.3750e-02,\n",
       "         -6.5502e-03, -3.8807e-02, -8.3313e-02, -3.3580e-02, -5.6181e-02,\n",
       "          4.4651e-03, -4.4784e-02, -1.1597e-02, -2.0023e-02,  1.7858e-02,\n",
       "         -1.9785e-03, -1.5178e-02, -2.2801e-02, -1.0723e-02, -5.0641e-02,\n",
       "         -8.8733e-02, -1.3201e-01,  6.1876e-03, -3.5450e-02, -1.7813e-02,\n",
       "         -3.7711e-02, -9.5482e-02, -3.3388e-02, -1.1074e-02, -7.5806e-02,\n",
       "         -4.6528e-02,  3.5227e-02, -3.7900e-02, -3.1209e-02, -5.1174e-03,\n",
       "         -6.8779e-02,  6.3555e-04, -2.8067e-02,  7.9260e-04,  1.5085e-02,\n",
       "         -1.3583e-03,  1.1688e-02, -1.8441e-02, -3.3954e-02, -4.4109e-02,\n",
       "         -2.5101e-02, -4.1839e-02,  1.0399e-02, -1.1213e-01,  8.2905e-04,\n",
       "         -5.1089e-02, -6.4600e-02, -4.4384e-02, -2.0716e-02, -2.9332e-02,\n",
       "          1.5550e-03, -1.6071e-02, -9.4512e-02,  2.7791e-02, -2.4350e-02,\n",
       "         -2.3783e-02, -2.0297e-02, -5.8971e-02,  2.3274e-02, -8.7108e-02,\n",
       "         -5.4547e-02, -3.6917e-02, -7.8051e-02, -1.9342e-02,  3.8096e-02,\n",
       "         -1.7582e-02, -3.9028e-03, -4.9082e-02, -1.8433e-01, -4.3337e-02,\n",
       "         -2.8912e-02,  1.2294e-02, -3.6284e-02, -1.1761e-02, -6.0094e-02,\n",
       "         -2.2100e-02, -1.1373e-01,  8.6883e-05, -3.7505e-02, -9.8167e-02,\n",
       "          5.8228e-03, -2.1875e-02, -1.3868e-02, -6.8844e-02, -1.4360e-02,\n",
       "         -2.7231e-02, -1.5121e-02, -6.3466e-02,  2.4067e-02, -2.7533e-02,\n",
       "          4.4141e-03,  5.0694e-02,  2.9169e-04, -2.5320e-02, -5.7873e-02,\n",
       "         -4.4612e-04, -1.7983e-02,  3.2311e-03, -7.4117e-02, -8.7057e-03,\n",
       "         -3.8713e-02, -1.0164e-01, -2.9478e-01,  5.7451e-02, -4.3533e-03,\n",
       "         -3.9488e-02, -3.0360e-02, -7.7666e-02, -3.0719e-02, -6.1238e-02,\n",
       "         -3.1034e-02,  6.7292e-03,  1.4015e-02, -1.0425e-01, -3.7270e-02,\n",
       "          6.4342e-03, -6.8597e-02, -1.5461e-02,  4.0145e-03, -3.1073e-02,\n",
       "         -6.5545e-03, -2.4744e-01, -3.7774e-03, -3.1334e-02,  1.7337e-02,\n",
       "         -6.4763e-02, -6.0825e-03, -4.7601e-02, -2.3606e-02, -5.1668e-02,\n",
       "         -7.9591e-02, -4.7503e-02, -4.7354e-02,  2.1448e-04, -4.6741e-02,\n",
       "         -5.3275e-02,  1.1936e-02, -2.7460e-02, -5.5191e-02, -2.5010e-02,\n",
       "         -2.5104e-02, -4.1759e-02,  4.5112e-02, -1.4812e-02, -6.0103e-02,\n",
       "         -1.3295e-01, -1.0638e-02, -2.7247e-02, -7.0091e-02, -3.0109e-02,\n",
       "         -1.4657e-02, -4.3211e-02, -5.5270e-02, -5.7571e-03,  2.7533e-02,\n",
       "         -2.6078e-02, -3.7038e-02, -5.5789e-03, -3.4296e-02, -5.5372e-02,\n",
       "         -4.4114e-02, -1.3405e-02, -1.5175e-03, -8.9302e-02, -6.8438e-03,\n",
       "         -9.1634e-02, -3.7731e-02, -1.5678e-02, -2.8527e-02, -8.4438e-02,\n",
       "         -4.0328e-02, -2.3221e-02,  1.3223e-02,  1.5395e-02,  1.4332e-02,\n",
       "         -5.7587e-03, -4.5081e-02, -2.0351e-02, -1.8727e-03, -7.1050e-02,\n",
       "         -5.8486e-04, -6.0502e-02, -1.3587e-02, -3.3649e-02, -4.4877e-02,\n",
       "          2.0852e-03,  2.2341e-02,  1.4839e-02, -5.8141e-02, -3.4381e-02,\n",
       "         -2.9868e-02,  9.7899e-03, -2.0395e-02, -5.2130e-02, -2.0731e-02,\n",
       "         -9.2243e-02, -5.4411e-02, -5.0275e-02, -9.1375e-02,  1.8306e-03,\n",
       "          2.0142e-02, -4.1153e-02, -1.8529e-02,  1.6726e-02, -4.5474e-02,\n",
       "          5.9461e-03,  1.5206e-02, -2.1267e-02, -1.8598e-02, -3.0081e-02,\n",
       "         -5.1100e-02,  1.8852e-03, -2.6002e-03,  4.3399e-02,  3.1865e-03,\n",
       "         -5.9481e-02, -3.2071e-02, -3.3492e-02, -1.5773e-02, -1.1323e-01,\n",
       "         -6.6175e-02, -7.7956e-02, -4.1290e-02, -4.7151e-02, -1.8377e-02,\n",
       "         -5.9987e-02, -5.9592e-02, -4.0417e-02, -1.5552e-02,  4.3662e-03,\n",
       "         -4.6351e-03,  3.4037e-02, -3.8421e-02,  2.1342e-03, -1.6951e-02,\n",
       "          1.2220e-02,  8.2627e-05, -2.5936e-02, -4.5197e-02, -2.3060e-02,\n",
       "         -3.4517e-02, -1.1536e-01, -7.4786e-03, -3.8882e-02, -5.1668e-02,\n",
       "         -1.9316e-01, -1.4243e-03, -3.0771e-02, -7.2752e-02,  3.6927e-02,\n",
       "         -3.4386e-04,  9.9845e-04, -4.2070e-02, -4.0673e-02, -2.5479e-02,\n",
       "         -3.9851e-02, -1.4854e-02, -1.4069e-02, -1.7246e-01, -5.4521e-02,\n",
       "         -2.2452e-02, -3.2232e-02, -8.5568e-02, -2.3721e-02, -1.7124e-02,\n",
       "         -6.5495e-02, -1.3005e-01, -3.6175e-02, -4.8210e-02, -3.7741e-02,\n",
       "         -5.6997e-02, -2.6379e-02,  9.4453e-03, -5.4396e-02,  8.3753e-03,\n",
       "         -6.5888e-02,  6.8267e-03, -1.8409e-02, -4.0941e-02,  5.4443e-04,\n",
       "          1.4480e-02, -1.0193e-01, -2.1265e-02,  1.2959e-02,  1.0792e-02,\n",
       "          2.5818e-02, -4.3791e-02,  1.6200e-02, -2.3660e-02, -1.8552e-02,\n",
       "         -5.0765e-02, -5.8910e-02, -1.0234e-01, -8.1121e-02, -6.2959e-02,\n",
       "         -5.3187e-02,  1.6540e-03, -3.8122e-02, -3.7987e-02, -7.5378e-02,\n",
       "         -9.6866e-03, -9.1908e-02, -4.6406e-03,  3.6364e-02, -7.2061e-02,\n",
       "         -2.3859e-02, -2.4688e-02, -5.7447e-02, -4.4441e-02, -3.2742e-02,\n",
       "         -2.9934e-02, -2.8223e-03, -1.9014e-01, -2.7543e-02, -5.3973e-02,\n",
       "         -1.1027e-02,  1.1239e-02, -7.8189e-02, -1.6205e-02, -2.7818e-02,\n",
       "         -7.6577e-02, -3.1671e-02], device='cuda:0'),\n",
       " tensor([[-0.0048, -0.0048, -0.0048,  ..., -0.0048, -0.0048, -0.0048],\n",
       "         [-0.0048, -0.0048, -0.0048,  ..., -0.0048, -0.0048, -0.0048],\n",
       "         [-0.0048, -0.0048, -0.0048,  ..., -0.0048, -0.0048, -0.0048],\n",
       "         ...,\n",
       "         [-0.0048, -0.0048, -0.0048,  ..., -0.0048, -0.0048, -0.0048],\n",
       "         [-0.0048, -0.0048, -0.0048,  ..., -0.0048, -0.0048, -0.0048],\n",
       "         [-0.0048, -0.0048, -0.0048,  ..., -0.0048, -0.0048, -0.0048]],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0673, -0.0456, -0.0145, -0.0522, -0.0641, -0.0884, -0.0566, -0.0366,\n",
       "         -0.0505, -0.0933, -0.1020, -0.0249, -0.0520, -0.1002, -0.0611, -0.1518,\n",
       "         -0.0593, -0.0878, -0.1073, -0.0113, -0.0407, -0.0908, -0.0052, -0.0274,\n",
       "         -0.1014,  0.0133, -0.0108, -0.0631, -0.0801, -0.0693,  0.0080, -0.0571,\n",
       "          0.0182,  0.0296, -0.0571, -0.0988, -0.0786, -0.0530, -0.0206, -0.0462,\n",
       "         -0.0410, -0.0437, -0.0317, -0.0646, -0.0704, -0.0366, -0.0373, -0.0378,\n",
       "         -0.0618, -0.0557,  0.0398, -0.0663, -0.0540, -0.0805, -0.0462, -0.0405,\n",
       "         -0.0202, -0.0699, -0.0755, -0.0156, -0.0716, -0.0443, -0.0345, -0.0749,\n",
       "         -0.0817, -0.0541, -0.0802, -0.0468, -0.0597, -0.1222, -0.0336, -0.0674,\n",
       "         -0.0237, -0.1347, -0.0403, -0.0435, -0.1545,  0.0266, -0.0816, -0.0221,\n",
       "         -0.0524, -0.0541, -0.1342, -0.0606, -0.0596, -0.0382, -0.1129, -0.1009,\n",
       "         -0.0437,  0.0777, -0.0927, -0.1275, -0.0519, -0.1967, -0.0139, -0.1396,\n",
       "         -0.0485, -0.0449, -0.0425, -0.0451, -0.1042, -0.0729, -0.0294, -0.1006,\n",
       "         -0.0645,  0.0041,  0.0415, -0.0791, -0.0985, -0.0224, -0.0529, -0.0040,\n",
       "         -0.0024, -0.0574,  0.0034, -0.0087, -0.0720, -0.0571, -0.0594, -0.0435,\n",
       "         -0.0384, -0.0722, -0.1175, -0.0553,  0.0096, -0.0643, -0.0574, -0.0751,\n",
       "         -0.1231, -0.0109, -0.0301, -0.0161, -0.1514, -0.0712, -0.0292, -0.0697,\n",
       "         -0.0623, -0.0415, -0.0740, -0.0293, -0.0138, -0.1502, -0.0369, -0.0333,\n",
       "         -0.1196, -0.0449, -0.0422, -0.1471, -0.0542, -0.0581, -0.1136, -0.0595,\n",
       "         -0.0557, -0.0269, -0.0613, -0.0402, -0.0552, -0.0533, -0.0877,  0.0045,\n",
       "         -0.0937, -0.0599, -0.0890,  0.0034, -0.0734, -0.1285, -0.0967, -0.0700,\n",
       "         -0.0386, -0.0327, -0.0681, -0.0086, -0.0617, -0.1069, -0.0641, -0.0373,\n",
       "         -0.0066, -0.0217, -0.0992, -0.0800, -0.0416,  0.0812, -0.0612, -0.0707,\n",
       "         -0.0346, -0.0662, -0.0374, -0.0718, -0.0201, -0.1021, -0.0276, -0.0716,\n",
       "         -0.0426, -0.1586, -0.0643,  0.0537, -0.0268, -0.0559, -0.0559, -0.0593,\n",
       "         -0.0472, -0.0369, -0.0323, -0.1277, -0.0992, -0.0492, -0.0453, -0.0662,\n",
       "         -0.0482, -0.0221, -0.0120, -0.0207, -0.1229, -0.0326, -0.0245, -0.0838,\n",
       "         -0.0143, -0.0339, -0.0512, -0.0974, -0.0329, -0.0687, -0.0869, -0.0199,\n",
       "         -0.0694, -0.0196, -0.0541, -0.0603, -0.0544, -0.0704,  0.0021, -0.0557,\n",
       "         -0.0505, -0.0007, -0.0261, -0.1034,  0.0170, -0.0391, -0.0962, -0.0741,\n",
       "         -0.0509, -0.0456, -0.1762, -0.0331, -0.0014, -0.0146, -0.0437, -0.0135,\n",
       "         -0.0392, -0.0833, -0.0048, -0.0414, -0.0210, -0.0233, -0.0471, -0.0652,\n",
       "         -0.0381, -0.0339, -0.1083, -0.0159, -0.0454, -0.1179, -0.0407, -0.0526,\n",
       "         -0.0912, -0.0353, -0.0382, -0.0625, -0.0405, -0.0130, -0.1390, -0.1457,\n",
       "         -0.0228, -0.0369, -0.0866, -0.0421, -0.0957, -0.0690, -0.0249, -0.0266,\n",
       "         -0.0484, -0.0762, -0.0780, -0.0308, -0.0217, -0.0180, -0.0190, -0.0973,\n",
       "         -0.0140, -0.0468, -0.0598, -0.0624, -0.0822, -0.0609, -0.0371, -0.0120,\n",
       "          0.0228, -0.1361, -0.0591, -0.0633, -0.0083, -0.0398, -0.0407, -0.0474,\n",
       "         -0.0335, -0.0484, -0.0624, -0.0640, -0.0296, -0.0281, -0.0383, -0.2951,\n",
       "         -0.0389, -0.1225, -0.0293, -0.0484, -0.0551, -0.0766, -0.0173, -0.0545,\n",
       "         -0.0546, -0.0658, -0.1207, -0.0760, -0.0796, -0.0055, -0.0659, -0.0867,\n",
       "         -0.0738, -0.0589, -0.0512, -0.0432, -0.0303, -0.0769, -0.0108, -0.0192,\n",
       "         -0.0359, -0.1166, -0.1005, -0.0671, -0.0785, -0.0422, -0.1185, -0.1627,\n",
       "         -0.0784, -0.0469, -0.0449, -0.0270, -0.0291, -0.0430, -0.0354, -0.0192,\n",
       "         -0.0392, -0.1009, -0.0164, -0.0603, -0.0592, -0.1118, -0.0430, -0.1358,\n",
       "         -0.0869, -0.0714, -0.1022,  0.0044, -0.0762, -0.0748, -0.0629, -0.0967,\n",
       "         -0.0452, -0.0883, -0.0683, -0.0859, -0.0772, -0.0369, -0.0606,  0.0564,\n",
       "         -0.0341, -0.0730, -0.0478, -0.1653, -0.0589, -0.0942, -0.0577, -0.0251,\n",
       "         -0.1211, -0.0348, -0.0711, -0.1234, -0.0667, -0.0473, -0.0913, -0.0638,\n",
       "         -0.0386, -0.0782, -0.0235, -0.0344, -0.0998, -0.0580, -0.0095, -0.0445,\n",
       "         -0.0275, -0.1021, -0.0581, -0.0136, -0.0325, -0.0615, -0.0274, -0.0401,\n",
       "          0.0483, -0.0806, -0.0479, -0.0295, -0.0858, -0.0147, -0.0468,  0.0329,\n",
       "         -0.0046, -0.0797, -0.0527, -0.0521, -0.0157, -0.1179, -0.0507, -0.0790,\n",
       "         -0.0562, -0.1901, -0.0719,  0.0140, -0.0694, -0.0254,  0.0323, -0.0285,\n",
       "         -0.0346, -0.0136,  0.0270, -0.0943, -0.0044, -0.0239, -0.0944, -0.0362,\n",
       "         -0.0056, -0.0434, -0.1468, -0.0442, -0.0047, -0.1179, -0.0473, -0.0401,\n",
       "         -0.0472, -0.1973, -0.1206, -0.0843, -0.1025, -0.0528, -0.1251, -0.0634,\n",
       "         -0.0277, -0.0121, -0.0413, -0.0476, -0.0300, -0.1629, -0.0443, -0.0362,\n",
       "         -0.0803, -0.0409, -0.0515, -0.0575, -0.0779, -0.0972,  0.0071,  0.0074,\n",
       "         -0.0555, -0.0286, -0.1014, -0.0710, -0.0540, -0.0247, -0.0122, -0.0713,\n",
       "         -0.0409, -0.0770, -0.0623, -0.1310, -0.0342, -0.0717, -0.1024, -0.0521,\n",
       "         -0.0424, -0.1336, -0.0606, -0.0638, -0.0671, -0.0677, -0.1404, -0.0473,\n",
       "         -0.0564, -0.0414, -0.1380, -0.0787, -0.0612, -0.0364, -0.0826, -0.0131,\n",
       "         -0.0031, -0.0519, -0.0135, -0.0562, -0.0763, -0.0425,  0.0178, -0.0568],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0293, -0.0002],\n",
       "         [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
       "         [-0.0002, -0.0002, -0.0002,  ...,  0.0666, -0.0002, -0.0002],\n",
       "         ...,\n",
       "         [-0.0002, -0.0002, -0.0002,  ..., -0.0430, -0.0002, -0.0002],\n",
       "         [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
       "         [-0.0002, -0.0002, -0.0002,  ..., -0.0002,  0.0034, -0.0002]],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.0409, -0.1973, -0.0425, -0.1124,  0.3229,  0.2789, -0.1163,  0.1183,\n",
       "          0.0612, -0.3010], device='cuda:0')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3c6e93-87af-426a-8ad5-a81bcba62990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3333, 3.3333, 4.3333])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\n",
    "averaging_decoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311d5661-e5fd-4efc-b2d9-f238953a7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = list(model.parameters())\n",
    "# variable_size_encoder(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82afcf7a-e4de-49d7-a835-411608e3731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProxSGDWithLinearSearch:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params, self.lr = list(params), lr\n",
    "        self.state = {p: {} for p in self.params}\n",
    "        self.hypers = [{'lr': lr}]\n",
    "        self.max_iter = 5\n",
    "        self.eta = 1e-5\n",
    "        \n",
    "    def soft_threshold(self, x, eta):\n",
    "        # Apply the soft-thresholding operator\n",
    "        return F.softshrink(x, lambd=eta)\n",
    "        \n",
    "    def prox_operator(self, x):\n",
    "        # Use the soft-thresholding operator as the proximal step\n",
    "        return self.soft_threshold(x, self.eta)\n",
    "\n",
    "    def Gt(self, x, step_size, x_grad):\n",
    "        return (1/step_size) * (x - self.prox_operator(x - step_size * x_grad))\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        model = kwargs.get(\"model\")\n",
    "        loss_fn = kwargs.get(\"loss_fn\")\n",
    "        X = kwargs.get(\"X\")\n",
    "        y = kwargs.get(\"y\")\n",
    "        \n",
    "        orig_params = [p.data.clone() for p in self.params]\n",
    "        step_size = self.lr\n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "            old_loss = loss_fn(pred, y)\n",
    "        flag = True\n",
    "        for _ in range(self.max_iter):\n",
    "            for p in self.params:\n",
    "                if p.grad is not None: \n",
    "                    Gt_val = self.Gt(p.data, step_size, p.grad.data)\n",
    "                    p.data = p.data - step_size * Gt_val\n",
    "            with torch.no_grad():\n",
    "                pred = model(X)\n",
    "                new_loss = loss_fn(pred, y)\n",
    "            if new_loss < old_loss:\n",
    "                flag = False\n",
    "                break\n",
    "            else:\n",
    "                for i, j in zip(self.params, orig_params):\n",
    "                    i.data.copy_(j)\n",
    "                step_size *= 0.5\n",
    "        if flag: \n",
    "            for p in self.params:\n",
    "                if p.grad is not None: \n",
    "                    Gt_val = self.Gt(p.data, step_size, p.grad.data)\n",
    "                    p.data = p.data - step_size * Gt_val\n",
    "        else:\n",
    "            self.lr = step_size\n",
    "        # print(self.lr)\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.grad = None\n",
    "\n",
    "    def set_hypers(self, **kwargs):\n",
    "        if 'lr' in kwargs:\n",
    "            self.lr = kwargs['lr']\n",
    "            self.hypers[0]['lr'] = kwargs['lr']\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7f3833-9cb2-459d-86b1-2b11ea031b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c008223f-22d0-4b30-bf02-6ad83feccae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step(model=model, loss_fn=loss_fn, X=X, y=y)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"BATCH: {batch} of {size/batch_size} batches\")\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "390563a7-8ac8-4947-8a2e-cbda1e90dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, number=\"main\"):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error for client {number}: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89d30967-d2e7-4eca-93ae-225309a9ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_vectors = None\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, model, train_dataloader, loss_fn, mu, max_iter=2):\n",
    "        self.model = model\n",
    "        # self.optimizer = ProxSGDWithLinearSearch(model.parameters(), 20)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.max_iter = max_iter\n",
    "        self.loss_fn = loss_fn\n",
    "        self.mu = mu\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(0, self.max_iter):\n",
    "            train(self.train_dataloader, self.model, self.loss_fn, ProxSGDWithLinearSearch(self.model.parameters(), 20))\n",
    "\n",
    "    def test(self, test_dataloader, number):\n",
    "        test(test_dataloader, self.model, self.loss_fn, number)\n",
    "\n",
    "    def set_parameters(self, model):\n",
    "        self.model = copy.deepcopy(model)\n",
    "            \n",
    "    def get_encoded_1(self, p):\n",
    "        encoded = variable_size_encoder(list(self.model.parameters()), self.mu, p)\n",
    "        final_vectors, mu = sparse_for_variable_size_encoder(encoded, self.mu)\n",
    "        return final_vectors, mu\n",
    "\n",
    "    def get_encoded_2(self, k):\n",
    "        encoded = fixed_size_encoder(list(self.model.parameters()), self.mu, k)\n",
    "        final_vectors, mu, seed = sparse_for_fixed_size_encoder(encoded, self.mu)\n",
    "        encoded_vectors = encoded\n",
    "        return final_vectors, mu, seed\n",
    "\n",
    "    # Built the member function to test if continuous update of the mean is helpful or not\n",
    "    def update_mean(self):\n",
    "        with torch.no_grad():\n",
    "            params = list(self.model.parameters())\n",
    "            self.mu = [torch.mean(p) for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7eee3638-48bb-4b5a-88ae-40f57b6f97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_vectors = None\n",
    "class Master:\n",
    "    def __init__(self, model, mu, loss_fn):\n",
    "        self.model = model\n",
    "        self.original_shapes = [p.shape for p in model.parameters()]\n",
    "        self.mu = mu\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def set_mean(self, mu):\n",
    "        self.mu = copy.deepcopy(mu)\n",
    "        \n",
    "    def update_global_model_from_protocol_1(self, clients_data):\n",
    "        # clients_data is a list of tuples (final_vectors, mu, p) from each client\n",
    "        # Decode each client's parameters and then compute updates\n",
    "        decoded_params_list = []\n",
    "        for (final_vectors, mu) in clients_data:\n",
    "            decoded = rebuild_from_protocol_1(final_vectors, mu, self.original_shapes)\n",
    "            decoded_params_list.append(decoded)\n",
    "\n",
    "        # Now decoded_params_list is a list of parameter lists from each client\n",
    "        # Convert each client's param list into a tensor stack and average updates\n",
    "        # First, get master_params for reference\n",
    "        master_params = list(self.model.parameters())\n",
    "        \n",
    "        # Compute updates: (client_params - master_params) for each client, then average\n",
    "        all_updates = []\n",
    "        with torch.no_grad():\n",
    "            for decoded_params in decoded_params_list:\n",
    "                updates = [(dp - mp) for dp, mp in zip(decoded_params, master_params)]\n",
    "                all_updates.append(updates)\n",
    "\n",
    "            # Average updates across clients\n",
    "            # Stack each parameter across clients and mean\n",
    "            averaged_updates = []\n",
    "            num_clients = len(all_updates)\n",
    "            for param_idx in range(len(master_params)):\n",
    "                # Gather this param_idx from all clients\n",
    "                stack = torch.stack([all_updates[c][param_idx] for c in range(num_clients)], dim=0)\n",
    "                avg = torch.mean(stack, dim=0)\n",
    "                averaged_updates.append(avg)\n",
    "\n",
    "            # Apply averaged updates to master model\n",
    "            for mp, au in zip(master_params, averaged_updates):\n",
    "                mp.data.add_(au)\n",
    "\n",
    "    def update_global_model_from_protocol_2(self, clients_data):\n",
    "        # clients_data is a list of tuples (final_vectors, mu, seed, k) from each client\n",
    "        decoded_params_list = []\n",
    "        global decoded_vectors\n",
    "        for (final_vectors, mu, seed) in clients_data:\n",
    "            decoded = rebuild_from_protocol_2(final_vectors, mu, seed, self.original_shapes)\n",
    "            decoded_params_list.append(decoded)\n",
    "            decoded_vectors = decoded\n",
    "            # print(decoded)\n",
    "\n",
    "        master_params = list(self.model.parameters())\n",
    "        all_updates = []\n",
    "        with torch.no_grad():\n",
    "            for decoded_params in decoded_params_list:\n",
    "                updates = [(dp - mp) for dp, mp in zip(decoded_params, master_params)]\n",
    "                all_updates.append(updates)\n",
    "\n",
    "            num_clients = len(all_updates)\n",
    "            averaged_updates = []\n",
    "            for param_idx in range(len(master_params)):\n",
    "                stack = torch.stack([all_updates[c][param_idx] for c in range(num_clients)], dim=0)\n",
    "                avg = torch.mean(stack, dim=0)\n",
    "                averaged_updates.append(avg)\n",
    "\n",
    "            # Apply averaged updates to master model\n",
    "            \n",
    "            for mp, au in zip(master_params, averaged_updates):\n",
    "                mp.data.add_(au)\n",
    "\n",
    "    def test(self, test_dataloader):\n",
    "        test(test_dataloader, self.model, self.loss_fn, \"master\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8dedf521-0485-4440-bd22-d9865b54eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "parameters = list(model.parameters())\n",
    "mu_1 = []\n",
    "with torch.no_grad():\n",
    "    for p in parameters:\n",
    "        mu_1.append(torch.mean(p))\n",
    "# mu_1 = torch.zeros(len(parameters), device=device)        \n",
    "master = Master(model, mu_1, loss_fn) \n",
    "clients = [Client(NeuralNetwork().to(device), client_loaders[i], loss_fn, mu_1, 2) for i in range(num_clients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af2ac3d8-255a-4ef3-9774-c05cfcabb76d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.305751  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.527659  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.302649  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.371232  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.300845  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.509848  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.307515  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.499726  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.303705  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.393872  [  256/12000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f307fbe5910>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     final_vectors, mu \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_encoded_1(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     16\u001b[0m     clients_data_protocol_1\u001b[38;5;241m.\u001b[39mappend((final_vectors, mu))\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_global_model_from_protocol_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclients_data_protocol_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m master\u001b[38;5;241m.\u001b[39mtest(test_dataloader) \n",
      "Cell \u001b[0;32mIn[52], line 16\u001b[0m, in \u001b[0;36mMaster.update_global_model_from_protocol_1\u001b[0;34m(self, clients_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m decoded_params_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (final_vectors, mu) \u001b[38;5;129;01min\u001b[39;00m clients_data:\n\u001b[0;32m---> 16\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[43mrebuild_from_protocol_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     decoded_params_list\u001b[38;5;241m.\u001b[39mappend(decoded)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Now decoded_params_list is a list of parameter lists from each client\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Convert each client's param list into a tensor stack and average updates\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# First, get master_params for reference\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[92], line 99\u001b[0m, in \u001b[0;36mrebuild_from_protocol_1\u001b[0;34m(final_vectors, mu, original_shapes)\u001b[0m\n\u001b[1;32m     94\u001b[0m     num_elements \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m dim_size\n\u001b[1;32m     97\u001b[0m Y_flat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((num_elements,), mu[i], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mmu[i]\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 99\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvec_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_flat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([pair[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m vec_data], dtype\u001b[38;5;241m=\u001b[39mY_flat\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mY_flat\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    101\u001b[0m Y_flat[indices] \u001b[38;5;241m=\u001b[39m values\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Encoder 1\n",
    "\n",
    "for i in range(1):\n",
    "    # Master sends global parameters to the client\n",
    "    for client in clients:\n",
    "        client.set_parameters(master.model)\n",
    "        # client.update_mean()\n",
    "    \n",
    "    # Clients are trained locally\n",
    "    for client in clients:\n",
    "        client.train()\n",
    "    \n",
    "    clients_data_protocol_1 = []\n",
    "    for client in clients:\n",
    "        final_vectors, mu = client.get_encoded_1(p=0.5)\n",
    "        clients_data_protocol_1.append((final_vectors, mu))\n",
    "    \n",
    "    master.update_global_model_from_protocol_1(clients_data_protocol_1)\n",
    "\n",
    "    master.test(test_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6f16af22-87fe-4c1b-aec4-13d90897e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.303441  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.696943  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.303581  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.554367  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.308671  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.626522  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.306719  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.509755  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.305079  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.520982  [  256/12000]\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "AU\n",
      "tensor([[-0.0214,  0.0237,  0.0168,  ..., -0.0039, -0.0227, -0.0193],\n",
      "        [-0.0155,  0.0242,  0.0104,  ..., -0.0126,  0.0356, -0.0008],\n",
      "        [ 0.0098,  0.0036,  0.0103,  ..., -0.0341,  0.0119, -0.0239],\n",
      "        ...,\n",
      "        [ 0.0245,  0.0310,  0.0008,  ...,  0.0177, -0.0197, -0.0199],\n",
      "        [ 0.0161,  0.0150,  0.0232,  ...,  0.0238,  0.0290,  0.0313],\n",
      "        [-0.0201,  0.0144,  0.0347,  ..., -0.0337,  0.0016, -0.0020]],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2989e-02, -3.8659e-03, -6.0304e-02, -2.1159e-02,  1.0440e-02,\n",
      "        -2.7025e-02,  6.3222e-03, -4.8151e-02, -4.6048e-02, -6.6954e-03,\n",
      "        -8.4686e-02, -7.5736e-02, -1.1500e-02, -4.6938e-02, -1.8234e-02,\n",
      "        -1.6939e-02, -4.9111e-02,  5.1384e-02,  1.5962e-02, -3.8774e-02,\n",
      "         1.7488e-02, -4.3346e-02, -2.2939e-03, -3.0060e-02,  2.0177e-02,\n",
      "        -9.0759e-02, -5.8015e-02, -5.1038e-02, -3.0069e-02, -2.6884e-02,\n",
      "        -6.1564e-02,  2.8432e-02, -4.3905e-02, -2.1565e-02, -1.3942e-02,\n",
      "        -8.7824e-04, -6.6271e-02, -1.9514e-02, -2.9887e-04, -3.1163e-02,\n",
      "        -2.5603e-02, -2.6992e-02, -4.3562e-02,  1.1027e-02,  3.4883e-03,\n",
      "        -5.5027e-02, -9.0391e-03, -3.7025e-02, -1.4644e-02, -9.8407e-03,\n",
      "        -2.7983e-02, -6.0829e-02, -2.6009e-03, -5.2728e-02,  6.1788e-03,\n",
      "         1.9279e-02, -6.7329e-02, -9.2242e-02, -1.2922e-03, -1.7421e-02,\n",
      "        -3.1643e-02,  8.4143e-03, -1.6835e-02, -2.3178e-02, -6.1139e-02,\n",
      "        -2.5664e-02,  4.4558e-02, -5.7432e-03, -1.8372e-02, -4.8293e-02,\n",
      "        -6.6069e-02,  1.0166e-02, -1.9281e-02, -3.8928e-03, -2.9749e-02,\n",
      "         4.3221e-03,  3.8297e-02,  1.0265e-02, -5.1627e-02, -1.9865e-02,\n",
      "         1.6784e-02, -3.5777e-02, -8.0898e-02, -2.1597e-02, -4.3092e-02,\n",
      "         7.1008e-03, -1.6612e-02,  4.3976e-04,  8.3714e-03, -1.6508e-02,\n",
      "        -2.1575e-02,  3.5800e-02,  2.4263e-02, -6.0508e-02, -4.2447e-02,\n",
      "         3.4056e-02, -3.9816e-02, -1.0908e-03, -8.1891e-03, -5.6171e-02,\n",
      "         3.8982e-02, -1.2636e-02, -2.9559e-02, -4.6241e-02, -3.0606e-02,\n",
      "         1.2137e-02, -6.4912e-02,  3.2460e-02, -6.5745e-02, -2.2636e-02,\n",
      "        -5.4253e-03,  2.1717e-02, -1.0718e-02, -5.4878e-02, -4.1032e-03,\n",
      "        -9.1019e-03, -3.6195e-02, -3.2080e-03, -4.0910e-02, -4.4578e-02,\n",
      "        -7.4058e-02, -1.6054e-02,  1.2051e-02,  3.3259e-02, -4.4754e-02,\n",
      "        -2.9258e-02, -3.3110e-03, -6.4991e-02, -1.1245e-02, -6.1075e-02,\n",
      "        -9.6226e-03, -1.0727e-02,  1.1974e-02, -1.3451e-02, -1.1927e-01,\n",
      "        -3.8631e-02, -2.0941e-02,  2.5340e-02,  2.6906e-02, -1.9203e-02,\n",
      "        -7.9248e-03, -4.1620e-02, -2.3613e-02, -3.2288e-02,  5.4541e-03,\n",
      "         2.4320e-02, -7.1625e-04, -3.9248e-02,  3.0377e-03, -4.1296e-02,\n",
      "         3.7225e-04,  1.3025e-02, -3.4272e-02,  1.1207e-02, -4.2922e-02,\n",
      "        -5.3969e-03,  5.3994e-02, -4.4706e-02, -1.2602e-02, -1.8249e-03,\n",
      "        -6.9570e-02, -4.4940e-02,  1.0270e-02, -4.8518e-02, -2.7801e-02,\n",
      "        -2.2766e-02, -1.2333e-02,  3.4399e-03, -4.0416e-03, -2.0497e-03,\n",
      "         1.1870e-02, -3.3090e-02, -1.5409e-02, -4.2617e-02,  4.9489e-02,\n",
      "        -2.1233e-02, -7.0280e-05, -8.1455e-03,  8.9308e-03,  2.3581e-02,\n",
      "        -3.7748e-02, -1.6901e-02, -6.9863e-02, -7.2422e-03,  1.1044e-02,\n",
      "        -8.1158e-03, -3.9554e-02, -2.6228e-02, -7.3088e-03, -1.1357e-01,\n",
      "        -8.8327e-03, -5.5846e-02,  4.1537e-02,  1.4533e-02, -4.9754e-02,\n",
      "        -2.6078e-02,  4.1827e-02, -4.9012e-02, -3.7550e-02,  7.9065e-03,\n",
      "        -3.3558e-02, -1.5222e-02, -1.7371e-02, -3.4268e-02, -4.5382e-02,\n",
      "        -2.4423e-02, -1.0242e-01,  3.3354e-02,  1.8560e-03,  1.9755e-02,\n",
      "        -5.9068e-02, -2.2271e-02, -4.3640e-02, -2.5379e-02, -1.1878e-03,\n",
      "         1.6278e-02, -1.1654e-02,  3.2105e-02,  5.8708e-03, -6.8368e-02,\n",
      "        -7.8117e-02,  1.5260e-02, -2.0844e-02, -2.9238e-02, -4.2676e-02,\n",
      "         1.7286e-02, -8.0432e-02, -1.5220e-02, -7.5302e-02, -3.9562e-02,\n",
      "        -3.5360e-03, -4.9312e-02, -1.8095e-02, -3.1506e-03, -2.8230e-02,\n",
      "        -1.0896e-02,  3.0228e-02, -3.6235e-02,  6.2413e-02,  1.3478e-02,\n",
      "        -3.9952e-02,  6.0138e-03, -5.8400e-02, -7.4095e-03, -3.8984e-02,\n",
      "         2.1667e-02,  1.2176e-02,  8.6226e-03, -6.3307e-02, -1.9443e-02,\n",
      "        -6.1229e-02, -6.2389e-02, -6.0034e-03, -1.2247e-02, -8.9387e-03,\n",
      "        -5.9941e-03,  3.5602e-02, -3.7935e-02,  4.7540e-02,  3.1816e-02,\n",
      "        -4.3954e-03, -7.0809e-02, -4.7704e-03, -2.0930e-03, -2.6580e-02,\n",
      "        -3.3976e-02, -2.3723e-02, -3.8777e-02, -2.6810e-02, -9.4119e-02,\n",
      "        -2.4423e-02, -4.0419e-02,  3.7728e-04, -3.0819e-02, -9.9724e-02,\n",
      "         8.7957e-03, -2.8805e-02,  2.6746e-02,  1.7766e-02, -2.6505e-03,\n",
      "        -3.4661e-03, -2.8431e-02, -3.3312e-02, -5.2269e-02, -5.5673e-02,\n",
      "        -2.9083e-02, -2.6712e-02, -6.9748e-02, -4.2853e-02,  2.2469e-02,\n",
      "         4.1529e-03, -3.0480e-02, -3.3254e-02,  1.3913e-03,  1.4130e-03,\n",
      "        -4.0469e-02, -3.4141e-02, -7.6277e-02,  3.3203e-02, -1.5632e-02,\n",
      "         8.6499e-03,  1.5736e-02, -1.4940e-02,  2.0736e-02, -1.6794e-03,\n",
      "         3.5485e-02, -2.9897e-02,  5.4967e-03, -2.0610e-02, -3.9573e-02,\n",
      "         3.6235e-03,  3.2540e-02, -2.9201e-02,  1.3641e-02, -6.3262e-02,\n",
      "         2.8510e-02, -4.4670e-02, -4.1440e-02, -2.0046e-03, -1.2084e-02,\n",
      "         9.2221e-03,  3.0941e-03,  2.4759e-02,  2.6712e-02, -2.1918e-02,\n",
      "        -6.7900e-02, -6.2020e-02, -1.2508e-02, -8.4275e-02, -4.1056e-02,\n",
      "         5.5246e-04, -3.8353e-02, -7.1819e-02, -6.3854e-02,  1.4371e-02,\n",
      "        -1.7726e-02, -1.3662e-02, -9.1389e-02, -3.1833e-02,  2.5450e-02,\n",
      "        -6.4896e-02,  5.5045e-03, -2.2313e-02, -3.1338e-02, -3.2756e-02,\n",
      "         1.1815e-02,  1.0033e-02, -8.1813e-02, -5.9284e-02, -5.9482e-03,\n",
      "        -4.2159e-02, -9.1938e-02, -8.9641e-03,  1.4919e-02, -3.2341e-02,\n",
      "        -2.3216e-02, -7.9499e-02, -3.1836e-02,  1.9626e-02, -2.1871e-02,\n",
      "        -1.2221e-02, -4.0508e-02,  1.8505e-02,  1.4744e-02,  9.4933e-03,\n",
      "        -2.6808e-02, -5.7039e-02, -3.0893e-02, -3.4453e-03, -1.9031e-02,\n",
      "         2.1455e-02, -6.8384e-03, -3.2002e-02,  1.8315e-02, -3.0682e-02,\n",
      "         1.5254e-02,  4.9555e-02, -3.4005e-02, -3.3254e-02, -6.5776e-02,\n",
      "        -2.9326e-02, -7.8215e-02, -5.3333e-02, -2.3486e-02, -8.6499e-03,\n",
      "        -1.3262e-02, -6.4411e-02, -4.1074e-02, -4.9620e-02, -4.0917e-02,\n",
      "        -7.6932e-02, -1.0704e-02, -5.3841e-02, -6.9194e-02, -1.4886e-02,\n",
      "        -2.5019e-02, -1.5671e-02, -1.5882e-02, -2.4008e-02, -7.8543e-02,\n",
      "        -1.8533e-02,  9.2348e-03, -3.6294e-02, -5.9248e-02, -2.0714e-02,\n",
      "         3.6053e-02, -5.2690e-02, -2.5375e-02, -4.8373e-03,  4.7722e-02,\n",
      "        -3.0119e-02,  3.4544e-02, -4.0822e-02, -2.3325e-02,  2.2393e-02,\n",
      "        -3.5432e-02, -2.3198e-02,  1.2573e-02, -8.5452e-02, -8.5414e-02,\n",
      "         2.1621e-02, -5.0028e-02,  4.3984e-03,  2.9826e-02, -5.0363e-02,\n",
      "        -2.6765e-02,  4.5770e-03, -8.6241e-03, -4.8360e-02, -1.0520e-02,\n",
      "        -2.4700e-02,  2.9408e-03, -4.1528e-02, -1.4694e-02, -6.6199e-02,\n",
      "         2.8967e-02,  1.5743e-02, -6.9307e-02, -1.2456e-02, -3.1384e-02,\n",
      "        -6.6752e-02,  2.6464e-02, -2.5151e-02, -2.6256e-02,  1.7159e-02,\n",
      "         1.8444e-03,  1.7354e-02,  2.7148e-02, -7.8439e-03, -6.1690e-02,\n",
      "        -4.0006e-02, -3.7148e-02,  8.1291e-03, -1.0955e-01,  3.0825e-02,\n",
      "        -1.3953e-04, -6.8821e-03,  3.8971e-02, -9.0547e-02, -4.9978e-02,\n",
      "        -2.2640e-02, -3.4344e-02,  1.6878e-02, -6.2689e-02, -5.4071e-02,\n",
      "        -4.5481e-02, -1.3801e-01, -3.6724e-02, -5.3584e-02, -1.9276e-02,\n",
      "        -5.3320e-02, -1.0737e-02, -4.8329e-02, -4.6169e-03, -4.8776e-03,\n",
      "        -1.4108e-02, -2.9610e-02,  5.1026e-03,  4.4811e-02,  8.7876e-03,\n",
      "        -6.5149e-02,  2.9931e-04, -5.4957e-02,  2.7707e-03,  1.8512e-02,\n",
      "        -2.6301e-02,  2.2373e-02, -3.7361e-02, -5.1373e-02, -7.3771e-03,\n",
      "        -6.0448e-02, -1.1548e-02, -3.2841e-05, -1.5215e-02,  6.2914e-03,\n",
      "        -9.4606e-02,  4.6403e-02, -6.9233e-02, -6.8415e-02,  3.3100e-03,\n",
      "        -8.0541e-02,  5.1139e-02,  1.5206e-02, -3.9737e-02, -9.1697e-03,\n",
      "        -2.5364e-02, -1.6285e-02, -3.6912e-02,  3.3482e-02,  3.0555e-02,\n",
      "         2.6966e-02, -4.2482e-02], device='cuda:0')\n",
      "tensor([[ 0.0363, -0.0082,  0.0055,  ...,  0.0170,  0.0302,  0.0012],\n",
      "        [ 0.0290,  0.0270,  0.0136,  ..., -0.0197,  0.0269, -0.0305],\n",
      "        [-0.0148,  0.0254, -0.0271,  ..., -0.0227,  0.0348, -0.0267],\n",
      "        ...,\n",
      "        [ 0.0413, -0.0187,  0.0045,  ..., -0.0383, -0.0266, -0.0012],\n",
      "        [-0.0426, -0.0260, -0.0351,  ..., -0.0369, -0.0329, -0.0277],\n",
      "        [ 0.0199, -0.0327,  0.0095,  ...,  0.0245, -0.0061, -0.0429]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0577, -0.0600, -0.0497, -0.0307,  0.0109, -0.0379, -0.0500, -0.0555,\n",
      "         0.0084, -0.0832, -0.1300, -0.0412,  0.0264,  0.0220, -0.0246, -0.0179,\n",
      "         0.0145, -0.0005,  0.0135, -0.0073,  0.0255, -0.0302, -0.0548,  0.0063,\n",
      "         0.0241,  0.0148, -0.0425,  0.0036,  0.0074, -0.1247, -0.0710, -0.0521,\n",
      "        -0.0900, -0.0257, -0.0041, -0.0049, -0.0552, -0.0080, -0.1173, -0.0499,\n",
      "        -0.0243, -0.0405, -0.0430, -0.0294, -0.0096,  0.0117,  0.0056, -0.0442,\n",
      "        -0.1493, -0.0019, -0.0646, -0.0312, -0.0292, -0.0373, -0.0209, -0.0543,\n",
      "        -0.0428,  0.0666, -0.0455, -0.0622, -0.0887, -0.0300, -0.0858, -0.0019,\n",
      "        -0.0068, -0.0600, -0.0205, -0.0735,  0.0054, -0.0097, -0.0481, -0.0089,\n",
      "         0.0211, -0.0768, -0.0505, -0.0252, -0.0153, -0.0029, -0.0432, -0.0334,\n",
      "         0.0188,  0.0070, -0.0328, -0.0127, -0.0358, -0.0492,  0.0194, -0.0477,\n",
      "        -0.0769, -0.0238,  0.0710, -0.1374, -0.0846,  0.0117, -0.0766, -0.0014,\n",
      "        -0.0542,  0.0413, -0.0589,  0.0051, -0.0324, -0.0597,  0.0074,  0.0350,\n",
      "        -0.0280, -0.0286, -0.0511,  0.0458, -0.0418,  0.0230,  0.0160,  0.0298,\n",
      "        -0.0181, -0.1079,  0.0125, -0.0148, -0.0779, -0.0190, -0.0635, -0.0554,\n",
      "         0.0477,  0.0272, -0.0519,  0.0415, -0.0348,  0.0056, -0.0522, -0.0733,\n",
      "         0.0026, -0.0194,  0.0057, -0.0318, -0.0032, -0.0359, -0.0125, -0.0814,\n",
      "        -0.0311, -0.0399, -0.0236, -0.0608, -0.0865, -0.0270, -0.0659,  0.0197,\n",
      "         0.0071, -0.0693, -0.0846, -0.0514,  0.0080, -0.0460, -0.0688, -0.0006,\n",
      "        -0.0311, -0.1186, -0.0085, -0.0351, -0.0397, -0.0753, -0.0056,  0.0120,\n",
      "        -0.0400, -0.1128, -0.0854, -0.0642, -0.0837,  0.0187, -0.0888, -0.0636,\n",
      "        -0.0036, -0.0367,  0.0302, -0.0360,  0.0322, -0.0424,  0.0287, -0.0121,\n",
      "        -0.0799, -0.0603, -0.0351, -0.0350, -0.0283,  0.0014, -0.0179, -0.0107,\n",
      "         0.0053,  0.0172, -0.0257,  0.0106,  0.0586, -0.0101, -0.0086, -0.0081,\n",
      "        -0.0805, -0.0862, -0.0946,  0.0202, -0.0368, -0.0095, -0.0346, -0.0010,\n",
      "         0.0040, -0.0056, -0.0187,  0.0246, -0.0668,  0.0294, -0.0412, -0.0046,\n",
      "        -0.0526, -0.0632, -0.0158, -0.0302, -0.0597,  0.0321, -0.0443,  0.0366,\n",
      "        -0.0244, -0.0280,  0.0201,  0.0130, -0.0171, -0.0152,  0.0083, -0.0617,\n",
      "        -0.0588, -0.0184, -0.0007,  0.0168, -0.0691, -0.0677,  0.0404, -0.0387,\n",
      "        -0.0219, -0.0521, -0.0889, -0.0428,  0.0127, -0.0698,  0.0557, -0.0824,\n",
      "        -0.0099, -0.0321, -0.0278, -0.0085, -0.1129, -0.0399,  0.0370, -0.0584,\n",
      "        -0.0761, -0.0627, -0.0586, -0.1070,  0.0091, -0.0553, -0.0852, -0.0636,\n",
      "        -0.0382, -0.0106, -0.0750, -0.0057,  0.0071, -0.1013, -0.0521, -0.0278,\n",
      "        -0.0067, -0.0665, -0.0486, -0.0722,  0.0201,  0.0056, -0.0388, -0.0443,\n",
      "         0.0096,  0.0644, -0.0575,  0.0220,  0.0479, -0.0288, -0.0161, -0.0656,\n",
      "        -0.0039, -0.0616, -0.1231,  0.0065, -0.0128, -0.1102, -0.0513, -0.0011,\n",
      "        -0.0874, -0.0421,  0.0510, -0.0230, -0.0490, -0.0367, -0.0529, -0.0158,\n",
      "         0.0094, -0.0077, -0.0162, -0.0302, -0.0573, -0.0081, -0.0264, -0.0534,\n",
      "         0.0045, -0.0287,  0.0396,  0.0211, -0.0539, -0.0142, -0.0044, -0.0452,\n",
      "        -0.0515, -0.0111,  0.0112,  0.0178, -0.1213,  0.0263,  0.0296, -0.0112,\n",
      "         0.0207,  0.0296, -0.0771, -0.0470, -0.0555, -0.0574, -0.0546, -0.0008,\n",
      "        -0.0073, -0.0620,  0.0179,  0.0234, -0.0542, -0.0196,  0.0016, -0.0858,\n",
      "        -0.0748, -0.0377, -0.0504,  0.0004, -0.0408, -0.0465,  0.0215, -0.0788,\n",
      "        -0.0499, -0.0399, -0.0998,  0.0282,  0.0026, -0.0446, -0.0648, -0.0563,\n",
      "        -0.0580, -0.0099,  0.0406, -0.0312, -0.0312, -0.0784, -0.0322, -0.0936,\n",
      "         0.0309,  0.0202, -0.0092, -0.0441, -0.0116, -0.1418, -0.0560, -0.0293,\n",
      "        -0.0250,  0.0326, -0.0185, -0.0771, -0.0306,  0.0574,  0.0129,  0.0266,\n",
      "         0.0323, -0.0149, -0.0800, -0.0219, -0.1336, -0.0118, -0.0019, -0.0412,\n",
      "        -0.0173, -0.0145,  0.0154, -0.0483, -0.0456, -0.0291,  0.0270, -0.0483,\n",
      "        -0.0045, -0.0486, -0.0363, -0.0650, -0.0359,  0.0403, -0.0136,  0.0193,\n",
      "         0.0191, -0.0799, -0.0074, -0.0798, -0.0019, -0.0044,  0.0258, -0.0133,\n",
      "         0.0330, -0.0674, -0.0357, -0.0114, -0.0886,  0.0045, -0.0565, -0.0228,\n",
      "        -0.0582,  0.0511, -0.0261, -0.0624, -0.0153, -0.0407, -0.0141,  0.0368,\n",
      "        -0.0180, -0.0154, -0.0083, -0.0079, -0.0237, -0.0240, -0.0387, -0.0645,\n",
      "         0.0539,  0.0047, -0.0654, -0.0866, -0.0423, -0.0860, -0.0085,  0.0141,\n",
      "        -0.0669, -0.0228,  0.0143, -0.0317, -0.0623,  0.0023, -0.0798,  0.0458,\n",
      "        -0.0654, -0.0429, -0.0936, -0.0988, -0.0524, -0.0143, -0.0258, -0.1165,\n",
      "        -0.0919, -0.0451, -0.0126, -0.0414, -0.0245, -0.0108,  0.0003, -0.0703,\n",
      "         0.0087, -0.0136, -0.0341, -0.0363,  0.0519, -0.0008, -0.0469, -0.0459,\n",
      "        -0.0387, -0.0399, -0.0090, -0.0328,  0.0325, -0.0380,  0.0359, -0.0714,\n",
      "        -0.0473, -0.0448, -0.0694,  0.0164,  0.0032, -0.0344, -0.0924, -0.0214,\n",
      "        -0.1026, -0.0290,  0.0023,  0.0431, -0.0167, -0.0310, -0.0650, -0.0731,\n",
      "        -0.0320, -0.0044, -0.0577, -0.0263, -0.0388, -0.0374, -0.0202, -0.0163,\n",
      "         0.0182, -0.0354, -0.0069, -0.0685, -0.0728, -0.0657, -0.0340, -0.0741],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0426, -0.0317, -0.0006,  ..., -0.0104, -0.0162,  0.0168],\n",
      "        [-0.0022, -0.0360,  0.0417,  ...,  0.0139, -0.0298, -0.0035],\n",
      "        [-0.0247,  0.0204,  0.0059,  ...,  0.0063, -0.0090, -0.0090],\n",
      "        ...,\n",
      "        [ 0.0395,  0.0165, -0.0270,  ..., -0.1005, -0.0247,  0.0088],\n",
      "        [ 0.0428, -0.0128,  0.0069,  ...,  0.0400,  0.0111, -0.0209],\n",
      "        [-0.0350, -0.0440,  0.0275,  ...,  0.0306,  0.0652,  0.0135]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.1733, -0.0724,  0.0728, -0.1324,  0.0456, -0.0188,  0.0012,  0.2377,\n",
      "        -0.2335,  0.2731], device='cuda:0')\n",
      "Test Error for client master: \n",
      " Accuracy: 10.1%, Avg loss: 2.314941 \n",
      "\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.312935  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.348347  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.308666  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.890965  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.315679  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.788092  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.309527  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.451618  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.321014  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.704955  [  256/12000]\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "AU\n",
      "tensor([[-7.7540e-06, -7.7559e-06, -7.7559e-06,  ..., -7.7549e-06,\n",
      "         -7.7559e-06, -7.7559e-06],\n",
      "        [-7.7549e-06, -7.7559e-06, -7.7549e-06,  ..., -7.7549e-06,\n",
      "         -7.7540e-06, -7.7550e-06],\n",
      "        [-7.7549e-06, -7.7552e-06, -7.7549e-06,  ..., -7.7540e-06,\n",
      "         -7.7549e-06, -7.7540e-06],\n",
      "        ...,\n",
      "        [-7.7577e-06, -7.7540e-06, -7.7550e-06,  ..., -7.7559e-06,\n",
      "         -7.7559e-06, -7.7559e-06],\n",
      "        [-7.7559e-06, -7.7549e-06, -7.7559e-06,  ..., -7.7559e-06,\n",
      "         -7.7540e-06, -7.7559e-06],\n",
      "        [-7.7559e-06, -7.7549e-06, -7.7540e-06,  ..., -7.7540e-06,\n",
      "         -7.7550e-06, -7.7549e-06]], device='cuda:0')\n",
      "tensor([-4.5126e-02, -5.9345e-02, -2.2704e-02, -3.4898e-02, -2.5337e-02,\n",
      "        -3.0428e-02,  1.4552e-02, -6.4468e-03, -1.6651e-02, -3.3014e-02,\n",
      "         1.4390e-02,  3.4902e-02, -3.1203e-02,  1.2387e-02, -2.0106e-02,\n",
      "        -1.9878e-02, -2.4414e-02, -2.3805e-02, -3.5597e-02,  1.2078e-02,\n",
      "        -5.2169e-02,  5.4992e-02, -9.8799e-02, -1.7736e-02, -5.4650e-02,\n",
      "         9.8853e-03,  6.6256e-02,  2.9988e-03,  2.4537e-02, -5.2174e-02,\n",
      "         3.9377e-02, -1.8884e-01, -1.5397e-02, -4.7040e-04, -1.3191e-02,\n",
      "        -3.8435e-02,  1.4605e-02, -1.8381e-01, -3.8740e-02,  2.5815e-02,\n",
      "         3.5367e-02, -8.7822e-05,  2.2891e-02, -2.1246e-02, -4.1413e-02,\n",
      "         3.3233e-02, -1.6924e-02, -6.6953e-03,  2.4416e-02,  1.7803e-03,\n",
      "         2.9667e-02,  3.4748e-02, -9.3261e-03,  4.8102e-02, -1.4246e-02,\n",
      "        -5.0784e-02,  4.6621e-02,  5.6860e-02, -1.5666e-02, -3.1097e-01,\n",
      "         2.2977e-02, -8.9714e-02,  2.9355e-02, -5.7734e-02,  6.0777e-02,\n",
      "        -2.1197e-02, -5.5505e-02, -5.9030e-02,  2.8991e-02, -5.2508e-03,\n",
      "         4.7599e-02, -4.9058e-03, -7.5715e-02, -1.1513e-02, -8.6810e-02,\n",
      "        -4.1704e-02, -5.1774e-02, -9.1657e-03,  3.4494e-03, -3.9474e-02,\n",
      "        -3.3252e-03, -7.4080e-02,  4.5591e-02, -1.2994e-02, -2.9730e-02,\n",
      "        -3.1095e-02,  2.7292e-03,  5.2350e-03, -1.8555e-01,  2.6020e-02,\n",
      "        -1.2748e-02, -2.2784e-02, -3.3179e-02,  1.1161e-02,  2.0827e-02,\n",
      "        -7.5241e-02,  9.6193e-03, -1.1957e-01, -2.0106e-04,  7.5673e-03,\n",
      "        -7.4135e-02, -1.6223e-02, -3.6795e-02, -2.1789e-02, -4.2720e-02,\n",
      "         2.1137e-03,  3.2265e-02, -6.0624e-02,  2.0805e-02,  1.1647e-02,\n",
      "        -7.9897e-03, -6.9682e-02, -9.4619e-03, -2.5798e-02, -4.0567e-02,\n",
      "        -3.5414e-02, -3.0369e-02, -5.3846e-02,  1.6316e-03,  5.9241e-02,\n",
      "         1.7356e-02,  9.2193e-03, -5.9032e-02, -4.9386e-02, -1.6403e-02,\n",
      "        -5.3627e-02, -4.1850e-02,  2.3985e-02,  3.6266e-02, -1.6031e-02,\n",
      "        -2.7259e-02, -6.9968e-02, -5.5497e-02,  1.0311e-02,  8.3418e-02,\n",
      "        -7.0082e-03, -1.2018e-02, -1.7373e-02, -1.0908e-01, -1.7568e-02,\n",
      "        -2.7225e-02, -2.3491e-02, -4.7825e-02,  5.9586e-03, -6.3887e-01,\n",
      "        -5.1285e-02, -1.3145e-02,  9.0899e-03, -7.7443e-02,  1.7841e-02,\n",
      "        -3.5036e-02, -2.4335e-02, -5.5648e-03, -3.4426e-02,  1.9846e-04,\n",
      "         3.6770e-04, -3.4015e-02, -4.2286e-03, -1.3863e-01, -8.9606e-02,\n",
      "         2.9779e-02, -4.4920e-02, -2.0710e-02, -2.0596e-02, -1.5663e-01,\n",
      "        -2.7121e-02, -3.1137e-02, -6.9493e-03,  8.3598e-03, -6.6615e-03,\n",
      "        -5.6548e-02,  1.3502e-02, -2.2594e-02, -2.5880e-02, -2.6706e-02,\n",
      "         1.8052e-02, -7.8877e-03, -4.0936e-03, -4.4396e-02, -3.4754e-02,\n",
      "        -8.6043e-03,  2.6106e-02,  7.0514e-03,  9.3988e-04, -1.1404e-01,\n",
      "        -6.7769e-02, -2.1058e-03,  2.4775e-02,  3.5842e-03,  1.1214e-01,\n",
      "        -6.4312e-02,  3.3661e-02, -4.9265e-02, -1.4307e-02,  2.2094e-02,\n",
      "         3.6783e-02, -7.8559e-02,  2.0038e-02, -1.2974e-02, -1.0450e-02,\n",
      "         1.0198e-02, -9.7288e-02, -4.4876e-02,  1.8461e-02, -1.5312e-02,\n",
      "        -1.7960e-01,  4.7981e-02, -7.1006e-02, -8.1030e-02, -1.7632e-01,\n",
      "         3.7324e-02, -1.5439e-03,  2.7751e-03, -1.1005e-01, -4.9605e-02,\n",
      "        -7.2482e-01, -2.1096e-02, -4.7874e-02, -5.4000e-03,  8.8601e-03,\n",
      "         2.6197e-02, -6.0162e-03, -6.6380e-02, -3.2767e-02, -1.8136e-02,\n",
      "        -3.9826e-02,  6.1102e-02, -3.9701e-01,  3.9334e-02,  2.9659e-02,\n",
      "         1.6746e-02, -1.2755e-02,  1.3165e-03, -7.1430e-02,  3.9467e-02,\n",
      "        -2.7003e-02, -5.0576e-02, -1.8864e-02, -6.3244e-02,  1.4224e-02,\n",
      "        -3.7120e-02, -3.6811e-02, -3.9526e-03, -5.3538e-02,  2.8254e-03,\n",
      "        -4.6443e-02, -1.2357e-01, -7.0922e-02,  4.4450e-02, -1.5970e-01,\n",
      "        -1.8354e-02,  3.1172e-02, -4.8920e-02, -4.1941e-02, -5.0071e-03,\n",
      "         9.5907e-03, -3.0694e-02, -2.9513e-02, -3.9607e-02, -1.0595e+00,\n",
      "        -4.0398e-02,  1.5535e-02, -4.4939e-02, -8.7292e-02, -6.2771e-02,\n",
      "        -2.5689e-02, -4.1551e-03, -4.9874e-02, -5.6662e-02,  5.3602e-02,\n",
      "         2.4358e-02, -2.1329e-02, -3.8303e-01,  8.3660e-03,  4.0458e-03,\n",
      "         1.7017e-02, -6.7457e-04, -7.3088e-02, -3.3767e-02, -3.8034e-02,\n",
      "         7.2165e-03, -5.7255e-03,  4.1585e-02,  7.0976e-03,  3.4432e-02,\n",
      "        -4.2781e-02, -1.7335e-02, -6.6290e-03,  1.0471e-02, -6.0585e-02,\n",
      "        -1.5167e-02,  1.5782e-02, -5.9247e-01,  2.8337e-02, -2.3966e-02,\n",
      "        -1.8421e-01,  4.5986e-03,  2.2748e-02, -1.2250e-02,  2.6317e-02,\n",
      "        -1.4800e-02,  4.9246e-03, -1.6652e-02, -6.3666e-02, -1.9130e-03,\n",
      "        -6.3658e-02,  4.0307e-03, -7.1516e-03, -3.2159e-02,  4.6066e-02,\n",
      "        -1.9836e-02, -8.5027e-02, -9.7914e-02, -3.8357e-03,  3.9802e-02,\n",
      "        -3.4419e-02,  8.9962e-03, -9.2923e-02,  1.0888e-02, -1.6997e-02,\n",
      "        -3.4345e-02, -2.4812e-02, -1.7090e-02, -1.6126e-02, -4.3657e-03,\n",
      "         3.6120e-02,  3.1953e-02, -2.6090e-01,  2.5629e-02,  3.0504e-02,\n",
      "        -2.2218e-03, -1.1635e-01,  5.8405e-02, -1.0551e-02, -1.7137e-01,\n",
      "         3.7775e-02,  8.5963e-04,  8.5328e-02,  3.2671e-03, -1.8418e-01,\n",
      "         5.2901e-02, -2.1999e-02,  1.9306e-02, -6.0554e-02, -1.6078e-03,\n",
      "        -5.8576e-02,  1.1847e-02,  2.1673e-02,  2.4935e-02,  3.8918e-03,\n",
      "         3.8735e-02,  5.7481e-02,  1.1333e-02,  7.8239e-03,  3.7408e-02,\n",
      "        -4.8273e-02,  5.7067e-02,  2.2282e-02, -4.1347e-02, -1.2623e-02,\n",
      "        -4.0977e-03, -4.3908e-02, -2.3875e-02, -1.8173e-02, -2.7510e-02,\n",
      "        -2.3249e-02,  7.3607e-02,  6.5598e-03, -2.4124e-01, -3.4540e-02,\n",
      "        -2.5329e-02,  2.5986e-03,  1.9319e-02, -4.1620e-02,  3.9331e-02,\n",
      "        -2.4713e-01, -4.0743e-02,  4.4606e-02,  3.2808e-03,  3.5618e-02,\n",
      "        -1.2656e-02,  4.7295e-02,  2.6491e-02, -4.4053e-03, -2.3311e-02,\n",
      "        -1.7049e-02,  1.0698e-02,  2.9405e-03,  4.2119e-02, -1.6388e-02,\n",
      "         1.9989e-02, -3.9899e-02, -1.1808e-02,  4.3693e-02, -9.5148e-03,\n",
      "        -1.7308e-02, -5.7467e-02,  4.8646e-03, -1.7327e-01,  2.5281e-02,\n",
      "         9.2516e-03, -6.5018e-02, -4.5426e-02,  4.5930e-02, -4.0635e-02,\n",
      "        -2.3978e-02,  2.6427e-02, -6.1611e-03, -5.9363e-02, -2.2509e-02,\n",
      "        -4.6804e-03, -4.8627e-02, -1.4138e-02,  3.5498e-02, -2.0522e-02,\n",
      "        -9.5055e-03,  3.5181e-03, -1.2683e-02,  1.5809e-02, -3.5024e-01,\n",
      "        -3.5026e-02,  7.9471e-03, -2.6442e-02, -3.0985e-02,  1.0590e-02,\n",
      "        -7.9109e-03, -5.3187e-02, -2.3911e-02, -3.6330e-02, -1.4505e-02,\n",
      "         3.3149e-02, -3.1822e-03,  6.9560e-03, -1.8991e-02,  3.9646e-03,\n",
      "        -2.7058e-02, -1.0165e-02,  5.3790e-02, -7.7915e-03,  1.9648e-02,\n",
      "         2.9318e-02, -1.3724e-02, -1.5424e-02, -4.2012e-02, -1.8720e-01,\n",
      "        -7.8214e-04, -4.6142e-02, -5.5767e-02, -1.2547e-02, -4.2205e-01,\n",
      "        -9.5022e-04, -2.6433e-02, -3.2848e-03,  5.3115e-02, -3.6706e-02,\n",
      "        -3.1442e-02, -3.2949e-01, -5.9328e-02,  5.7088e-02, -2.9940e-02,\n",
      "         1.2184e-02, -1.1328e-02, -1.0816e-01,  1.8861e-02, -3.5245e-02,\n",
      "        -1.1558e-02,  1.2318e-01,  9.4251e-04, -1.2219e-01,  2.1842e-02,\n",
      "         2.5174e-02, -3.4845e-02,  2.8704e-02, -2.4523e-02, -2.6456e-02,\n",
      "        -2.3556e-03, -3.8729e-03, -8.1677e-02, -2.6800e-02, -8.2348e-02,\n",
      "         3.0070e-03, -2.4553e-02, -5.1255e-04, -6.0230e-02, -2.9721e-02,\n",
      "        -2.8318e-02, -3.5203e-02, -1.0098e-02,  2.8716e-02, -7.4361e-02,\n",
      "         2.6550e-02,  4.4007e-03,  2.1144e-02, -1.4013e-03, -7.0149e-03,\n",
      "         3.3315e-02, -6.6164e-02, -2.2882e-01,  1.8926e-02, -3.2798e-02,\n",
      "         7.6731e-02, -3.2959e-02, -1.8840e-02, -1.8245e-02, -3.7949e-02,\n",
      "         5.4097e-03, -3.7062e-02, -3.1119e-02, -5.8114e-02, -3.0327e-02,\n",
      "        -8.9367e-02, -5.4517e-02], device='cuda:0')\n",
      "tensor([[-9.2645e-06, -9.2617e-06, -9.2631e-06,  ..., -9.2645e-06,\n",
      "         -9.2626e-06, -9.2629e-06],\n",
      "        [-9.2626e-06, -9.2626e-06, -9.2636e-06,  ..., -9.2626e-06,\n",
      "         -9.2626e-06, -9.2626e-06],\n",
      "        [-9.2626e-06, -9.2608e-06, -9.2626e-06,  ..., -9.2626e-06,\n",
      "         -9.2645e-06, -9.2626e-06],\n",
      "        ...,\n",
      "        [-9.2645e-06, -9.2626e-06, -9.2631e-06,  ..., -9.2645e-06,\n",
      "         -9.2626e-06, -9.2629e-06],\n",
      "        [-9.2645e-06, -9.2608e-06, -9.2645e-06,  ..., -9.2608e-06,\n",
      "         -9.2645e-06, -9.2626e-06],\n",
      "        [-9.2626e-06, -9.2645e-06, -9.2626e-06,  ..., -9.2626e-06,\n",
      "         -9.2631e-06, -9.2645e-06]], device='cuda:0')\n",
      "tensor([-2.2428e-02,  9.3356e-03, -1.4175e-02, -1.1923e-02, -1.4403e-02,\n",
      "        -4.0994e-03, -1.7181e-02,  3.3244e-02, -6.2111e-02,  1.5698e-02,\n",
      "         7.2799e-02,  2.7577e-02, -5.1304e-02, -7.8985e-03,  3.1934e-02,\n",
      "        -2.6619e-02, -6.1382e-02,  7.5181e-03,  2.6048e-03,  2.0389e-02,\n",
      "        -7.4027e-02,  1.1610e-02,  1.3670e-02,  1.7481e-03, -4.8677e-02,\n",
      "        -2.1017e-02,  2.2775e-02, -9.2424e-03, -6.0311e-02,  6.7683e-02,\n",
      "        -2.8447e-04,  1.6084e-02,  3.1540e-02, -4.6824e-02, -3.1643e-02,\n",
      "        -8.8742e-02,  4.3315e-03, -7.2007e-02,  4.6310e-02,  1.9388e-02,\n",
      "        -4.7241e-03,  2.0557e-02,  7.7403e-03,  1.3467e-02, -3.8581e-02,\n",
      "        -1.5227e-02, -9.2560e-01, -4.8119e-03,  8.9477e-02, -3.1389e-02,\n",
      "         4.2965e-02, -4.9669e-02, -3.6457e-02, -2.4495e-02, -1.1067e-01,\n",
      "         1.8801e-02,  2.8050e-02, -4.9999e-02, -1.1109e-02,  1.7867e-02,\n",
      "         7.2009e-02, -1.3697e-02,  1.6237e-02, -3.7161e-02, -2.5452e-02,\n",
      "         6.6372e-02,  1.4257e-02,  3.3522e-03, -3.9883e-01, -3.5851e-02,\n",
      "        -2.5778e-02, -1.9042e-02,  1.3475e-02,  8.1023e-02, -1.8970e-03,\n",
      "         1.6457e-02,  3.4877e-02, -5.3189e-03,  8.8598e-03,  2.8802e-02,\n",
      "        -4.4640e-01, -4.2800e-03,  4.3762e-02, -6.2047e-02,  1.2252e-02,\n",
      "         2.3673e-02, -7.4719e-03,  1.2626e-02,  1.6472e-02,  9.9495e-03,\n",
      "        -1.2035e-01,  6.7408e-02,  2.4530e-02, -6.0193e-02,  2.2850e-02,\n",
      "         2.6352e-02,  1.7979e-02, -6.1910e-02,  1.5189e-02, -2.3126e-02,\n",
      "         4.4858e-02, -5.6367e-02, -4.8002e-02, -1.0646e-01,  9.4712e-03,\n",
      "         3.4714e-02, -5.1430e-03, -1.3957e-02, -4.5942e-02,  1.5891e-02,\n",
      "        -2.0363e-02, -1.1009e-02,  2.9356e-02,  9.1527e-02, -3.4331e-02,\n",
      "        -9.1020e-02,  2.1598e-02, -5.4005e-02,  2.4262e-02,  2.7298e-02,\n",
      "        -3.4944e-02, -5.5518e-02,  2.3561e-02, -2.3666e-02, -6.2555e-03,\n",
      "        -2.2059e-02, -3.9008e-03,  1.5776e-02,  3.8769e-02, -3.0106e-02,\n",
      "        -1.3637e-02, -2.2181e-02, -5.7763e-03,  7.2828e-03, -1.2018e-01,\n",
      "         5.7752e-02, -3.4355e-02, -2.3544e-03,  3.6875e-02,  3.3179e-02,\n",
      "         4.2450e-02,  1.8171e-02, -1.2865e-01, -2.3805e-02,  2.1278e-02,\n",
      "         9.0280e-03,  4.5271e-02, -2.8176e-02, -1.0018e-01,  2.0550e-02,\n",
      "         1.9143e-02, -2.2571e-02, -1.1635e-01,  8.6006e-02,  2.4202e-02,\n",
      "        -4.1977e-03, -3.5888e-02,  3.3589e-02, -5.6722e-02, -4.5245e-02,\n",
      "        -1.0249e-01,  7.0695e-02,  7.6062e-02, -9.8667e-03,  8.5098e-02,\n",
      "        -7.9716e-02,  1.2208e-01, -1.3812e-01, -1.3384e-02, -1.7050e-02,\n",
      "        -3.8001e-02, -9.6958e-03, -8.0683e-03, -1.2060e-03, -5.1979e-02,\n",
      "        -3.0211e-02, -1.6052e-01,  2.7319e-02,  2.3340e-02, -1.2821e-03,\n",
      "        -8.6030e-02, -2.7802e-02,  5.1592e-02,  9.4005e-04, -5.0555e-02,\n",
      "        -2.3865e-02,  2.7897e-02, -7.0041e-02, -3.4638e-02, -3.5597e-01,\n",
      "         9.6897e-03, -5.0601e-02,  4.1647e-02, -6.0646e-01,  5.2744e-02,\n",
      "        -3.3920e-02, -8.0552e-03,  1.3761e-02,  7.4554e-03, -3.3094e-02,\n",
      "        -9.8736e-02, -3.1001e-03, -1.2081e-02, -9.4276e-03, -6.8387e-03,\n",
      "        -4.5416e-02,  2.1356e-02, -2.7701e-02,  5.0806e-03, -5.8705e-03,\n",
      "        -2.9700e-02,  5.4945e-03,  2.0538e-02, -2.6633e-01, -4.0872e-02,\n",
      "        -1.5332e-02,  5.6533e-03, -3.9676e-02, -4.8758e-02, -2.8571e-01,\n",
      "        -5.1286e-02, -7.2061e-03, -3.6366e-02, -3.7574e-02,  5.8486e-02,\n",
      "        -3.4812e-02, -2.4627e-03, -2.8319e-02,  3.6968e-02,  3.5786e-02,\n",
      "        -4.0296e-02, -3.4267e-02, -2.3515e-02,  1.4295e-02, -2.8719e-01,\n",
      "        -8.6534e-02, -4.8978e-02,  1.4339e-02, -4.3535e-02,  7.6667e-03,\n",
      "        -3.5367e-02, -7.8812e-02,  3.0808e-02, -1.2481e-02,  3.1843e-02,\n",
      "        -2.5964e-02, -2.1562e-01,  1.7065e-02,  7.3113e-03,  3.8912e-02,\n",
      "        -1.4140e-03,  5.8306e-02, -4.2240e-02,  2.0156e-02,  3.0853e-02,\n",
      "         2.2608e-02,  6.6672e-03, -8.4194e-02,  4.6082e-02, -3.0741e-02,\n",
      "        -1.7691e-01,  4.8239e-02,  3.0545e-02, -9.9982e-02,  2.7956e-03,\n",
      "         3.9878e-04, -6.0199e-02,  1.1198e-02, -2.9985e-02, -4.8469e-02,\n",
      "         4.9428e-02, -1.1055e-02, -1.8635e-02, -1.0337e-01,  3.4193e-02,\n",
      "        -6.2273e-02, -4.4477e-02,  5.2356e-02, -7.9155e-02,  8.9222e-03,\n",
      "         8.0846e-03,  3.2135e-02,  2.2505e-03, -1.5146e-02, -6.0775e-03,\n",
      "         1.5279e-02, -3.7764e-02, -7.7088e-02, -1.6166e-02, -1.7211e-02,\n",
      "        -4.6248e-02,  3.3876e-03,  2.4542e-02, -2.4370e-02,  1.0853e-02,\n",
      "        -5.2227e-02,  1.5720e-02, -3.4891e-02,  2.7531e-02,  3.6833e-02,\n",
      "         2.7742e-02, -3.2197e-02,  3.7338e-02,  2.9959e-02,  1.2853e-02,\n",
      "        -5.4695e-02, -7.4453e-02, -1.0268e-01, -1.3039e-02,  1.2463e-02,\n",
      "        -2.1741e-01, -3.5742e-02, -6.4694e-04, -3.3158e-02, -3.8280e-02,\n",
      "        -8.1904e-02, -8.8076e-02, -1.4040e-01, -1.2469e-02, -4.1230e-02,\n",
      "        -1.3403e-02, -2.2853e-02, -2.0897e-02,  3.6801e-02, -2.4076e-02,\n",
      "        -4.2489e-03, -1.3447e-02,  5.8126e-03,  3.6704e-03,  1.5820e-02,\n",
      "        -5.8196e-04, -2.5905e-02,  6.3786e-02, -3.6843e-02, -5.7691e-02,\n",
      "         1.1508e-02,  2.1915e-02, -2.7642e-02, -4.9881e-03, -3.3924e-02,\n",
      "         6.9477e-03, -1.1831e-02, -2.3873e-02, -1.5719e-02, -5.4171e-01,\n",
      "         2.0473e-03,  5.1039e-03, -2.9809e-02, -2.8510e-03, -2.6571e-02,\n",
      "         1.3011e-02,  6.4490e-02,  4.8588e-03, -3.6543e-02, -3.2381e-02,\n",
      "        -2.6897e-02, -1.7449e-03,  2.2843e-02, -3.6797e-02, -2.3686e-02,\n",
      "        -4.2493e-02, -2.0871e-02, -6.6690e-03, -5.9443e-02,  5.5651e-03,\n",
      "         7.8415e-02, -3.7548e-03,  1.0176e-02,  2.7467e-02, -3.1273e-02,\n",
      "         2.6020e-02,  3.4414e-02,  3.3204e-02, -3.5509e-02,  1.5011e-02,\n",
      "        -3.3707e-02, -5.4149e-02,  2.1971e-02, -1.4159e-02, -1.4878e-02,\n",
      "         8.7128e-02,  1.2874e-02, -8.2085e-02, -1.4227e-02, -2.6410e-02,\n",
      "        -1.0860e-02, -2.9290e-02, -4.2289e-02,  4.2066e-02,  8.6005e-03,\n",
      "        -7.2877e-03,  1.4588e-02,  1.8026e-02,  6.6256e-02,  7.4310e-02,\n",
      "         2.1708e-02, -1.1266e-03, -2.6645e-02, -5.0119e-02, -2.0050e-02,\n",
      "        -1.1748e-01, -1.4646e-02, -1.6369e-02,  3.1214e-02, -3.6592e-02,\n",
      "        -2.6848e-02, -3.8445e-02,  2.5315e-03, -7.7974e-02,  9.6188e-04,\n",
      "         3.7251e-02, -4.3087e-02,  5.2107e-02,  1.2415e-02,  3.3955e-02,\n",
      "         1.1495e-02, -4.3169e-02, -1.1853e-01, -4.0755e-03,  1.6915e-02,\n",
      "        -3.2491e-02,  5.3647e-02, -1.5297e-03, -3.4573e-02,  1.7684e-02,\n",
      "        -6.4385e-03,  5.4559e-03, -7.1017e-04,  1.3020e-02, -3.8720e-02,\n",
      "        -6.6809e-01, -9.7386e-03, -1.0957e-01, -2.7821e-02, -7.3163e-03,\n",
      "         8.6562e-02,  2.3274e-02,  7.6269e-02, -5.5328e-02, -3.9678e-02,\n",
      "        -5.1577e-02, -8.0577e-02, -5.5639e-02,  7.5139e-03, -2.9101e-02,\n",
      "        -2.2610e-02,  5.9505e-03, -4.3095e-02,  4.0140e-02,  1.8034e-02,\n",
      "        -9.2512e-02,  9.4832e-02, -6.6311e-03, -5.5224e-02, -2.2735e-02,\n",
      "         4.5156e-02,  3.5932e-02, -2.1979e-02, -3.7774e-02, -3.2931e-02,\n",
      "         5.2237e-02, -1.7440e-03, -9.1793e-03,  1.7093e-02, -4.7521e-02,\n",
      "        -2.8153e-03, -8.4660e-02, -1.8806e-01, -2.5625e-02, -1.0211e-02,\n",
      "        -4.5906e-02,  2.9120e-02, -8.6569e-01, -2.5128e-02, -1.0161e-01,\n",
      "        -1.1388e-02, -3.3762e-02, -1.5685e-03, -1.9455e-02,  4.1842e-03,\n",
      "         3.3682e-02, -3.4700e-02, -1.5593e-02, -7.6662e-02, -3.3994e-02,\n",
      "         8.9309e-03,  3.1762e-02,  1.1229e-02,  4.4812e-02, -1.3256e-02,\n",
      "        -6.4332e-02, -5.6057e-02,  1.4306e-02,  2.8415e-03,  5.4036e-02,\n",
      "         4.6846e-02,  2.7745e-03,  1.7436e-02,  8.6637e-05,  2.0136e-02,\n",
      "        -1.6827e-02, -2.8334e-02,  3.7818e-02, -1.2093e-02, -4.6998e-02,\n",
      "        -7.3345e-04,  3.1372e-02,  2.7453e-02,  1.4910e-02,  8.3032e-02,\n",
      "        -6.7714e-03, -7.6011e-03], device='cuda:0')\n",
      "tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0002,  0.0141, -0.0002],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [-0.0002, -0.0002, -0.0002,  ...,  0.0468, -0.0002, -0.0002],\n",
      "        ...,\n",
      "        [-0.0002, -0.0002, -0.0002,  ...,  0.0701, -0.0002, -0.0002],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0346, -0.0002]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0379, -0.8169,  0.2011,  0.1521,  0.1950,  0.4244,  0.0243, -0.2870,\n",
      "        -0.2707,  0.3395], device='cuda:0')\n",
      "Test Error for client master: \n",
      " Accuracy: 10.1%, Avg loss: 2.398820 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encoder 2\n",
    "flag = False\n",
    "m1 = None\n",
    "m2 = None\n",
    "for i in range(2):\n",
    "    # Master sends global parameters to the client\n",
    "    for client in clients:\n",
    "        client.set_parameters(master.model)\n",
    "        client.update_mean()\n",
    "    \n",
    "    # Clients are trained locally\n",
    "    for client in clients:\n",
    "        client.train()\n",
    "    \n",
    "    clients_data_protocol_2 = []\n",
    "    for client in clients:\n",
    "        final_vectors, mu, seed = client.get_encoded_2(k=1000)\n",
    "        print(seed)\n",
    "        clients_data_protocol_2.append((final_vectors, mu, seed))\n",
    "    \n",
    "    master.update_global_model_from_protocol_2(clients_data_protocol_2)\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        m1 = list(master.model.parameters())\n",
    "    else:\n",
    "        m2 = list(master.model.parameters())\n",
    "    master.test(test_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bc01adc7-334e-4585-80f8-6f411bfca689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[2.5442e-05, 2.5442e-05, 2.5442e-05,  ..., 2.5442e-05, 2.5442e-05,\n",
       "          2.5442e-05],\n",
       "         [2.5442e-05, 2.5442e-05, 2.5442e-05,  ..., 2.5442e-05, 2.5442e-05,\n",
       "          2.5442e-05],\n",
       "         [2.5442e-05, 2.5442e-05, 2.5442e-05,  ..., 2.5442e-05, 2.5442e-05,\n",
       "          2.5442e-05],\n",
       "         ...,\n",
       "         [2.5442e-05, 2.5442e-05, 2.5442e-05,  ..., 2.5442e-05, 2.5442e-05,\n",
       "          2.5442e-05],\n",
       "         [2.5442e-05, 2.5442e-05, 2.5442e-05,  ..., 2.5442e-05, 2.5442e-05,\n",
       "          2.5442e-05],\n",
       "         [2.5442e-05, 2.5442e-05, 2.5442e-05,  ..., 2.5442e-05, 2.5442e-05,\n",
       "          2.5442e-05]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-6.6256e-02, -3.4606e-02, -5.4255e-02, -3.5483e-02, -2.3226e-02,\n",
       "         -3.5855e-02, -1.0605e-02, -4.2455e-02, -3.7819e-02, -3.6189e-02,\n",
       "         -4.0422e-02, -9.4494e-03, -5.0297e-02, -1.0827e-02, -2.1747e-02,\n",
       "         -1.3506e-02, -3.8381e-02, -3.3967e-03, -4.2109e-02, -1.8381e-02,\n",
       "         -3.9867e-02, -8.6074e-03, -1.1790e-01, -1.8876e-02, -4.7605e-02,\n",
       "         -8.2704e-02, -1.7387e-02, -1.5982e-02, -1.8216e-02, -9.1649e-02,\n",
       "         -6.5051e-03, -1.8136e-01, -2.4645e-02, -1.1372e-02,  4.3235e-05,\n",
       "         -2.9036e-02, -4.1221e-02, -1.9482e-01, -5.9910e-02, -1.2944e-02,\n",
       "         -2.5052e-02, -2.4252e-02, -1.3251e-02, -1.8677e-02, -5.4886e-02,\n",
       "         -1.2672e-02, -3.3763e-02, -1.5155e-02, -5.5707e-03, -3.1260e-02,\n",
       "          4.8718e-03, -3.4352e-03, -4.5367e-03, -1.9095e-02, -2.8090e-02,\n",
       "         -5.5348e-02, -1.3815e-02, -2.4613e-02, -1.4779e-02, -3.1345e-01,\n",
       "          0.0000e+00, -1.0124e-01, -1.2904e-02, -7.4831e-02, -4.4817e-03,\n",
       "         -1.4636e-02, -3.8901e-02, -5.6035e-02, -9.9731e-03, -1.9902e-02,\n",
       "         -9.2437e-03,  8.6142e-03, -8.6127e-02, -2.3583e-02, -9.3151e-02,\n",
       "         -4.4966e-02, -4.0999e-02, -9.9606e-03, -3.2200e-02, -3.3644e-02,\n",
       "         -1.7210e-02, -8.8692e-02, -1.2700e-02, -1.2484e-02, -5.3554e-02,\n",
       "         -5.3961e-02, -1.9252e-02, -2.4848e-02, -1.6734e-01, -1.3673e-02,\n",
       "         -3.8536e-02, -9.0689e-03, -1.3225e-02, -4.3333e-02, -1.8494e-02,\n",
       "         -5.2181e-02, -3.7028e-02, -1.2826e-01, -4.2362e-02, -1.9167e-02,\n",
       "         -6.2630e-02,  1.7036e-03, -4.6811e-02, -3.8985e-02, -3.9381e-02,\n",
       "         -4.7157e-03, -5.4055e-03, -4.1271e-02, -2.2025e-02, -4.1813e-02,\n",
       "         -2.9499e-02, -3.6730e-02, -1.9756e-02, -4.9388e-02, -2.2465e-02,\n",
       "         -6.1236e-02, -3.4710e-02, -3.4785e-02, -1.2533e-02,  1.9188e-02,\n",
       "         -2.4253e-02, -2.6632e-02, -4.6798e-02, -4.2625e-02, -7.4023e-02,\n",
       "         -5.8175e-02, -5.9274e-02, -2.7252e-02, -5.0952e-03, -5.4587e-02,\n",
       "         -7.0654e-02, -5.5903e-02, -5.1690e-02, -2.3183e-02, -4.4728e-03,\n",
       "         -2.0432e-02, -3.8536e-02, -2.5581e-02, -1.1522e-01, -3.4489e-02,\n",
       "         -2.0931e-02, -4.3587e-02, -4.4156e-02, -1.2369e-02, -6.1726e-01,\n",
       "         -2.2133e-02, -2.4111e-02, -1.6791e-02, -5.3872e-02, -1.8954e-02,\n",
       "         -1.8115e-02, -5.8748e-06, -4.1475e-02, -4.9669e-03, -1.5899e-02,\n",
       "         -2.2885e-02, -7.3858e-03, -2.7634e-02, -1.6119e-01, -9.1452e-02,\n",
       "         -1.8962e-02, -7.4157e-02, -4.3692e-02, -4.1890e-02, -1.5042e-01,\n",
       "         -5.1000e-02, -4.7795e-02, -1.0066e-02, -2.2170e-02, -2.4791e-02,\n",
       "         -3.7279e-02, -2.6041e-02, -2.5578e-02, -3.6465e-02, -1.0199e-02,\n",
       "         -1.0522e-02, -3.6252e-02,  5.8888e-04, -3.5962e-02, -1.9156e-02,\n",
       "         -1.7968e-02, -7.9129e-03, -2.8494e-02, -3.5557e-02, -1.2166e-01,\n",
       "         -5.1475e-02, -2.2938e-02, -1.7640e-02, -3.2392e-03, -6.6965e-03,\n",
       "         -1.0228e-01, -1.6499e-04, -3.9140e-02, -7.7236e-03, -1.7261e-02,\n",
       "         -7.8493e-03, -5.9585e-02, -5.8834e-03, -1.9353e-02, -1.3972e-02,\n",
       "          6.0999e-04, -1.3702e-01, -3.6308e-02, -8.6064e-04, -2.6451e-02,\n",
       "         -2.0863e-01, -5.4196e-02, -6.9084e-02, -6.2169e-02, -1.8189e-01,\n",
       "         -4.6169e-03, -1.8154e-02, -1.5931e-02, -1.2571e-01, -5.0573e-02,\n",
       "         -7.2801e-01, -4.9478e-02, -3.8415e-02, -2.3841e-02, -3.3351e-02,\n",
       "         -2.6433e-02, -2.3202e-02, -7.6389e-02, -3.9113e-02, -3.2225e-02,\n",
       "         -3.5202e-02,  2.5248e-04, -3.8034e-01, -9.2091e-03,  6.2633e-03,\n",
       "         -7.7947e-03, -4.9657e-02, -1.6833e-02, -5.5185e-02, -1.9287e-03,\n",
       "         -2.2650e-02, -4.7505e-02, -2.7317e-02, -3.0611e-02, -5.3676e-03,\n",
       "         -4.8034e-02, -2.2274e-02, -6.0927e-02, -4.1946e-02, -2.6579e-02,\n",
       "         -1.5079e-02, -8.6951e-02, -4.3411e-02, -2.1995e-02, -1.6460e-01,\n",
       "         -6.8065e-02, -1.0366e-02, -4.4942e-02, -5.0730e-02, -2.1042e-02,\n",
       "         -1.7093e-02, -1.9892e-02, -3.3312e-02, -1.3027e-02, -1.0534e+00,\n",
       "         -6.5590e-02, -2.0190e-02, -4.5187e-02, -8.9776e-02, -9.0162e-02,\n",
       "         -4.4721e-02, -2.7424e-02, -6.4319e-02, -5.3342e-02, -6.9230e-03,\n",
       "         -5.2951e-03, -2.8297e-02, -3.6387e-01, -1.2330e-02, -6.5978e-02,\n",
       "         -7.1057e-03, -2.3361e-02, -8.0533e-02, -2.0228e-02, -3.7453e-02,\n",
       "         -1.8954e-02, -4.9998e-02, -2.2271e-02, -1.8652e-02, -5.8894e-03,\n",
       "         -6.2659e-02, -3.2248e-02, -6.2917e-02, -1.2465e-02, -2.3317e-02,\n",
       "         -3.5068e-02, -2.1623e-02, -6.0076e-01,  3.7167e-03, -4.4073e-02,\n",
       "         -2.1419e-01, -1.0977e-02, -3.9119e-02, -6.1201e-03, -2.4280e-02,\n",
       "         -2.9257e-02, -9.2662e-03, -3.8024e-02, -6.5643e-02, -6.8685e-03,\n",
       "         -3.9018e-02, -4.6907e-02, -2.4883e-02, -1.8040e-02, -2.2939e-02,\n",
       "         -1.4664e-02, -7.7323e-02, -9.9589e-02, -1.6484e-02, -1.5099e-02,\n",
       "         -4.0456e-02, -3.0929e-02, -1.2835e-01, -1.8546e-02, -1.8938e-02,\n",
       "         -3.4970e-02, -5.6681e-02, -1.0025e-02, -1.4267e-02, -1.6258e-02,\n",
       "         -7.4451e-03, -2.2329e-02, -2.8595e-01, -2.6042e-02, -1.8469e-02,\n",
       "         -2.7442e-02, -1.7627e-01, -1.8924e-02, -4.8770e-02, -1.5271e-01,\n",
       "         -5.6588e-03, -2.9590e-02, -1.1130e-02, -2.1926e-02, -1.6667e-01,\n",
       "          2.1448e-03, -1.9606e-02,  1.2727e-03, -5.9317e-02, -1.3374e-02,\n",
       "         -4.9628e-02, -6.1723e-03, -2.4941e-02, -7.0783e-03, -2.3680e-02,\n",
       "         -6.9263e-03, -3.4911e-02, -2.8726e-02,  1.3623e-03, -2.4218e-02,\n",
       "         -4.1777e-02, -3.0000e-02, -5.7624e-03, -1.3149e-02, -2.7104e-02,\n",
       "         -4.5708e-02, -4.9816e-02, -1.5034e-02, -2.2866e-02, -3.7899e-02,\n",
       "         -2.5794e-02, -1.3559e-03, -5.9810e-02, -2.4835e-01, -4.3552e-02,\n",
       "         -1.5033e-02, -5.9068e-03, -2.6875e-03, -5.6374e-02, -1.1709e-02,\n",
       "         -2.6699e-01, -1.7970e-02, -2.2313e-02, -5.1914e-02, -7.2677e-03,\n",
       "         -7.9860e-03, -3.2723e-03, -1.8001e-02, -2.2342e-02, -2.2456e-02,\n",
       "         -3.7243e-02, -2.9143e-02, -1.6516e-02,  4.8711e-03, -2.9778e-02,\n",
       "         -3.3132e-02, -7.3392e-02, -3.2101e-02, -1.6564e-02, -3.6496e-02,\n",
       "         -9.4714e-03, -7.4349e-02, -3.0213e-02, -2.2841e-01, -2.2456e-02,\n",
       "         -2.9046e-02, -5.7352e-02, -7.8582e-02, -1.6246e-02, -4.9299e-02,\n",
       "         -2.0872e-02, -2.2308e-02, -5.6579e-02, -9.3654e-02, -7.5677e-03,\n",
       "         -2.0475e-03, -2.7685e-02, -3.3079e-02,  7.3061e-03, -9.6452e-03,\n",
       "         -2.1422e-02, -2.3855e-02, -1.9386e-02, -5.9480e-02, -4.1046e-01,\n",
       "         -3.8603e-02, -8.0721e-03, -1.3301e-02, -7.3471e-03, -2.4981e-02,\n",
       "         -6.5430e-02, -5.9496e-02, -4.3241e-03, -5.8142e-02,  7.2437e-04,\n",
       "         -1.7501e-02, -1.8747e-02, -8.6481e-03, -4.9710e-02, -3.8752e-02,\n",
       "         -3.1074e-02,  5.1225e-03, -2.1980e-02, -4.2494e-02, -1.3517e-02,\n",
       "         -2.2042e-02, -8.3082e-03, -1.7804e-02, -6.5122e-02, -1.7527e-01,\n",
       "         -2.0814e-03, -3.9861e-02, -5.0421e-02, -2.5856e-02, -4.7229e-01,\n",
       "         -3.4138e-02, -6.0684e-02, -1.6996e-02, -4.7415e-02, -3.6915e-02,\n",
       "         -3.4631e-02, -3.1524e-01, -3.6426e-02,  9.6393e-04, -6.0880e-02,\n",
       "         -4.0670e-02, -1.5670e-02, -1.2541e-01, -1.8510e-02, -6.5505e-02,\n",
       "         -5.0397e-02, -3.1701e-03, -1.6256e-02, -1.4671e-01, -1.5594e-02,\n",
       "         -3.2137e-02, -5.8987e-02, -3.7358e-02, -4.8825e-02, -2.8464e-02,\n",
       "         -3.2553e-02, -2.5744e-02, -9.5517e-02, -7.4099e-03, -1.0093e-01,\n",
       "         -5.2520e-02, -4.7801e-02, -4.1320e-02, -3.7615e-02, -1.7766e-02,\n",
       "         -3.2217e-02, -2.4358e-02, -1.6642e-02, -2.3224e-02, -8.5319e-02,\n",
       "         -1.3530e-02, -1.8165e-02,  3.1647e-02, -3.2554e-02, -1.6157e-02,\n",
       "         -4.2086e-02, -4.5673e-02, -2.7383e-01, -2.9519e-02, -4.6203e-02,\n",
       "         -1.2901e-02, -6.0257e-03, -5.5502e-03, -3.8792e-02, -4.0598e-02,\n",
       "         -1.4625e-02, -3.2886e-02, -5.0100e-02, -4.9353e-02, -2.9523e-02,\n",
       "         -7.4461e-02, -1.1634e-01], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[4.9092e-05, 4.9092e-05, 4.9092e-05,  ..., 4.9092e-05, 4.9092e-05,\n",
       "          4.9092e-05],\n",
       "         [4.9092e-05, 4.9092e-05, 4.9092e-05,  ..., 4.9092e-05, 4.9092e-05,\n",
       "          4.9092e-05],\n",
       "         [4.9092e-05, 4.9092e-05, 4.9092e-05,  ..., 4.9092e-05, 4.9092e-05,\n",
       "          4.9092e-05],\n",
       "         ...,\n",
       "         [4.9092e-05, 4.9092e-05, 4.9092e-05,  ..., 4.9092e-05, 4.9092e-05,\n",
       "          4.9092e-05],\n",
       "         [4.9092e-05, 4.9092e-05, 4.9092e-05,  ..., 4.9092e-05, 4.9092e-05,\n",
       "          4.9092e-05],\n",
       "         [4.9092e-05, 4.9092e-05, 4.9092e-05,  ..., 4.9092e-05, 4.9092e-05,\n",
       "          4.9092e-05]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-8.2244e-03, -4.9875e-02, -4.1031e-02, -6.6450e-02, -4.7305e-02,\n",
       "         -5.6901e-02, -5.1818e-02, -5.0561e-04, -3.0747e-02, -3.6532e-02,\n",
       "         -3.8345e-02, -4.7880e-02, -3.4489e-02, -5.4249e-03,  7.0082e-03,\n",
       "         -3.5729e-02, -6.8882e-02, -1.0716e-02, -2.4825e-02, -4.1000e-03,\n",
       "         -6.1239e-02, -4.4749e-02, -3.5245e-02, -2.6096e-02, -5.5722e-02,\n",
       "         -4.5256e-02, -2.3421e-02, -3.7022e-02, -6.6523e-02, -2.3299e-02,\n",
       "         -6.7318e-02, -1.2943e-02, -5.9851e-02, -5.1290e-02, -3.7710e-02,\n",
       "         -6.1553e-02, -5.9130e-02, -5.1721e-02, -2.9439e-02, -1.2298e-02,\n",
       "         -1.9723e-03, -9.1498e-03, -1.7303e-02, -2.4156e-02, -6.2521e-02,\n",
       "         -4.5399e-02, -9.4987e-01, -4.6591e-02, -2.6489e-02, -5.9955e-03,\n",
       "         -3.4690e-02, -5.2070e-02, -5.6215e-02, -3.3659e-02, -1.7376e-01,\n",
       "         -6.0511e-03, -3.6901e-03, -2.5379e-02, -2.6569e-02, -1.2666e-02,\n",
       "         -1.4308e-02, -6.6455e-02, -6.2475e-02, -7.9104e-02, -5.1862e-02,\n",
       "         -3.1786e-02, -1.9525e-02, -5.3802e-02, -3.7683e-01, -6.2882e-02,\n",
       "         -5.4620e-02, -4.8450e-02, -4.4072e-03, -2.7794e-03, -2.3523e-02,\n",
       "         -2.9232e-02,  3.1965e-02, -3.5256e-03, -2.0321e-02, -3.8588e-02,\n",
       "         -4.5964e-01, -3.4043e-02, -2.4484e-02, -9.1932e-02, -6.6309e-03,\n",
       "         -1.0976e-03, -1.8817e-02, -3.8068e-02, -5.3587e-02, -2.8823e-02,\n",
       "         -9.0042e-02, -2.7577e-02, -4.6323e-02, -6.7764e-02, -4.6972e-02,\n",
       "         -1.5635e-02, -3.4243e-02, -4.8537e-02, -4.4880e-02, -4.5153e-02,\n",
       "          5.8859e-03, -9.0642e-02, -5.9069e-02, -8.5287e-02, -3.9297e-02,\n",
       "         -1.2541e-02, -2.8891e-02, -3.4623e-03, -8.5377e-02, -5.2725e-03,\n",
       "         -4.6797e-02, -2.2808e-02, -1.6464e-02, -1.8947e-02, -5.9224e-02,\n",
       "         -6.4325e-02, -2.8241e-02, -7.8467e-02, -2.3001e-02, -4.1047e-02,\n",
       "         -1.8604e-02, -2.9029e-02, -9.9430e-03, -2.2572e-02, -3.1654e-02,\n",
       "         -3.4073e-02, -4.8567e-02, -1.9653e-02, -5.1652e-04, -5.2966e-02,\n",
       "         -1.5082e-02, -2.7902e-02,  2.4456e-03, -1.4903e-02, -9.4045e-02,\n",
       "         -3.5119e-02, -5.0083e-02, -8.1890e-03, -1.1074e-02, -4.7828e-03,\n",
       "         -8.2311e-03, -3.1963e-02, -1.7689e-01, -4.8166e-02, -5.9050e-03,\n",
       "         -5.1211e-02, -2.6043e-02, -5.6044e-02, -1.1020e-01, -3.7291e-02,\n",
       "         -4.9979e-02, -2.1881e-02, -1.4594e-01, -7.6033e-03, -2.3329e-02,\n",
       "         -1.7943e-02, -3.9356e-02, -2.6575e-02, -5.7090e-02, -7.0342e-02,\n",
       "         -1.4757e-01, -1.3800e-02, -1.6291e-02, -3.8495e-02, -7.9162e-03,\n",
       "         -7.2645e-02,  6.7259e-02, -2.0194e-01, -4.0147e-02, -2.3986e-02,\n",
       "         -1.2870e-02, -7.6659e-02, -1.4788e-02, -2.4476e-03, -2.2545e-02,\n",
       "         -5.7726e-02, -2.4796e-01, -1.0081e-02, -1.3432e-02, -4.9194e-02,\n",
       "         -9.8563e-02, -4.2287e-02,  7.7719e-04, -1.9734e-02, -4.8899e-02,\n",
       "         -1.1593e-02, -5.9117e-03, -3.6687e-02, -1.7394e-03, -3.9215e-01,\n",
       "         -2.5493e-02, -6.8355e-02, -2.4169e-03, -6.4868e-01, -3.8944e-03,\n",
       "         -5.1151e-02, -1.1851e-02, -7.8173e-03, -2.0934e-02, -3.9177e-02,\n",
       "         -5.8946e-02, -3.8032e-02, -5.8419e-02, -1.4468e-02, -3.0324e-02,\n",
       "         -4.1658e-02, -4.6039e-02, -6.7089e-02, -8.6821e-03, -2.5946e-02,\n",
       "         -1.9135e-02, -8.8453e-03, -4.1282e-02, -2.5961e-01, -6.9581e-02,\n",
       "         -1.0618e-02, -9.5542e-03, -5.5698e-02, -4.5123e-02, -2.7390e-01,\n",
       "         -3.2606e-02, -4.2197e-02, -6.4883e-02, -6.7405e-02, -1.7097e-02,\n",
       "         -2.4104e-02, -3.2842e-02, -2.9678e-02, -1.9693e-02, -4.1916e-04,\n",
       "         -9.5303e-03, -4.8639e-02, -2.8088e-02, -3.5095e-02, -3.7149e-01,\n",
       "         -1.0953e-01, -2.2696e-02, -2.5957e-02, -2.5916e-02, -3.5317e-02,\n",
       "         -2.5790e-02, -9.0370e-02, -2.3934e-02, -1.8475e-02, -5.3881e-02,\n",
       "         -5.3473e-02, -1.9568e-01, -7.4517e-02, -3.7207e-02, -1.0127e-02,\n",
       "         -1.9521e-02, -5.4720e-03, -6.6093e-02, -3.1935e-02, -1.0405e-02,\n",
       "         -2.1266e-02, -3.1480e-02, -9.4267e-02, -6.9288e-03, -2.9660e-02,\n",
       "         -1.8700e-01, -3.1168e-02, -9.7850e-03, -9.2669e-02, -2.8468e-02,\n",
       "         -5.0520e-02, -8.6497e-02, -2.5470e-02, -1.1209e-02, -2.7074e-03,\n",
       "         -7.3574e-03, -8.3556e-02, -4.7814e-03, -8.1598e-02, -3.3836e-02,\n",
       "         -4.3124e-02, -1.0440e-02, -1.5901e-02, -1.0042e-01, -2.6091e-02,\n",
       "         -2.2060e-02, -3.6569e-02, -8.2768e-02, -4.2043e-02, -4.6315e-02,\n",
       "         -5.5419e-02, -7.7880e-02, -8.4079e-02, -6.2228e-02, -4.7829e-02,\n",
       "         -3.2810e-02,  0.0000e+00, -9.0832e-03, -6.0088e-02, -3.5240e-02,\n",
       "         -2.3912e-02, -1.7006e-02, -5.9765e-02, -2.2913e-02, -1.2746e-02,\n",
       "         -3.0913e-02, -5.0441e-02,  1.2788e-03, -8.2713e-03, -5.0539e-03,\n",
       "         -1.1572e-01, -7.4809e-02, -9.5274e-02, -3.8494e-02, -7.9987e-03,\n",
       "         -2.3952e-01, -3.9390e-02, -3.7935e-02, -4.3727e-02, -4.0318e-02,\n",
       "         -8.3361e-02, -1.7430e-01, -1.4612e-01, -8.9338e-03, -6.9758e-02,\n",
       "         -2.8651e-02, -2.4458e-02, -7.0374e-02, -1.8759e-02, -4.8878e-02,\n",
       "         -2.7761e-02, -2.5358e-02, -2.1171e-02, -2.9205e-02, -1.0910e-02,\n",
       "         -1.4268e-02, -4.0862e-02, -2.0364e-03, -2.2969e-02, -9.2074e-02,\n",
       "         -3.6460e-02, -2.5822e-02, -8.2862e-02, -2.3831e-02, -5.8271e-02,\n",
       "         -2.3407e-02, -2.0960e-02, -4.6079e-02, -7.4031e-02, -5.4807e-01,\n",
       "         -1.3360e-02, -6.2359e-02, -2.6928e-02, -3.8824e-03, -3.4778e-02,\n",
       "         -3.8449e-02, -6.7911e-03, -5.5846e-02, -3.2564e-02, -3.3696e-02,\n",
       "         -2.9576e-02, -7.0921e-03, -5.4219e-02, -7.4643e-02, -7.6122e-02,\n",
       "         -5.1283e-02, -2.9414e-02, -3.2093e-02, -6.9913e-02, -4.3254e-02,\n",
       "         -2.1088e-02, -3.6349e-02, -6.1047e-03, -3.5832e-02, -2.6970e-02,\n",
       "         -1.1049e-02, -1.6967e-02, -2.7588e-02, -1.8724e-02, -9.6390e-03,\n",
       "         -3.6683e-02, -5.0223e-02, -1.2805e-02, -5.6130e-02, -4.8946e-03,\n",
       "         -5.7801e-03, -1.4260e-03, -6.4712e-02, -3.7177e-02, -3.5266e-02,\n",
       "         -1.4617e-03, -4.9755e-02, -5.3877e-02, -1.7294e-02, -1.0216e-03,\n",
       "         -2.3862e-02, -2.9592e-02, -3.8481e-03, -8.7145e-03, -3.2885e-03,\n",
       "         -1.6942e-02, -6.4050e-03, -2.6656e-02, -3.4928e-02, -1.4520e-02,\n",
       "         -1.1503e-01, -6.7307e-02, -3.8978e-02, -3.4051e-02, -3.0439e-02,\n",
       "         -1.4609e-02, -8.4935e-03, -7.9626e-03, -4.1916e-02, -4.0840e-02,\n",
       "         -1.4900e-02, -5.7372e-02, -1.3545e-02, -8.1779e-03, -1.9130e-03,\n",
       "         -6.4510e-03, -7.6716e-02, -9.1968e-02, -1.1421e-02, -3.2592e-02,\n",
       "         -6.6023e-02, -7.6535e-04, -2.8945e-02, -3.2648e-02, -2.0638e-02,\n",
       "         -1.5341e-02, -3.0800e-02, -2.6475e-02, -2.5283e-03, -4.9741e-02,\n",
       "         -6.9881e-01, -4.6011e-02, -7.5097e-02, -2.9783e-02, -3.7833e-02,\n",
       "         -9.1396e-05, -4.7246e-02, -3.7743e-03, -4.7028e-02, -5.7715e-02,\n",
       "         -9.1413e-02, -9.0451e-02, -6.9120e-02, -3.3573e-02, -4.8099e-02,\n",
       "         -3.3335e-02, -3.6906e-02, -3.8896e-02, -8.9656e-03, -1.3345e-02,\n",
       "         -1.7133e-01, -3.7526e-04, -2.2010e-02, -9.4099e-02, -2.7450e-02,\n",
       "         -3.7382e-02, -2.3953e-02, -2.6801e-02, -7.3809e-02, -4.0964e-02,\n",
       "         -4.8328e-03, -1.3400e-02, -1.1425e-04, -1.0648e-02, -4.3579e-02,\n",
       "         -4.7010e-02, -8.5714e-02, -2.1060e-01, -1.2823e-02, -1.4439e-02,\n",
       "         -6.5570e-02, -1.4017e-02, -9.0021e-01, -3.6128e-02, -8.4784e-02,\n",
       "         -4.3240e-02, -4.2933e-02, -5.4281e-02, -2.0686e-02, -3.3443e-02,\n",
       "         -2.0224e-02, -4.4133e-02, -7.7772e-02, -7.1975e-02, -6.0880e-02,\n",
       "         -2.1669e-02, -2.6904e-02, -2.6243e-02, -2.8772e-02, -4.3384e-03,\n",
       "         -5.1496e-02, -4.7976e-02, -2.5222e-02, -2.4754e-02, -4.1003e-02,\n",
       "          1.0183e-03, -5.2047e-02, -1.8743e-02, -2.3549e-02, -4.3032e-02,\n",
       "         -5.1772e-02, -7.1561e-02, -9.1331e-03, -3.3992e-02, -6.2838e-02,\n",
       "         -3.5333e-02, -1.6814e-02, -2.3710e-02, -2.7688e-02, -6.7608e-04,\n",
       "         -4.4888e-02, -4.9504e-02], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0003, -0.0003, -0.0003,  ..., -0.0003,  0.0000, -0.0003],\n",
       "         [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "         [-0.0003, -0.0003, -0.0003,  ...,  0.0111, -0.0003, -0.0003],\n",
       "         ...,\n",
       "         [-0.0003, -0.0003, -0.0003,  ...,  0.0000, -0.0003, -0.0003],\n",
       "         [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
       "         [-0.0003, -0.0003, -0.0003,  ..., -0.0003,  0.0000, -0.0003]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0932, -0.9176,  0.2410,  0.0583,  0.2654,  0.4415, -0.0029, -0.0343,\n",
       "         -0.5137,  0.6232], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e2e17f6d-4d40-4fd9-9cb6-b2ca283ae4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0119,  0.0179,  0.0064,  ..., -0.0062, -0.0387,  0.0264],\n",
       "         [-0.0016, -0.0247,  0.0323,  ...,  0.0325, -0.0031,  0.0219],\n",
       "         [ 0.0069,  0.0186,  0.0192,  ...,  0.0130, -0.0224,  0.0001],\n",
       "         ...,\n",
       "         [-0.0089, -0.0162, -0.0201,  ...,  0.0022,  0.0027, -0.0130],\n",
       "         [ 0.0312, -0.0130, -0.0255,  ..., -0.0427,  0.0132, -0.0063],\n",
       "         [ 0.0151, -0.0246,  0.0305,  ...,  0.0127,  0.0278,  0.0264]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 1.2529e-02, -4.6513e-02, -2.2060e-02, -1.3401e-01, -6.8725e-02,\n",
       "          2.1339e-03, -5.9777e-03, -3.7459e-02,  2.2330e-02, -3.8302e-02,\n",
       "         -1.4649e-05, -4.6191e-02, -9.5482e-02,  2.0120e-02, -9.8750e-03,\n",
       "         -3.2757e-02, -1.8433e-01, -9.3645e-02, -5.5934e-02, -5.7587e-02,\n",
       "         -1.1895e-01, -1.2388e-03, -6.8861e-02, -2.0461e-02, -2.1278e-02,\n",
       "         -8.1022e-02, -1.4796e-02,  1.8898e-04, -3.5278e-02,  3.1165e-02,\n",
       "         -7.7811e-02,  5.1968e-04,  9.5230e-04, -1.7101e-02, -1.0388e-01,\n",
       "          6.6247e-04, -9.1717e-02, -6.5444e-02, -4.7672e-03, -4.5477e-02,\n",
       "          2.7450e-02, -3.8403e-02, -2.0825e-03,  2.1622e-03, -9.1526e-02,\n",
       "         -9.4939e-03, -2.9669e-02, -1.1323e-01, -2.7693e-02,  7.1997e-03,\n",
       "         -6.1100e-02, -1.3464e-01, -7.8908e-03, -3.5094e-02,  2.5130e-02,\n",
       "         -3.9282e-02,  0.0000e+00, -6.3604e-02, -3.0153e-02, -3.9618e-02,\n",
       "         -1.2450e-02,  1.3693e-03, -1.0386e-01, -5.3951e-02,  1.0473e-03,\n",
       "          6.2159e-03,  1.1688e-02,  1.5730e-02,  1.2900e-02, -5.4088e-02,\n",
       "          7.9364e-05, -2.1279e-02,  9.9461e-03, -2.5651e-02, -3.9010e-02,\n",
       "         -1.1301e-01,  2.5499e-02, -3.3893e-02, -8.3653e-02, -4.9652e-03,\n",
       "         -1.3120e-01, -7.8942e-02,  2.6072e-03, -3.8410e-02, -1.9559e-02,\n",
       "         -1.1181e-01,  3.3393e-02, -3.3920e-02, -4.2062e-02, -5.1705e-02,\n",
       "         -3.6064e-02, -4.2880e-02,  8.9594e-03, -8.3930e-03, -3.3123e-02,\n",
       "         -2.8287e-02, -1.5874e-01,  0.0000e+00,  1.6007e-03, -7.8652e-03,\n",
       "         -1.4986e-02, -3.9068e-02, -2.9098e-02, -1.6988e-02, -7.7326e-03,\n",
       "         -5.7873e-02, -8.2097e-02, -5.7150e-02, -1.9920e-02, -5.0923e-02,\n",
       "         -8.6285e-03, -4.6661e-03, -3.8090e-02, -7.8730e-02, -1.3022e-01,\n",
       "         -1.5222e-02,  4.1417e-04, -9.6872e-02,  1.8312e-02,  5.0289e-02,\n",
       "         -1.8977e-01, -1.0306e-02, -8.9302e-02, -4.0810e-03, -4.7022e-02,\n",
       "         -7.9050e-02, -3.1667e-02, -2.5524e-04, -3.2327e-02, -8.2555e-02,\n",
       "          9.7467e-04, -9.0320e-03, -8.1026e-02,  3.5663e-02, -1.9776e-02,\n",
       "         -2.8822e-02, -1.4667e-02, -3.4340e-02, -6.5888e-02,  1.1857e-02,\n",
       "         -2.2688e-02, -5.8845e-02, -4.6318e-02,  4.0946e-03, -3.8164e-02,\n",
       "         -1.0143e-01, -4.6957e-02, -2.9907e-03, -2.7345e-01, -4.0688e-02,\n",
       "         -3.8803e-02, -4.7209e-02, -7.9425e-02, -2.2094e-03,  4.1411e-02,\n",
       "          1.7335e-02, -4.5515e-02, -5.7409e-02, -1.0200e-01, -6.1066e-02,\n",
       "         -5.8516e-02, -8.8181e-02, -1.2944e-02, -1.6229e-02, -5.1787e-02,\n",
       "         -2.9836e-02, -6.0654e-02,  0.0000e+00, -1.0540e-02, -3.2454e-02,\n",
       "         -1.0165e-01, -4.7943e-03, -2.9035e-02, -2.1142e-02, -2.4966e-02,\n",
       "         -6.2761e-02, -1.1411e-01, -1.3274e-01,  1.6267e-03, -2.5698e-02,\n",
       "         -6.3181e-02, -4.2314e-02, -5.1487e-04, -5.6965e-02, -3.4358e-02,\n",
       "          6.0414e-03, -6.8763e-02, -5.8064e-02, -1.4708e-02, -5.3084e-03,\n",
       "         -2.0734e-02,  1.2290e-02, -2.3077e-02, -3.2475e-02, -2.0007e-02,\n",
       "         -3.0418e-02, -1.0386e-02, -1.3762e-02, -1.6332e-02, -4.1035e-02,\n",
       "         -7.4994e-03, -2.8657e-02, -3.6386e-01, -3.1663e-02,  2.7095e-02,\n",
       "         -4.0695e-03, -1.0560e-02, -4.7387e-02, -4.0947e-02, -3.8236e-02,\n",
       "         -3.4412e-02, -2.9339e-02, -6.3138e-02, -9.2059e-02, -3.7147e-02,\n",
       "          4.5010e-03, -2.6748e-02,  4.1760e-02, -3.5045e-02, -3.2802e-02,\n",
       "         -4.6931e-02,  3.0937e-02, -4.3831e-02,  4.7163e-03, -2.8527e-02,\n",
       "         -4.7940e-02,  1.5522e-02, -4.4080e-02, -3.5393e-02, -2.2051e-02,\n",
       "          5.0163e-02, -9.7832e-02, -2.2536e-02, -1.3235e-02, -6.5989e-02,\n",
       "          4.1719e-03,  1.0092e-02,  5.1120e-04,  2.8020e-04, -2.7177e-02,\n",
       "         -2.8435e-02, -4.6704e-02,  1.1658e-05, -6.4155e-02,  1.3606e-02,\n",
       "         -5.1232e-02,  4.1076e-03, -2.7144e-02,  4.2485e-03, -2.4990e-02,\n",
       "         -1.3319e-02, -5.4049e-02, -3.0484e-02,  3.1091e-05,  1.4505e-02,\n",
       "         -4.3791e-02,  1.3887e-03, -6.1058e-02, -1.2347e-01, -3.9968e-02,\n",
       "         -3.9152e-02, -3.8582e-02, -2.4744e-01,  1.0931e-02, -2.0659e-01,\n",
       "          1.0621e-02,  1.0247e-02,  6.9979e-05,  4.1859e-02, -4.5321e-02,\n",
       "         -4.6041e-03,  2.1820e-04,  1.3021e-02, -8.7643e-02, -3.7202e-02,\n",
       "         -2.4995e-03, -1.5601e-01, -3.7892e-02,  2.0334e-02, -8.9366e-02,\n",
       "         -5.5191e-02, -6.9648e-02,  3.4449e-03, -4.3725e-02,  2.0965e-02,\n",
       "         -5.1668e-02,  6.1189e-02, -1.3075e-01, -1.5543e-02, -2.6109e-02,\n",
       "          1.2070e-02,  1.7536e-03, -1.2182e-03, -1.3422e-01, -4.2236e-03,\n",
       "         -3.0185e-03, -2.8804e-01, -9.7037e-02, -3.1690e-02, -4.1607e-02,\n",
       "          2.3019e-02, -1.0571e-02, -5.3538e-02, -9.9557e-03, -6.0609e-02,\n",
       "         -1.0123e-02, -1.0342e-01, -2.1374e-02, -1.4669e-02, -4.6084e-02,\n",
       "          5.6983e-03, -9.7968e-02, -4.4868e-02, -4.4270e-02, -2.1997e-02,\n",
       "         -1.2140e-02, -5.4963e-02, -4.5931e-02, -1.9121e-02, -1.3401e-02,\n",
       "          2.3976e-02, -5.3580e-03, -5.1362e-02, -6.0258e-02,  2.0082e-02,\n",
       "         -2.0151e-02, -3.7500e-02,  1.1721e-02, -2.1974e-02,  1.5550e-03,\n",
       "         -6.2181e-02, -1.0193e-01, -5.0313e-02, -2.0446e-02, -1.8008e-02,\n",
       "         -7.5047e-02, -5.3804e-02,  1.6244e-02, -9.1420e-02, -1.4698e-02,\n",
       "         -2.3400e-02, -2.5581e-02, -1.7596e-02, -7.5698e-02, -3.9176e-02,\n",
       "         -6.3911e-02,  1.6560e-02, -2.4185e-02, -3.8844e-02, -1.2777e-02,\n",
       "         -2.2229e-02, -2.5323e-02, -7.8171e-02, -2.5789e-02,  1.2120e-02,\n",
       "         -4.1078e-02,  1.9641e-02, -4.4263e-02, -1.4822e-02, -8.3650e-02,\n",
       "         -5.7121e-02, -3.7356e-02, -3.9301e-02, -2.6076e-02, -2.3107e-02,\n",
       "         -3.3068e-02, -8.3314e-02,  1.2909e-02, -8.9204e-02,  3.4415e-02,\n",
       "          1.1957e-02, -4.0364e-07, -1.1366e-02, -3.0600e-02, -2.4262e-01,\n",
       "          1.1410e-02, -4.8208e-02, -2.1752e-02, -1.4694e-01,  9.3072e-03,\n",
       "         -4.1499e-02, -3.1257e-02, -5.7466e-02, -1.0845e-01, -3.9848e-03,\n",
       "         -1.7246e-03, -7.0810e-02, -5.2340e-02, -2.3227e-02, -6.9590e-02,\n",
       "         -1.2886e-02,  2.6871e-02, -2.0621e-02, -1.7594e-02, -2.2191e-03,\n",
       "          1.7110e-02,  8.2187e-03, -2.2559e-02, -4.7293e-01, -8.5586e-02,\n",
       "         -2.6154e-02,  5.0737e-03, -5.3525e-02,  3.1261e-03, -1.1671e-01,\n",
       "         -7.3319e-03, -8.5169e-02,  1.1484e-01, -3.3944e-03, -4.0793e-02,\n",
       "         -4.1956e-02, -5.4458e-02, -2.4948e-02, -1.0148e-01, -1.8493e-02,\n",
       "         -3.0382e-02, -1.5988e-01, -2.7467e-02,  1.7559e-02, -1.0692e-01,\n",
       "         -2.2076e-03, -1.1313e-01, -5.4605e-02, -1.6743e-01, -6.5495e-02,\n",
       "         -3.3946e-02, -3.0112e-02, -2.8619e-02, -5.9500e-02, -6.5663e-02,\n",
       "         -3.9003e-02, -2.6404e-02,  3.0217e-02,  1.6067e-03, -9.6775e-02,\n",
       "          1.2705e-02, -7.4956e-02,  3.8535e-02, -3.4679e-03,  6.2091e-03,\n",
       "         -1.7160e-02, -2.3192e-02,  1.0636e-02,  8.9223e-03, -2.0979e-03,\n",
       "         -3.6928e-02, -1.5018e-02, -5.8502e-02, -3.5103e-02,  2.7504e-03,\n",
       "         -1.8570e-02, -5.0539e-02, -5.3470e-06,  3.8760e-03, -3.1096e-02,\n",
       "         -6.8817e-02, -2.7292e-03, -3.4861e-02, -3.7235e-02, -3.7710e-02,\n",
       "         -6.1489e-02, -7.5296e-02,  1.6623e-02, -3.5832e-02, -2.6682e-02,\n",
       "          4.5063e-02,  9.5891e-03, -4.8305e-02, -4.2926e-02, -4.4155e-02,\n",
       "         -3.3717e-02,  3.6313e-02,  3.0029e-02, -1.5351e-02, -1.2388e-02,\n",
       "         -3.0670e-02, -7.1751e-02, -2.9933e-02, -1.7955e-02, -5.7596e-03,\n",
       "          1.7595e-02, -2.9329e-02, -3.6722e-02, -1.7254e-01, -1.7746e-02,\n",
       "         -4.2998e-02, -8.3657e-02, -6.1052e-02, -2.1346e-03,  2.5067e-02,\n",
       "         -8.3313e-02, -2.8716e-02, -5.6074e-02, -2.1186e-02, -2.3718e-02,\n",
       "         -4.4539e-02, -2.4373e-02, -1.4273e-01, -6.8244e-02, -7.4117e-02,\n",
       "         -8.5970e-02, -5.3376e-02, -5.9872e-02,  4.8807e-02, -6.4412e-02,\n",
       "         -2.2547e-02, -1.5337e-03,  1.9747e-02, -8.8725e-02,  2.3774e-02,\n",
       "         -6.4423e-02, -3.8789e-02], device='cuda:0'),\n",
       " tensor([[ 0.0257, -0.0058, -0.0405,  ..., -0.0183,  0.0346, -0.0301],\n",
       "         [-0.0440, -0.0229, -0.0406,  ...,  0.0268, -0.0088,  0.0086],\n",
       "         [-0.0483,  0.0121,  0.0071,  ...,  0.0126, -0.0241, -0.0704],\n",
       "         ...,\n",
       "         [-0.0305, -0.0128, -0.0160,  ...,  0.0252,  0.0221, -0.0233],\n",
       "         [ 0.0373, -0.0362, -0.0122,  ..., -0.0216, -0.1044, -0.0396],\n",
       "         [-0.0272, -0.0280,  0.0357,  ..., -0.0370, -0.0099, -0.0181]],\n",
       "        device='cuda:0'),\n",
       " tensor([-8.1461e-02, -5.4697e-02, -7.5072e-02, -4.0853e-02, -1.4486e-01,\n",
       "         -6.7184e-02, -1.7543e-02, -7.3926e-02, -3.3317e-02,  1.3558e-01,\n",
       "         -4.5073e-02, -4.5556e-02,  8.7470e-02, -8.7776e-02, -2.9213e-02,\n",
       "         -7.0993e-02, -4.0726e-02, -4.7109e-02, -9.4030e-02, -9.7979e-02,\n",
       "          9.4749e-02, -2.9573e-02, -7.2668e-02, -1.3629e-01, -2.8088e-02,\n",
       "         -5.5758e-02,  9.8066e-02,  2.1452e-02, -1.9347e-02, -1.2226e-01,\n",
       "         -4.4973e-02, -2.8355e-02, -2.3860e-02, -1.6266e-02, -1.0952e-01,\n",
       "         -5.5085e-02, -8.0496e-02, -7.1836e-02, -1.1928e-01, -1.4758e-02,\n",
       "         -6.6407e-02, -2.6956e-02, -2.0147e-02,  8.7103e-02, -1.0710e-01,\n",
       "         -2.4384e-02, -9.3597e-02, -8.0856e-02, -2.5368e-02, -3.5495e-02,\n",
       "          6.0609e-03, -8.5963e-03, -1.1910e-01, -7.2813e-02, -2.3623e-02,\n",
       "          1.9231e-02, -6.5937e-02, -7.8564e-02, -5.9770e-02, -6.1400e-02,\n",
       "         -1.4380e-01, -4.0108e-02, -3.3426e-02, -1.0023e-01, -4.0294e-02,\n",
       "         -9.5991e-02, -8.1382e-02, -2.2948e-02, -1.0780e-01, -1.4959e-02,\n",
       "         -4.1822e-02, -7.5853e-02, -8.4086e-02, -1.4804e-01,  3.0394e-03,\n",
       "         -1.0212e-01, -7.1431e-03, -5.3717e-02, -7.2996e-02, -1.0440e-01,\n",
       "         -4.1476e-02, -2.0900e-02, -8.8793e-02, -3.7662e-02, -3.7682e-02,\n",
       "         -1.0047e-01, -4.8255e-02, -3.6956e-02, -2.2363e-01,  1.2380e-01,\n",
       "         -1.3680e-01, -4.5620e-02,  2.6844e-02, -5.6972e-02, -9.7059e-02,\n",
       "         -6.5073e-02, -7.4355e-02, -7.3722e-02, -1.1299e-01, -8.3599e-02,\n",
       "         -4.9490e-02, -1.0632e-01, -8.9787e-02, -9.1589e-02, -8.9708e-02,\n",
       "         -3.4549e-02,  6.3663e-02, -2.5730e-02, -3.4798e-03, -6.3680e-02,\n",
       "         -2.8188e-02, -4.2607e-02, -5.0096e-03, -4.5999e-02, -4.8908e-02,\n",
       "         -7.7907e-02, -3.4743e-02, -2.4745e-02, -1.5265e-02, -6.2553e-02,\n",
       "         -9.2298e-02,  9.8279e-03, -1.0256e-01, -5.2176e-02, -3.5334e-02,\n",
       "         -6.0352e-02, -1.2441e-01, -1.0805e-01, -4.6844e-02, -1.5421e-01,\n",
       "         -3.3670e-02, -4.3768e-02,  6.2042e-04, -5.6833e-02, -3.9342e-02,\n",
       "         -1.0656e-01, -2.3126e-02, -2.4261e-01, -6.9208e-02, -8.7990e-02,\n",
       "         -4.6083e-02, -8.9672e-02, -7.5914e-02, -3.3299e-02, -6.4755e-02,\n",
       "         -3.7542e-02, -6.0334e-02, -3.5699e-02, -9.1419e-02, -8.5379e-02,\n",
       "         -1.6054e-01, -1.6339e-02, -5.6778e-02, -5.1578e-02,  2.7596e-02,\n",
       "         -9.1542e-02, -6.7318e-02,  4.0722e-02, -4.7305e-02, -6.3794e-02,\n",
       "         -1.0632e-01, -1.4607e-01, -1.3459e-02, -8.5909e-02, -1.6749e-02,\n",
       "         -2.7984e-02, -1.1382e-01, -1.2168e-01, -2.0041e-02, -5.3256e-02,\n",
       "         -4.4726e-02, -6.7083e-03,  1.2369e-02, -3.3494e-02, -2.7070e-02,\n",
       "         -3.3633e-02, -3.6455e-02,  9.9305e-02,  1.0802e-01, -9.5357e-02,\n",
       "         -7.1840e-02, -1.0967e-01, -8.0051e-02, -4.7517e-02, -1.1603e-01,\n",
       "         -1.2145e-01, -2.3884e-02, -3.0558e-02, -7.5894e-02, -2.9948e-02,\n",
       "         -5.7038e-02, -1.2059e-02, -7.2068e-02, -2.8924e-01, -3.4556e-02,\n",
       "         -8.2994e-02, -8.6890e-02, -3.7653e-02, -7.9667e-02, -2.3529e-02,\n",
       "         -3.1294e-02,  7.9315e-02, -2.4332e-02,  9.8643e-02, -6.0986e-02,\n",
       "         -3.3714e-02, -3.4802e-02, -3.5880e-02, -5.3905e-02,  8.3021e-02,\n",
       "         -1.8804e-01, -2.6435e-01, -5.4177e-02, -2.2217e-02, -2.7008e-02,\n",
       "         -8.0259e-02, -1.7309e-01, -3.2865e-02, -6.9737e-02, -8.0407e-02,\n",
       "         -3.2389e-01, -8.1488e-02, -1.1023e-01,  1.2688e-01, -4.5715e-02,\n",
       "         -7.7917e-02, -1.3896e-02, -6.7934e-02, -1.0350e-01, -6.7399e-02,\n",
       "         -4.9209e-02, -1.5790e-01, -1.3668e-01, -6.2288e-02, -1.0105e-01,\n",
       "         -1.0169e-01, -6.6690e-02, -7.9869e-02, -3.0132e-02, -8.9202e-02,\n",
       "         -1.0375e-01, -1.2893e-01, -6.0063e-02, -1.9682e-02, -1.2027e-01,\n",
       "         -3.8248e-02, -3.0042e-02, -1.0892e-01, -9.9285e-02, -5.3955e-03,\n",
       "         -1.1222e-01, -4.2263e-02, -4.4504e-02, -2.1011e-02, -3.4939e-02,\n",
       "         -4.2552e-02, -7.7532e-02, -2.8215e-02, -1.5293e-01, -8.6291e-03,\n",
       "         -4.6750e-02, -2.6723e-02, -2.1077e-01, -7.2087e-02, -8.6003e-02,\n",
       "         -1.6910e-01, -5.6991e-02, -1.5169e-01, -3.0350e-02, -1.3454e-02,\n",
       "         -1.5424e-02, -6.1056e-02, -1.3149e-01, -1.7421e-02, -7.5054e-02,\n",
       "         -1.1686e-01, -1.2000e-01,  1.0816e-01, -9.6624e-02, -3.2544e-02,\n",
       "         -4.3432e-02, -2.8087e-01, -7.5747e-02, -8.5945e-02, -1.2823e-01,\n",
       "         -5.5735e-02, -2.0797e-02, -5.1803e-02, -1.9654e-02, -4.1699e-02,\n",
       "         -5.8297e-02, -1.2367e-01, -6.1705e-02, -4.7900e-02, -8.1270e-02,\n",
       "         -9.4385e-02, -4.1989e-02, -1.7622e-01, -6.7474e-02, -6.5223e-02,\n",
       "          1.2233e-01, -6.3284e-02, -5.3088e-01, -1.5801e-01, -1.5031e-01,\n",
       "         -5.1377e-02,  2.6244e-03, -1.4030e-01, -6.3817e-02, -5.2532e-02,\n",
       "         -8.5425e-02, -7.8576e-02, -5.8851e-02, -8.7061e-02, -3.1898e-02,\n",
       "         -2.7173e-01, -1.0179e-01, -2.9501e-02, -5.3170e-02, -9.1181e-02,\n",
       "         -7.1679e-02, -5.3112e-02,  1.8833e-02, -1.0223e-02, -1.5096e-01,\n",
       "         -4.7616e-02, -1.3398e-01, -4.1352e-02, -3.1722e-02, -5.4870e-02,\n",
       "         -5.3509e-02, -1.8127e-02, -1.1599e-01, -6.3087e-02, -7.0029e-02,\n",
       "         -1.3627e-01, -4.0282e-02, -3.9183e-02, -5.7873e-02, -8.5392e-02,\n",
       "         -6.8059e-02, -3.8172e-02, -6.5973e-02, -1.0722e-01, -1.2470e-01,\n",
       "         -1.9853e-01, -6.2224e-02, -1.6389e-01, -1.0113e-01, -5.0787e-02,\n",
       "         -6.8594e-02,  6.6686e-03, -1.3814e-01, -2.4157e-02, -7.1952e-02,\n",
       "         -2.7806e-02, -3.4041e-02, -6.7844e-02, -4.3467e-02, -3.9015e-02,\n",
       "         -3.9220e-02,  3.5357e-02, -1.3878e-01, -3.6770e-02, -2.5708e-02,\n",
       "         -4.6215e-02,  2.2753e-03, -1.8997e-01, -2.6833e-02, -1.0787e-01,\n",
       "         -2.8279e-02,  2.1112e-02,  8.5690e-03, -2.7441e-02, -6.8143e-02,\n",
       "         -3.6230e-02, -1.2994e-02, -7.7971e-02, -4.7376e-02,  1.3654e-02,\n",
       "         -8.5314e-02, -6.9243e-02, -1.0236e-01, -9.9641e-02, -1.2053e-01,\n",
       "         -4.1656e-04, -8.7833e-02, -4.9621e-02,  4.6506e-02, -5.2974e-02,\n",
       "         -6.2455e-02, -9.2700e-02, -2.5783e-02, -1.5860e-01, -2.5323e-02,\n",
       "         -1.2417e-01, -1.9047e-01, -9.3410e-02, -4.1165e-04, -2.1972e-01,\n",
       "         -5.9967e-02, -3.4570e-02, -3.5049e-02,  5.9891e-02, -1.4912e-01,\n",
       "         -4.8604e-02, -9.6593e-02, -3.6446e-02, -1.0899e-01, -8.2855e-02,\n",
       "         -4.1408e-02, -4.9710e-02, -5.5841e-02, -1.0697e-01, -2.4827e-03,\n",
       "          9.9164e-02,  5.0863e-02, -2.1309e-01, -1.3091e-01, -5.2788e-02,\n",
       "         -1.3457e-01, -9.0459e-03, -1.0915e-01, -1.1474e-01, -6.7804e-02,\n",
       "         -4.0835e-02, -6.5671e-02, -1.0921e-01, -2.8257e-02, -2.2624e-03,\n",
       "         -4.2810e-02, -4.3407e-02, -4.4528e-02,  1.2988e-02, -5.9855e-02,\n",
       "         -6.0893e-02, -2.3450e-02, -1.9931e-02, -2.5174e-02, -1.1258e-01,\n",
       "         -1.8239e-02, -1.8093e-02,  1.2557e-02, -1.1732e-02, -5.7315e-02,\n",
       "         -6.2791e-02,  2.0008e-02, -2.7874e-02, -3.5016e-02, -4.5896e-02,\n",
       "         -2.8107e-02, -4.0950e-02, -2.6069e-01, -2.8372e-02,  1.0841e-02,\n",
       "         -3.4765e-02, -7.1429e-02, -2.5330e-02, -6.8023e-02, -4.6436e-02,\n",
       "         -5.5900e-02, -1.1733e-01, -1.0160e-01,  2.2346e-02, -5.6698e-02,\n",
       "         -8.0861e-02, -8.6446e-02, -7.0900e-02, -1.2635e-01,  5.4068e-02,\n",
       "         -3.2544e-02, -5.3526e-02, -4.7894e-02, -6.2425e-03,  4.0557e-03,\n",
       "         -2.6905e-02,  2.4367e-02, -6.2613e-02, -6.1741e-02, -5.2721e-02,\n",
       "         -2.8058e-02, -4.3337e-02,  9.4795e-03,  3.4187e-02, -5.0370e-02,\n",
       "          3.0634e-02, -1.3802e-02, -8.6327e-02, -1.5213e-01, -8.9229e-02,\n",
       "         -6.6510e-02,  1.7221e-02, -4.4440e-02, -2.3359e-02, -1.0981e-02,\n",
       "          4.4409e-02, -3.0250e-02, -2.0754e-02, -2.5569e-02, -2.9113e-02,\n",
       "         -9.4198e-02,  2.2076e-01, -3.0050e-02, -5.6709e-02, -6.5942e-02,\n",
       "         -9.2714e-02,  8.7085e-03, -3.1209e-02, -5.0534e-02, -3.7158e-02,\n",
       "         -5.1947e-02, -8.0180e-02], device='cuda:0'),\n",
       " tensor([[-0.1030, -0.0409, -0.1821,  ..., -0.0578, -0.0644, -0.3656],\n",
       "         [-0.0068, -0.0338,  0.0503,  ...,  0.0641, -0.0532, -0.3248],\n",
       "         [-0.1987,  0.1222, -0.0018,  ..., -0.0169, -0.0756,  0.0245],\n",
       "         ...,\n",
       "         [-0.0329, -0.1305, -0.0763,  ..., -0.0155, -0.0152,  0.0562],\n",
       "         [-0.0771,  0.0050, -0.0254,  ...,  0.1681,  0.0448,  0.0317],\n",
       "         [ 0.0357,  0.0277, -0.0255,  ...,  0.0206, -0.0021,  0.0063]],\n",
       "        device='cuda:0'),\n",
       " tensor([-0.2660, -0.3408, -0.0927, -0.2752,  0.2033,  0.3667, -0.0909,  0.0576,\n",
       "          0.0306,  0.3804], device='cuda:0')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f90500bc-dd79-4fca-b658-631c250078d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for client master: \n",
      " Accuracy: 9.6%, Avg loss: 2.302585 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "master.test(test_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e6f229f0-ecaf-4274-bf1d-0ae481f367c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for client 0: \n",
      " Accuracy: 93.8%, Avg loss: 0.199948 \n",
      "\n",
      "Test Error for client 1: \n",
      " Accuracy: 94.3%, Avg loss: 0.184125 \n",
      "\n",
      "Test Error for client 2: \n",
      " Accuracy: 94.2%, Avg loss: 0.184488 \n",
      "\n",
      "Test Error for client 3: \n",
      " Accuracy: 94.6%, Avg loss: 0.170945 \n",
      "\n",
      "Test Error for client 4: \n",
      " Accuracy: 94.0%, Avg loss: 0.196233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clients)):\n",
    "    clients[i].test(test_dataloader, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc1a6f94-ffb5-459b-b493-434652d74af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0034, -0.0293,  0.0045,  ..., -0.0706, -0.0303, -0.0350],\n",
      "        [ 0.0277,  0.0182,  0.0111,  ..., -0.0082, -0.0259, -0.0036],\n",
      "        [-0.0215,  0.0046, -0.0207,  ...,  0.0268,  0.0262, -0.0042],\n",
      "        ...,\n",
      "        [-0.0049,  0.0225, -0.0007,  ...,  0.0260, -0.0093,  0.0071],\n",
      "        [ 0.0043,  0.0010, -0.0133,  ..., -0.0349, -0.0701, -0.0245],\n",
      "        [-0.0099, -0.0102, -0.0349,  ...,  0.0226,  0.0103, -0.0269]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-9.9580e-02, -1.2118e-02, -4.5072e-02,  2.2311e-02,  1.5570e-02,\n",
      "        -6.3918e-02, -4.1587e-02, -4.3540e-02,  1.0151e-02, -3.2280e-02,\n",
      "        -2.6119e-02, -6.0773e-03, -3.0981e-02, -2.0027e-03, -2.6738e-02,\n",
      "        -7.8128e-02,  3.8500e-02, -6.6534e-03, -3.7936e-02, -5.0390e-02,\n",
      "        -1.0271e-02, -1.7515e-02,  6.2471e-03, -1.5648e-02, -1.3823e-02,\n",
      "        -3.6772e-02, -1.3515e-02, -2.6886e-02, -8.3774e-03, -1.7551e-02,\n",
      "        -9.0413e-03,  1.0268e-02, -4.7208e-02, -5.4715e-02, -3.6182e-02,\n",
      "        -7.7890e-02, -2.1872e-02, -1.0282e-02, -2.2086e-02, -1.8517e-02,\n",
      "         9.3802e-03, -6.4244e-03, -1.6972e-02, -3.0769e-02, -1.3175e-01,\n",
      "         1.0394e-02, -1.4790e-02, -2.3586e-03, -5.8902e-02, -1.2791e-01,\n",
      "        -3.1731e-03,  3.1714e-02, -1.4717e-02,  2.7715e-02, -6.7719e-04,\n",
      "         1.7513e-02,  2.4180e-02,  2.1020e-02, -2.9967e-03, -1.9746e-02,\n",
      "        -1.6143e-01,  4.1556e-03, -6.5088e-02,  1.3819e-02,  1.0262e-04,\n",
      "        -5.1648e-02,  1.3633e-03, -1.4663e-02, -4.2874e-05, -2.3675e-02,\n",
      "        -5.4465e-02, -4.2824e-02, -7.8883e-02, -5.7501e-02, -3.8984e-02,\n",
      "        -6.9693e-02, -3.9774e-02, -1.1518e-02,  4.1758e-02, -1.4841e-01,\n",
      "         7.3040e-03, -9.4005e-03, -2.9364e-02, -5.9036e-02, -6.1954e-02,\n",
      "        -7.9506e-02,  4.1105e-02,  3.6612e-02, -9.0250e-02, -4.5223e-02,\n",
      "        -2.3244e-02, -3.6974e-02,  2.8703e-03, -4.1244e-03, -9.5911e-03,\n",
      "        -2.3813e-03,  8.5399e-05, -2.2669e-03, -1.2295e-02, -1.6992e-02,\n",
      "         1.0757e-02, -6.5258e-02, -9.2535e-02, -6.1776e-03, -8.0487e-02,\n",
      "        -3.8554e-02,  1.0960e-02,  9.7879e-03,  4.4983e-03, -2.6125e-02,\n",
      "        -5.3705e-02, -2.1541e-02, -2.4052e-02, -9.9454e-03, -2.3928e-02,\n",
      "        -5.9801e-02, -3.1081e-02, -5.8461e-02,  8.2740e-03, -3.9364e-03,\n",
      "        -1.3750e-01, -7.7454e-02, -9.1348e-03, -5.6280e-02, -2.9243e-02,\n",
      "         1.2124e-02, -4.0111e-02, -7.5854e-02, -3.6451e-02, -4.3319e-03,\n",
      "         2.2065e-02, -1.4782e-02,  1.7770e-02,  3.9097e-02, -9.4307e-03,\n",
      "        -3.6269e-02, -1.1193e-01, -4.6203e-03, -1.9479e-02, -1.6816e-02,\n",
      "        -2.7367e-02, -4.0985e-02, -2.1519e-02, -8.4123e-02, -3.5406e-02,\n",
      "         1.8794e-02,  1.8573e-02, -1.7197e-02, -8.6122e-03, -6.5879e-02,\n",
      "        -4.6162e-02,  4.3191e-02, -8.5090e-02,  2.3711e-02,  4.5780e-02,\n",
      "         1.6708e-02, -3.0144e-02, -1.4274e-02, -5.6020e-02, -4.4405e-04,\n",
      "         5.6389e-04, -3.1848e-03, -4.2650e-02, -2.3651e-02, -3.7089e-02,\n",
      "        -5.0776e-02, -5.3510e-02,  2.3605e-03,  5.3183e-03, -8.8860e-03,\n",
      "        -1.2633e-02, -3.1230e-02, -5.8256e-04, -6.5652e-03, -1.1331e-02,\n",
      "        -3.6265e-02, -8.9798e-03, -3.4254e-02,  2.0623e-02, -1.5910e-02,\n",
      "         1.3349e-02, -1.8922e-02, -7.1738e-02, -1.6717e-02, -4.9930e-02,\n",
      "        -3.0854e-02,  1.6317e-02,  1.0791e-02,  1.2272e-02, -3.5867e-02,\n",
      "         2.9524e-02, -2.6880e-02, -6.1705e-02, -2.3741e-02, -3.3966e-02,\n",
      "         1.3342e-02, -6.6307e-02, -5.0077e-02, -1.8956e-02, -6.6104e-03,\n",
      "        -9.6264e-03, -3.0572e-02, -3.8676e-02, -3.8436e-02, -8.1805e-04,\n",
      "        -2.9598e-03, -1.0168e-01, -1.7918e-03, -2.4390e-02, -2.7527e-02,\n",
      "        -1.3772e-02, -1.9238e-02, -1.6714e-02, -2.8037e-02, -2.8499e-02,\n",
      "        -3.1131e-03,  9.3940e-03, -3.9885e-02, -1.3848e-02, -2.9858e-02,\n",
      "        -1.5337e-02, -2.1278e-02,  1.1982e-02, -1.2877e-01, -2.6412e-02,\n",
      "        -3.6614e-02, -1.1383e-02, -1.9875e-02,  2.8427e-02, -7.2885e-02,\n",
      "         1.8318e-03, -2.7219e-02,  9.6537e-03, -2.0120e-02, -3.6827e-02,\n",
      "        -7.1006e-02,  2.1150e-02, -9.0707e-03, -6.4709e-02, -3.8181e-02,\n",
      "        -8.3590e-04,  3.5272e-03, -7.1517e-02,  1.1151e-02, -6.6784e-02,\n",
      "        -2.8779e-03,  3.0691e-02,  1.7634e-02, -1.5699e-01, -3.9792e-02,\n",
      "         2.7225e-03, -4.5837e-02, -1.9617e-02,  2.2589e-02, -6.8384e-02,\n",
      "        -7.6236e-02, -4.7645e-02, -2.2163e-02, -1.8724e-02, -6.7032e-03,\n",
      "        -2.6393e-02, -4.2711e-02,  1.3080e-02, -9.4855e-02, -5.6691e-02,\n",
      "        -3.8990e-03, -7.3418e-02, -5.5932e-02, -3.7084e-02, -2.5794e-02,\n",
      "         7.2087e-03, -2.8451e-02, -1.8788e-02, -5.6504e-03, -4.8697e-02,\n",
      "        -2.6774e-03, -1.6600e-02, -7.6661e-02, -3.8564e-02, -6.0150e-02,\n",
      "        -4.8336e-02,  2.2751e-02, -1.4043e-02, -6.2283e-05,  6.3535e-03,\n",
      "        -4.3039e-02, -4.1490e-02,  8.4748e-04,  1.8090e-02,  6.9188e-03,\n",
      "        -8.7125e-02,  2.8527e-02, -1.2533e-02,  2.5185e-02,  7.7631e-03,\n",
      "        -5.7886e-02,  2.6754e-02,  1.4265e-02, -4.7126e-02, -3.1957e-02,\n",
      "         4.1164e-03, -3.4389e-02, -2.1555e-04, -2.7719e-02, -5.5989e-02,\n",
      "         3.6533e-03, -4.4938e-02, -1.5182e-02, -5.1045e-02, -5.1456e-02,\n",
      "        -6.1068e-03,  1.7495e-03, -3.5723e-03, -2.0415e-02,  3.8467e-03,\n",
      "        -4.2681e-02, -1.4410e-02,  1.5443e-02, -2.0375e-03, -1.1912e-02,\n",
      "        -8.3568e-02, -1.1089e-02, -3.9779e-02, -6.4760e-02,  3.7813e-02,\n",
      "         0.0000e+00, -6.3478e-03, -1.0557e-01, -5.3090e-02, -4.9643e-02,\n",
      "        -5.6809e-02, -5.1752e-03, -3.4752e-02, -2.7263e-02, -1.0899e-02,\n",
      "        -4.6572e-02, -1.8757e-02, -9.3569e-02, -1.2921e-02,  2.6104e-02,\n",
      "        -2.1726e-02, -3.1918e-02, -3.8333e-02, -5.9838e-02, -3.5235e-02,\n",
      "        -2.5721e-02, -8.5186e-02,  1.7877e-03, -2.2349e-03, -1.0822e-02,\n",
      "         1.8098e-02, -1.8089e-02, -6.8930e-02,  1.0138e-02,  1.3809e-02,\n",
      "         3.1057e-02, -1.8589e-02,  1.4685e-02, -1.3829e-02, -5.6314e-02,\n",
      "        -5.0615e-02, -4.8789e-02, -6.5823e-02, -2.4391e-02, -3.0441e-03,\n",
      "        -4.7937e-02, -2.9999e-02,  3.7069e-02,  1.4740e-02, -3.0959e-04,\n",
      "         2.1193e-03, -5.7435e-02, -6.3907e-02,  3.8421e-02, -2.5099e-02,\n",
      "        -4.9158e-02, -2.7530e-02, -6.5704e-02, -4.9170e-02, -2.0965e-02,\n",
      "        -1.8873e-02,  2.4564e-03,  2.3695e-03, -2.3890e-03, -1.7846e-02,\n",
      "         8.0593e-03, -4.3824e-02, -7.8106e-02, -3.6985e-02,  9.8113e-03,\n",
      "         4.5328e-03, -2.5076e-02, -4.7455e-02,  1.3040e-02, -2.8599e-02,\n",
      "        -1.6731e-02,  2.8348e-02, -6.7456e-03,  7.1932e-03, -7.6034e-02,\n",
      "        -5.9355e-02, -7.3433e-02, -4.0423e-03, -1.0767e-01,  1.0090e-03,\n",
      "        -1.1773e-01, -1.0063e-01,  1.3051e-02,  4.0475e-02,  3.3811e-02,\n",
      "        -1.4490e-02,  8.8623e-03, -4.5451e-02, -5.2279e-02, -1.5991e-02,\n",
      "        -4.1670e-02, -5.8178e-02, -2.1115e-02,  1.3605e-02, -6.0441e-02,\n",
      "        -2.9680e-02, -5.8251e-02, -1.2944e-02, -2.5297e-02, -2.9035e-02,\n",
      "        -5.4929e-02,  1.4416e-02, -1.3737e-02,  1.7428e-02, -5.4484e-02,\n",
      "        -1.8263e-02, -4.0293e-02, -2.1512e-02,  1.7548e-02, -4.3551e-02,\n",
      "         3.8031e-02, -7.6529e-02,  4.3852e-03,  1.8358e-02, -3.0966e-02,\n",
      "         2.1602e-02,  2.8552e-02, -1.1724e-03, -1.0215e-02, -1.9625e-02,\n",
      "        -2.5006e-02, -2.3916e-02, -6.4237e-02, -2.0945e-02, -4.8839e-02,\n",
      "        -5.3981e-02, -2.9207e-02, -5.8210e-02, -2.1053e-02, -1.4003e-02,\n",
      "         2.9765e-02, -8.0686e-03, -5.0901e-02, -2.9101e-02,  4.8241e-02,\n",
      "        -3.6561e-03, -6.0573e-03, -8.4206e-03, -7.2685e-02, -2.0322e-02,\n",
      "        -1.7782e-02, -4.0810e-02,  2.9852e-02, -2.7055e-02, -9.9429e-03,\n",
      "         4.0553e-03, -5.4613e-02, -1.4602e-02, -3.2364e-02, -6.6012e-02,\n",
      "        -1.0559e-02, -4.8313e-02, -7.5223e-02, -3.6983e-02,  2.0702e-02,\n",
      "         1.9536e-02, -9.7447e-02,  5.8006e-03, -1.1602e-01, -3.4350e-02,\n",
      "         2.3085e-04, -2.8974e-02, -1.1291e-01,  1.1213e-02, -2.9316e-02,\n",
      "        -9.2542e-03,  2.9300e-02, -2.7275e-02, -8.6586e-03, -3.4449e-02,\n",
      "        -1.5493e-02, -7.2385e-04, -4.4018e-02, -9.9604e-03, -1.3359e-02,\n",
      "         1.3530e-02, -3.4099e-02, -4.0802e-03, -2.5632e-02, -5.4209e-02,\n",
      "        -1.4840e-02, -2.4798e-02, -1.2873e-02, -4.1240e-02, -1.6434e-02,\n",
      "        -1.0625e-02,  2.0340e-02], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-1.8401e-02,  6.5943e-03,  0.0000e+00,  ..., -5.7693e-03,\n",
      "         -3.8185e-02,  2.2193e-02],\n",
      "        [-3.0714e-02, -2.2234e-02,  1.0274e-02,  ...,  1.8626e-09,\n",
      "         -2.4750e-02, -3.4104e-02],\n",
      "        [ 2.1617e-02, -1.6724e-02, -3.7681e-02,  ...,  4.1922e-02,\n",
      "         -3.2596e-02, -3.3100e-02],\n",
      "        ...,\n",
      "        [ 3.2732e-02, -2.2665e-02,  3.9923e-02,  ..., -2.0206e-02,\n",
      "         -1.5635e-03, -2.1805e-02],\n",
      "        [-5.7202e-02, -2.8260e-02, -1.9250e-02,  ..., -1.2996e-02,\n",
      "         -2.9648e-02, -6.3859e-02],\n",
      "        [-5.9634e-02,  1.5108e-02, -5.2554e-02,  ...,  1.5910e-02,\n",
      "         -3.1294e-02,  1.8986e-02]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-8.5279e-02, -6.3379e-03, -2.1516e-02, -7.8326e-03, -8.5417e-02,\n",
      "        -1.9937e-02, -7.5083e-02, -3.9216e-02,  4.1903e-02, -2.7903e-02,\n",
      "        -6.7071e-02, -6.7313e-02, -4.2965e-02, -3.6700e-02, -2.4375e-02,\n",
      "        -7.1059e-02, -3.4581e-02, -5.4564e-02, -8.7931e-02, -6.7653e-02,\n",
      "         1.6477e-02,  1.1958e-02, -1.2920e-01, -4.5203e-02, -1.1040e-02,\n",
      "         1.0029e-01, -1.9121e-02, -9.4432e-05, -6.5515e-02,  9.3925e-02,\n",
      "        -1.3182e-02,  4.0319e-02, -3.1487e-02, -9.9087e-02,  4.1642e-02,\n",
      "        -5.7088e-02, -3.0340e-02, -4.0474e-02, -5.3313e-02,  2.3844e-02,\n",
      "        -1.2044e-01, -3.5405e-02, -5.6136e-03,  1.5752e-02, -7.8291e-02,\n",
      "        -4.8131e-02, -3.6838e-02, -4.5151e-02, -1.6391e-02, -1.3913e-02,\n",
      "         4.0802e-02, -4.7057e-02, -2.7458e-02,  4.1357e-03, -5.8576e-02,\n",
      "        -6.1350e-02, -5.2345e-02,  4.7123e-02, -1.3871e-01, -2.5500e-02,\n",
      "        -6.4655e-02, -2.0031e-02,  1.4677e-02, -5.4494e-02, -4.2520e-02,\n",
      "        -3.4417e-02, -5.5184e-02, -4.5202e-02, -6.0015e-02, -1.5080e-01,\n",
      "        -2.5267e-02, -4.6728e-02, -2.4571e-02, -6.9271e-02, -3.8454e-03,\n",
      "        -8.7927e-02, -6.8168e-02, -5.8542e-02, -6.6025e-02, -6.8891e-02,\n",
      "        -3.3794e-02, -3.6610e-02, -6.2604e-02, -8.2092e-02, -5.9604e-02,\n",
      "        -3.5236e-02,  3.2163e-02, -5.1894e-02, -6.5118e-02, -2.4381e-02,\n",
      "        -5.1043e-02,  2.0210e-02, -8.5124e-02, -2.2260e-02, -5.5197e-02,\n",
      "        -8.1479e-03, -4.3350e-02, -2.0190e-02,  7.7368e-03, -5.4540e-02,\n",
      "        -4.0220e-02,  9.2880e-02, -7.6468e-03, -1.4049e-02, -9.3279e-02,\n",
      "        -5.6938e-03,  7.1634e-03, -4.8862e-02, -4.4160e-02, -1.1670e-02,\n",
      "        -5.9870e-02, -3.2391e-02, -3.1814e-02, -7.3451e-02, -2.1821e-02,\n",
      "        -3.8208e-02, -4.6569e-02, -5.2161e-02, -4.0121e-02, -3.5804e-02,\n",
      "        -3.2332e-02, -7.1251e-03, -2.7819e-02, -2.3050e-02, -6.1362e-02,\n",
      "        -2.6297e-02, -2.9947e-02, -7.7245e-02, -6.7724e-02,  2.1433e-02,\n",
      "        -6.4351e-02, -7.9526e-02, -9.5523e-02, -4.6242e-02, -9.5085e-02,\n",
      "        -8.5059e-02,  4.0202e-02, -2.8651e-02, -2.1380e-02, -7.7980e-02,\n",
      "        -1.0608e-02,  1.2823e-01, -8.9631e-02, -5.7970e-02, -6.4427e-02,\n",
      "        -4.5847e-02,  2.1078e-02, -1.0751e-02, -8.6398e-03, -2.1105e-02,\n",
      "        -5.2471e-02, -1.7608e-02, -5.7940e-02, -5.0967e-02, -5.3403e-02,\n",
      "        -9.0447e-02,  2.0967e-03, -5.4488e-02, -6.2548e-02, -3.6686e-02,\n",
      "         2.3436e-02, -3.1988e-02, -8.3817e-02, -4.1744e-02,  1.7299e-02,\n",
      "        -4.6417e-02, -4.2972e-02, -2.5574e-02, -4.1984e-02, -3.5777e-02,\n",
      "        -1.8764e-03, -2.7952e-02,  1.9881e-02,  1.0000e-02, -1.1682e-01,\n",
      "        -8.4715e-02, -4.2148e-02,  1.6804e-02, -9.4473e-02, -6.2531e-02,\n",
      "        -4.5502e-02,  1.6218e-03, -7.3374e-02, -3.9236e-02, -4.7610e-02,\n",
      "        -4.1303e-02, -2.2508e-02, -8.4311e-03, -1.6747e-02, -5.3328e-02,\n",
      "        -1.2452e-02, -1.8392e-02,  2.3205e-02, -2.8197e-02, -4.5455e-02,\n",
      "        -5.9338e-02, -3.1156e-02, -3.9674e-02,  5.4054e-02,  2.3571e-02,\n",
      "        -4.9150e-02, -7.7957e-02,  6.6180e-02, -4.9229e-02, -1.8513e-02,\n",
      "        -1.0068e-02, -5.0321e-02, -4.1384e-02,  6.7470e-03, -4.8781e-02,\n",
      "        -4.5604e-02, -1.1416e-02, -7.9121e-02,  8.1157e-02, -5.2320e-03,\n",
      "        -7.3898e-02, -4.8328e-02, -5.4806e-02, -9.4905e-02, -3.7260e-02,\n",
      "        -3.1999e-02, -9.8514e-02,  1.1794e-02, -3.4455e-03,  1.3440e-02,\n",
      "        -1.1925e-02,  7.4159e-02, -2.6044e-02, -7.0327e-02, -5.1917e-02,\n",
      "        -6.7127e-03, -1.2984e-02, -4.5704e-02, -8.7567e-02, -6.2480e-02,\n",
      "        -1.9241e-02, -2.7858e-02,  6.7640e-03, -6.6563e-02,  2.2178e-02,\n",
      "        -2.4156e-02, -3.7848e-02, -8.1042e-04, -3.5972e-02,  6.4427e-03,\n",
      "        -1.0307e-01, -6.3821e-02, -2.7871e-02,  5.1545e-02, -6.6411e-02,\n",
      "        -1.9576e-02, -3.2926e-02, -6.8294e-02, -7.9526e-02, -4.8390e-02,\n",
      "        -3.7942e-02, -6.4245e-02, -4.0121e-02,  1.4183e-02,  5.7980e-03,\n",
      "        -1.7949e-02, -3.1353e-02, -3.0086e-02, -1.9133e-02,  2.1152e-01,\n",
      "        -1.9291e-02, -3.7959e-02, -2.8523e-02, -3.0648e-02, -9.0202e-02,\n",
      "        -4.3072e-02, -6.2717e-02, -2.5556e-02, -6.7986e-03, -2.0793e-02,\n",
      "        -4.3708e-02, -4.4388e-02,  1.7894e-02,  4.3110e-03,  4.7915e-02,\n",
      "        -3.3194e-02, -6.6836e-02,  3.2490e-02, -7.9291e-02, -3.4491e-02,\n",
      "        -4.6244e-02,  8.0748e-03, -7.9268e-02, -4.0051e-02,  8.7271e-03,\n",
      "        -5.2541e-02, -2.3859e-02, -2.4096e-02, -7.0176e-03, -6.3976e-02,\n",
      "        -1.0197e-01, -1.2023e-01, -2.5408e-03, -4.2191e-02, -4.8325e-02,\n",
      "         2.8797e-04,  5.0196e-02, -7.0874e-02, -5.3235e-02, -3.3434e-02,\n",
      "        -1.7712e-02, -1.8132e-02, -8.4125e-02, -4.8471e-02, -5.4691e-02,\n",
      "        -1.3721e-01, -3.7512e-02, -3.7001e-02, -3.0607e-02,  6.8089e-02,\n",
      "        -6.5191e-02,  2.5526e-02, -4.7992e-02,  6.1201e-02, -1.0214e-01,\n",
      "        -2.7369e-03, -2.8193e-02, -8.9632e-02,  4.7947e-03, -1.1305e-02,\n",
      "        -1.6495e-02, -1.1481e-01, -3.8039e-02, -3.3120e-02, -6.0587e-02,\n",
      "        -1.9465e-03, -3.1287e-02, -4.0174e-02, -5.7994e-02, -1.9178e-03,\n",
      "        -4.0529e-02, -1.9439e-02,  2.6720e-02, -4.1792e-02,  1.9039e-02,\n",
      "         2.5795e-02, -2.9296e-02, -6.8174e-02, -2.2704e-02, -3.2636e-02,\n",
      "        -5.7368e-02, -1.3037e-02, -6.8252e-02, -4.5457e-02, -2.5779e-02,\n",
      "        -5.9187e-02, -1.0746e-01,  2.1365e-02, -4.3123e-02, -7.9223e-02,\n",
      "        -7.2389e-02, -2.6019e-02, -6.1465e-02, -6.8104e-02, -5.7551e-02,\n",
      "        -3.5191e-02, -2.0372e-02, -3.2671e-02, -3.7357e-02,  3.0573e-02,\n",
      "        -6.3843e-03,  1.3913e-02, -5.5123e-02, -5.4768e-02, -7.3093e-02,\n",
      "         1.4624e-01,  4.5471e-02, -3.4053e-02, -2.0697e-02, -4.7712e-02,\n",
      "        -1.3046e-02, -3.3216e-02, -4.1289e-02,  7.5349e-04, -7.4676e-02,\n",
      "        -4.7874e-02, -7.8990e-02, -7.7046e-02, -4.7859e-02, -3.2952e-02,\n",
      "        -9.8376e-02, -3.6339e-02,  3.2810e-03, -6.4112e-03, -8.0861e-02,\n",
      "        -1.1716e-01,  6.9433e-02, -6.0486e-02, -5.8522e-02,  1.5557e-02,\n",
      "        -2.8127e-02, -6.2592e-02, -8.2079e-02, -4.0514e-02, -9.9727e-02,\n",
      "        -3.2305e-02, -2.1305e-02, -1.0496e-02,  1.0953e-03, -4.9721e-02,\n",
      "        -4.0556e-02, -4.2170e-02, -4.4394e-02, -1.0653e-01, -7.1137e-02,\n",
      "        -6.2361e-02, -4.0180e-02, -4.8568e-02, -4.7316e-03,  5.4375e-02,\n",
      "         3.3904e-02, -7.7564e-02, -5.0666e-02,  1.4580e-02, -5.9523e-02,\n",
      "        -3.9563e-02, -5.8380e-02, -7.7499e-03,  4.2036e-02, -1.7570e-02,\n",
      "        -2.0984e-02, -1.0265e-01, -3.0170e-02, -2.0647e-02, -6.2038e-02,\n",
      "        -3.7950e-02,  2.9882e-03, -4.1816e-02, -5.9382e-02, -1.3328e-02,\n",
      "        -1.3080e-02, -1.6272e-02, -3.3495e-02, -5.4277e-02, -9.7555e-02,\n",
      "        -2.6442e-02, -1.6229e-02, -3.4655e-02, -2.9664e-02, -3.5858e-02,\n",
      "        -9.2194e-02,  1.0539e-01, -3.8790e-02, -3.9882e-02,  3.5089e-03,\n",
      "        -3.1215e-03,  3.4635e-02, -3.7872e-02, -6.4406e-02, -7.0080e-02,\n",
      "         4.3953e-02, -1.1047e-01, -4.3694e-02, -4.4245e-02, -8.0473e-02,\n",
      "        -9.9607e-02, -6.5196e-02, -5.0155e-02, -5.2146e-03, -3.6319e-02,\n",
      "        -3.1010e-02, -1.1451e-01,  8.2528e-03, -7.6291e-02,  9.4278e-02,\n",
      "        -3.0155e-02, -2.7315e-02, -9.9481e-03, -4.8616e-02, -8.5935e-02,\n",
      "        -5.4428e-02, -8.8633e-03, -3.0679e-02,  4.7992e-02, -5.5011e-02,\n",
      "        -1.6047e-02, -3.9021e-02, -6.0407e-02, -3.0965e-02,  7.9067e-02,\n",
      "        -7.6771e-02, -5.4155e-02, -6.1073e-02, -4.4836e-02, -4.2035e-02,\n",
      "        -9.1360e-02, -5.8070e-02, -1.4107e-02,  6.0278e-03,  3.4327e-02,\n",
      "        -2.5914e-02,  5.0686e-02,  9.3047e-02, -4.0931e-02, -4.9302e-02,\n",
      "        -4.1473e-02,  2.5983e-02, -3.2185e-02, -4.7067e-02, -3.8924e-02,\n",
      "        -7.1810e-02, -6.8027e-02,  1.2672e-01, -1.5829e-03, -6.6627e-02,\n",
      "        -2.2097e-02,  1.6842e-02], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0019, -0.0412, -0.0079,  ..., -0.0269, -0.0464, -0.0266],\n",
      "        [ 0.0267,  0.0070, -0.0283,  ...,  0.0082, -0.1017, -0.0426],\n",
      "        [ 0.0015, -0.0747,  0.0071,  ..., -0.0321, -0.0453, -0.0573],\n",
      "        ...,\n",
      "        [ 0.0064,  0.0068, -0.0638,  ..., -0.0164,  0.0422, -0.0174],\n",
      "        [ 0.0545,  0.0420, -0.0222,  ..., -0.1164, -0.0009,  0.0230],\n",
      "        [-0.0257, -0.0311, -0.1011,  ..., -0.1142, -0.0136,  0.0687]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1796, -0.0290,  0.1349, -0.1809,  0.0168, -0.0645, -0.2499,  0.2269,\n",
      "        -0.0713,  0.0423], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139a4dd-cec1-419f-8750-138b833c5d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
