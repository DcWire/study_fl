{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7744187e-9a74-440b-95b8-557b723fc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import fastai \n",
    "from torchvision.transforms import ToTensor\n",
    "# from fastai.data.core import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.vision.all import Learner, Metric\n",
    "from fastai import optimizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5849ab-a4ca-4515-97b5-35c90615be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c4d276-b524-46c7-b31a-8324a4b2b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([256, 1, 28, 28])\n",
      "Shape of y: torch.Size([256]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b180ad30-e4fe-4af6-9367-d3e5b03bc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0af6c2a9-8714-4c3f-bf16-44b3b964ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 5\n",
    "train_size = len(training_data)\n",
    "# indices = list(range(train_size))\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED)\n",
    "indices = torch.randperm(train_size).tolist()\n",
    "\n",
    "subset_size = train_size // num_clients\n",
    "client_subsets = [] \n",
    "for i in range(num_clients):\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = start_idx + subset_size\n",
    "\n",
    "    if i == num_clients - 1:\n",
    "        end_idx = train_size\n",
    "\n",
    "    subset_indices = indices[start_idx:end_idx]\n",
    "    client_subsets.append(Subset(training_data, subset_indices))\n",
    "\n",
    "client_loaders = [DataLoader(sub, batch_size=batch_size, shuffle=True) for sub in client_subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "831d6af4-3ad3-4d67-8681-472ba8624385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits \n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "original_shapes = []\n",
    "for p in model.parameters():\n",
    "    original_shapes.append(p.shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1ab18bf1-90d6-4bde-a5fc-3ebb2766e207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-1.4421e-05, device='cuda:0'), tensor(0.0010, device='cuda:0'), tensor(-1.2502e-05, device='cuda:0'), tensor(0.0005, device='cuda:0'), tensor(-0.0003, device='cuda:0'), tensor(-0.0018, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "# We now have 5 different datasets, each with some sort of representation of the data that is unknown, ie, we have no \n",
    "# statistical information on the data that each of these clients would have\n",
    "# We now need to implement variations of the 3 protocols, namely, the encoding protocol, the communication protocol and the decoding protocol\n",
    "\n",
    "# For communication protocol for fixed size encoder, we set the seed. So the seed is communicated with the values. \n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Encoders\n",
    "def variable_size_encoder(grad_vectors, mu, p=0.1):\n",
    "    # Lets take p = 0.1\n",
    "    new_grad_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(grad_vectors)):\n",
    "            mask = torch.rand_like(grad_vectors[i], device=grad_vectors[i].device) < p\n",
    "            Y = torch.empty_like(grad_vectors[i], device=grad_vectors[i].device)\n",
    "            Y[mask] = (grad_vectors[i][mask] - mu[i] * (1-p))/p\n",
    "            Y[~mask] = mu[i]\n",
    "            new_grad_vectors.append(Y)\n",
    "    return new_grad_vectors\n",
    "\n",
    "def fixed_size_encoder(grad_vectors, mu, seed, k=40):\n",
    "    # k can vary\n",
    "    orig = k \n",
    "    new_grad_vectors = []\n",
    "    # print(\"GRAD VECTOR\", grad_vectors[-2])\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(grad_vectors)):\n",
    "            k = orig\n",
    "            shape = grad_vectors[i].shape\n",
    "            # Flattening the parameters to permutate over them\n",
    "            flat_grad = grad_vectors[i].view(-1)\n",
    "            C = shape[-1]\n",
    "            # Get the length of the flat_grad array\n",
    "            d = flat_grad.numel()\n",
    "            k = min(k, d)\n",
    "            # print(k, d, C)\n",
    "            torch.manual_seed(seed)\n",
    "            # Shuffle the list [1, 2, ... d] and get the first k elements\n",
    "            indices = torch.randperm(d, device=flat_grad.device)[:k]\n",
    "            mask = torch.zeros(d, dtype=torch.bool, device=flat_grad.device)\n",
    "            mask[indices] = True\n",
    "            \n",
    "            Y = torch.empty_like(flat_grad)\n",
    "            # Encode the parameters\n",
    "            chosen_vals = (d/k)*flat_grad[mask] - ((d-k)/k)*mu[i]\n",
    "            Y[mask] = flat_grad[mask]\n",
    "            # if i == 4:\n",
    "            #     print(\"values\", chosen_vals)\n",
    "            #     print(\"indices\", indices)\n",
    "            Y[~mask] = mu[i]\n",
    "            Y = Y.view(shape)\n",
    "            new_grad_vectors.append(Y)\n",
    "    # print(\"HERE1\", new_grad_vectors[-2])\n",
    "    return new_grad_vectors\n",
    "            \n",
    "            \n",
    "# Decoders : I wont be making use of this later on\n",
    "def averaging_decoder(grad_vectors_list):\n",
    "    if isinstance(grad_vectors_list, list):\n",
    "        grad_vectors_list = torch.stack(grad_vectors_list, dim=0)\n",
    "    return torch.mean(grad_vectors_list, dim=0)\n",
    "\n",
    "# Communication protocols\n",
    "def sparse_for_variable_size_encoder(encoded_vectors, mu):\n",
    "    final_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(encoded_vectors)):\n",
    "            flat_vector = encoded_vectors[i].view(-1)\n",
    "            mask = flat_vector != mu[i]\n",
    "            # vals = encoded_vectors[i][mask]\n",
    "            indices = torch.nonzero(mask, as_tuple=False).view(-1)\n",
    "            values = flat_vector[mask]\n",
    "            final_vectors.append(list(zip(indices, values)))\n",
    "\n",
    "    \n",
    "    return final_vectors, mu\n",
    "    \n",
    "def sparse_for_fixed_size_encoder(encoded_vectors, mu, seed):\n",
    "    final_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(encoded_vectors)):\n",
    "            flat_vector = encoded_vectors[i].view(-1)\n",
    "            mask = torch.zeros(len(flat_vector), dtype=torch.bool, device=flat_vector.device)\n",
    "            mask[flat_vector != mu[i]] = True\n",
    "            values = flat_vector[mask]\n",
    "            final_vectors.append(values)\n",
    "    \n",
    "    return final_vectors, mu, seed\n",
    "\n",
    "def rebuild_from_protocol_1(final_vectors, mu, original_shapes):\n",
    "    rebuilt_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i, vec_data in enumerate(final_vectors):\n",
    "            num_elements = 1\n",
    "            \n",
    "            for dim_size in original_shapes[i]:\n",
    "                num_elements *= dim_size\n",
    "    \n",
    "            \n",
    "            Y_flat = torch.full((num_elements,), mu[i], dtype=torch.float32, device=mu[i].device)\n",
    "    \n",
    "            indices = torch.tensor([pair[0] for pair in vec_data], dtype=torch.long, device=Y_flat.device)\n",
    "            values = torch.tensor([pair[1] for pair in vec_data], dtype=Y_flat.dtype, device=Y_flat.device)\n",
    "            Y_flat[indices] = values\n",
    "            Y = Y_flat.view(original_shapes[i])\n",
    "            rebuilt_vectors.append(Y)\n",
    "    return rebuilt_vectors\n",
    "\n",
    "def rebuild_from_protocol_2(final_vectors, mu, seed, original_shapes):\n",
    "    rebuilt_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i, values in enumerate(final_vectors):\n",
    "            \n",
    "            num_elements = 1\n",
    "            for dim_size in original_shapes[i]:\n",
    "                num_elements *= dim_size\n",
    "    \n",
    "            \n",
    "            k = len(values)  # number of chosen elements\n",
    "            d = num_elements\n",
    "            torch.manual_seed(seed)\n",
    "            indices = torch.randperm(d, device=device)[:k]\n",
    "            Y_flat = torch.full((num_elements,), float(mu[i]), dtype=torch.float32, device=mu[i].device)\n",
    "            # Y_flat[indices] = values\n",
    "            sorted_indices, sorted_pos = torch.sort(indices)\n",
    "            sorted_values = values[sorted_pos]\n",
    "            Y_flat[sorted_indices] = values\n",
    "            # if i == 4:\n",
    "            #     print(\"values\", values)\n",
    "            #     print(\"indices\", indices)\n",
    "            # Now we have Y, we must invert to get X\n",
    "            # mask for chosen elements: Y != mu[i]\n",
    "            chosen_mask = (Y_flat != mu[i])\n",
    "        \n",
    "            # Apply X = (k/d)*Y + ((d-k)/d)*mu if chosen\n",
    "            # X_flat = torch.empty_like(Y_flat)\n",
    "            # X_flat[chosen_mask] = (k/d)*Y_flat[chosen_mask] + ((d-k)/d)*mu[i]\n",
    "            # X_flat[~chosen_mask] = mu[i]\n",
    "                \n",
    "            # X = X_flat.view(original_shapes[i])\n",
    "            rebuilt_vectors.append(Y_flat.view(original_shapes[i]))\n",
    "    # print(rebuilt_vectors[-2])\n",
    "    return rebuilt_vectors\n",
    "\n",
    "\n",
    "parameters = list(model.parameters())\n",
    "mu_1 = []\n",
    "with torch.no_grad():\n",
    "    for p in parameters:\n",
    "        mu_1.append(torch.mean(p))\n",
    "print(mu_1)\n",
    "encoded_vectors = fixed_size_encoder(parameters, mu_1, SEED, k=1000)\n",
    "final_vectors, mu, SEED = sparse_for_fixed_size_encoder(encoded_vectors, mu_1, SEED)\n",
    "rebuilt_vectors = rebuild_from_protocol_2(final_vectors, mu_1, SEED, original_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82afcf7a-e4de-49d7-a835-411608e3731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProxSGDWithLinearSearch:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params, self.lr = list(params), lr\n",
    "        self.state = {p: {} for p in self.params}\n",
    "        self.hypers = [{'lr': lr}]\n",
    "        self.max_iter = 5\n",
    "        self.eta = 1e-5\n",
    "        \n",
    "    def soft_threshold(self, x, eta):\n",
    "        # Apply the soft-thresholding operator\n",
    "        return F.softshrink(x, lambd=eta)\n",
    "        \n",
    "    def prox_operator(self, x):\n",
    "        # Use the soft-thresholding operator as the proximal step\n",
    "        return self.soft_threshold(x, self.eta)\n",
    "\n",
    "    def Gt(self, x, step_size, x_grad):\n",
    "        return (1/step_size) * (x - self.prox_operator(x - step_size * x_grad))\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        model = kwargs.get(\"model\")\n",
    "        loss_fn = kwargs.get(\"loss_fn\")\n",
    "        X = kwargs.get(\"X\")\n",
    "        y = kwargs.get(\"y\")\n",
    "        \n",
    "        orig_params = [p.data.clone() for p in self.params]\n",
    "        step_size = self.lr\n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "            old_loss = loss_fn(pred, y)\n",
    "        flag = True\n",
    "        for _ in range(self.max_iter):\n",
    "            for p in self.params:\n",
    "                if p.grad is not None: \n",
    "                    Gt_val = self.Gt(p.data, step_size, p.grad.data)\n",
    "                    p.data = p.data - step_size * Gt_val\n",
    "            with torch.no_grad():\n",
    "                pred = model(X)\n",
    "                new_loss = loss_fn(pred, y)\n",
    "            if new_loss < old_loss:\n",
    "                flag = False\n",
    "                break\n",
    "            else:\n",
    "                for i, j in zip(self.params, orig_params):\n",
    "                    i.data.copy_(j)\n",
    "                step_size *= 0.5\n",
    "        if flag: \n",
    "            for p in self.params:\n",
    "                if p.grad is not None: \n",
    "                    Gt_val = self.Gt(p.data, step_size, p.grad.data)\n",
    "                    p.data = p.data - step_size * Gt_val\n",
    "        else:\n",
    "            self.lr = step_size\n",
    "        # print(self.lr)\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.grad = None\n",
    "\n",
    "    def set_hypers(self, **kwargs):\n",
    "        if 'lr' in kwargs:\n",
    "            self.lr = kwargs['lr']\n",
    "            self.hypers[0]['lr'] = kwargs['lr']\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7f3833-9cb2-459d-86b1-2b11ea031b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c008223f-22d0-4b30-bf02-6ad83feccae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step(model=model, loss_fn=loss_fn, X=X, y=y)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"BATCH: {batch} of {size/batch_size} batches\")\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "390563a7-8ac8-4947-8a2e-cbda1e90dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, number=\"main\"):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error for client {number}: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "89d30967-d2e7-4eca-93ae-225309a9ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Client:\n",
    "    def __init__(self, model, train_dataloader, loss_fn, mu, max_iter=2):\n",
    "        self.model = model\n",
    "        # self.optimizer = ProxSGDWithLinearSearch(model.parameters(), 20)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.max_iter = max_iter\n",
    "        self.loss_fn = loss_fn\n",
    "        self.mu = mu\n",
    "        \n",
    "    def train(self):\n",
    "        for i in range(0, self.max_iter):\n",
    "            train(self.train_dataloader, self.model, self.loss_fn, ProxSGDWithLinearSearch(self.model.parameters(), 20))\n",
    "\n",
    "    def test(self, test_dataloader, number):\n",
    "        test(test_dataloader, self.model, self.loss_fn, number)\n",
    "\n",
    "    def set_parameters(self, model):\n",
    "        self.model = copy.deepcopy(model)\n",
    "            \n",
    "    def get_encoded_1(self, p):\n",
    "        encoded = variable_size_encoder(list(self.model.parameters()), self.mu, p)\n",
    "        final_vectors, mu = sparse_for_variable_size_encoder(encoded, self.mu)\n",
    "        return final_vectors, mu\n",
    "\n",
    "    def get_encoded_2(self, k, seed):\n",
    "        encoded = fixed_size_encoder(list(self.model.parameters()), self.mu, seed, k)\n",
    "        self.encoded = encoded\n",
    "        final_vectors, mu, seed = sparse_for_fixed_size_encoder(encoded, self.mu, seed)\n",
    "        # encoded_vectors = encoded\n",
    "        return final_vectors, mu, seed\n",
    "\n",
    "    # Built the member function to test if continuous update of the mean is helpful or not\n",
    "    def update_mean(self):\n",
    "        with torch.no_grad():\n",
    "            params = list(self.model.parameters())\n",
    "            self.mu = [torch.mean(p) for p in params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7eee3638-48bb-4b5a-88ae-40f57b6f97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Master:\n",
    "    def __init__(self, model, mu, loss_fn):\n",
    "        self.model = model\n",
    "        self.original_shapes = [p.shape for p in model.parameters()]\n",
    "        self.mu = mu\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def set_mean(self, mu):\n",
    "        self.mu = copy.deepcopy(mu)\n",
    "        \n",
    "    def update_global_model_from_protocol_1(self, clients_data):\n",
    "        # clients_data is a list of tuples (final_vectors, mu, p) from each client\n",
    "        # Decode each client's parameters and then compute updates\n",
    "        decoded_params_list = []\n",
    "        for (final_vectors, mu) in clients_data:\n",
    "            decoded = rebuild_from_protocol_1(final_vectors, mu, self.original_shapes)\n",
    "            decoded_params_list.append(decoded)\n",
    "\n",
    "        # Now decoded_params_list is a list of parameter lists from each client\n",
    "        # Convert each client's param list into a tensor stack and average updates\n",
    "        # First, get master_params for reference\n",
    "        master_params = list(self.model.parameters())\n",
    "        \n",
    "        # Compute updates: (client_params - master_params) for each client, then average\n",
    "        all_updates = []\n",
    "        with torch.no_grad():\n",
    "            for decoded_params in decoded_params_list:\n",
    "                updates = [(dp - mp) for dp, mp in zip(decoded_params, master_params)]\n",
    "                all_updates.append(updates)\n",
    "\n",
    "            # Average updates across clients\n",
    "            # Stack each parameter across clients and mean\n",
    "            averaged_updates = []\n",
    "            num_clients = len(all_updates)\n",
    "            for param_idx in range(len(master_params)):\n",
    "                # Gather this param_idx from all clients\n",
    "                stack = torch.stack([all_updates[c][param_idx] for c in range(num_clients)], dim=0)\n",
    "                avg = torch.mean(stack, dim=0)\n",
    "                averaged_updates.append(avg)\n",
    "\n",
    "            # Apply averaged updates to master model\n",
    "            for mp, au in zip(master_params, averaged_updates):\n",
    "                mp.data.add_(au)\n",
    "\n",
    "    def update_global_model_from_protocol_2(self, clients_data):\n",
    "        # clients_data is a list of tuples (final_vectors, mu, seed, k) from each client\n",
    "        decoded_params_list = []\n",
    "        for (final_vectors, mu, seed) in clients_data:\n",
    "            decoded = rebuild_from_protocol_2(final_vectors, mu, seed, self.original_shapes)\n",
    "            decoded_params_list.append(decoded)\n",
    "            # decoded_vectors = decoded\n",
    "            # print(decoded)\n",
    "        self.decoded_params = decoded_params_list\n",
    "        self.clients_data = clients_data\n",
    "        master_params = list(self.model.parameters())\n",
    "        all_updates = []\n",
    "        with torch.no_grad():\n",
    "            for decoded_params in decoded_params_list:\n",
    "                updates = [(dp - mp) for dp, mp in zip(decoded_params, master_params)]\n",
    "                all_updates.append(updates)\n",
    "\n",
    "            num_clients = len(all_updates)\n",
    "            averaged_updates = []\n",
    "            for param_idx in range(len(master_params)):\n",
    "                stack = torch.stack([all_updates[c][param_idx] for c in range(num_clients)], dim=0)\n",
    "                avg = torch.mean(stack, dim=0)\n",
    "                averaged_updates.append(avg)\n",
    "\n",
    "            # Apply averaged updates to master model\n",
    "            \n",
    "            for mp, au in zip(master_params, averaged_updates):\n",
    "                mp.data.add_(au)\n",
    "\n",
    "    def test(self, test_dataloader):\n",
    "        test(test_dataloader, self.model, self.loss_fn, \"master\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8dedf521-0485-4440-bd22-d9865b54eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "parameters = list(model.parameters())\n",
    "mu_1 = []\n",
    "with torch.no_grad():\n",
    "    for p in parameters:\n",
    "        mu_1.append(torch.mean(p))\n",
    "# mu_1 = torch.zeros(len(parameters), device=device)        \n",
    "master = Master(model, mu_1, loss_fn) \n",
    "clients = [Client(NeuralNetwork().to(device), client_loaders[i], loss_fn, mu_1, 5) for i in range(num_clients)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ac3d8-255a-4ef3-9774-c05cfcabb76d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encoder 1\n",
    "\n",
    "for i in range(1):\n",
    "    # Master sends global parameters to the client\n",
    "    for client in clients:\n",
    "        client.set_parameters(master.model)\n",
    "        # client.update_mean()\n",
    "    \n",
    "    # Clients are trained locally\n",
    "    for client in clients:\n",
    "        client.train()\n",
    "    \n",
    "    clients_data_protocol_1 = []\n",
    "    for client in clients:\n",
    "        final_vectors, mu = client.get_encoded_1(p=0.5)\n",
    "        clients_data_protocol_1.append((final_vectors, mu))\n",
    "    \n",
    "    master.update_global_model_from_protocol_1(clients_data_protocol_1)\n",
    "\n",
    "    master.test(test_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6f16af22-87fe-4c1b-aec4-13d90897e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.310975  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.438191  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.393345  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.234294  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.288048  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.307470  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.530795  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.299698  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.246769  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.134052  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.310458  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.503135  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.412047  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.216708  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.236499  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.308937  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.608255  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.322590  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.242099  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.191294  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 2.309484  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.422171  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.410944  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.228428  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.223379  [  256/12000]\n",
      "Test Error for client master: \n",
      " Accuracy: 76.9%, Avg loss: 1.139277 \n",
      "\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.194152  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.148784  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.208165  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.179778  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.100030  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.123972  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.238875  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.238384  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.133348  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.109472  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.172258  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.235317  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.228394  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.103445  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.107892  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.170889  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.208209  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.221029  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.180716  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.097721  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 1.168325  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.275006  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.199319  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.125776  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.189554  [  256/12000]\n",
      "Test Error for client master: \n",
      " Accuracy: 96.0%, Avg loss: 0.128813 \n",
      "\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.106357  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.124750  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.078255  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.178469  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.046748  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.134336  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.110391  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.107600  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.114736  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.053504  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.175221  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.192284  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.078688  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.067981  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.072044  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.093072  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.137036  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.098119  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.064125  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.056681  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.162907  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.112957  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.099248  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.058347  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.092074  [  256/12000]\n",
      "Test Error for client master: \n",
      " Accuracy: 97.0%, Avg loss: 0.091816 \n",
      "\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.044729  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.088561  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.026573  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.025146  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.048180  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.069308  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.077779  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.086457  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.057373  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.041300  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.083697  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.052635  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.030326  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.059760  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.045011  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.094630  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.074022  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.103630  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.041535  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.030915  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.067405  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.065091  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.098974  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.049896  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.028386  [  256/12000]\n",
      "Test Error for client master: \n",
      " Accuracy: 97.5%, Avg loss: 0.075625 \n",
      "\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.055407  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.028294  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.075919  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.046848  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.033404  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.075104  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.037767  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.033470  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.041393  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.044145  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.043738  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.079413  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.033304  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.016982  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.029028  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.030536  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.040692  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.072003  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.037912  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.067351  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.035735  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.059984  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.061142  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.042454  [  256/12000]\n",
      "BATCH: 0 of 46.875 batches\n",
      "loss: 0.028385  [  256/12000]\n",
      "Test Error for client master: \n",
      " Accuracy: 97.8%, Avg loss: 0.068344 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encoder 2\n",
    "base_seed = 42\n",
    "\n",
    "for i in range(5):\n",
    "    # Master sends global parameters to the client\n",
    "    for client in clients:\n",
    "        client.set_parameters(master.model)\n",
    "        client.update_mean()\n",
    "    \n",
    "    # Clients are trained locally\n",
    "    for client in clients:\n",
    "        client.train()\n",
    "    \n",
    "    clients_data_protocol_2 = []\n",
    "    for client_id, client in enumerate(clients):\n",
    "        current_seed = base_seed + i * 1000 + client_id\n",
    "        torch.manual_seed(current_seed)\n",
    "        final_vectors, mu, seed = client.get_encoded_2(k=5000000, seed=current_seed)\n",
    "        clients_data_protocol_2.append((final_vectors, mu, seed))\n",
    "    \n",
    "    master.update_global_model_from_protocol_2(clients_data_protocol_2)\n",
    "    \n",
    "    master.test(test_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f90500bc-dd79-4fca-b658-631c250078d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for client master: \n",
      " Accuracy: 97.8%, Avg loss: 0.068344 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "master.test(test_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e6f229f0-ecaf-4274-bf1d-0ae481f367c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for client 0: \n",
      " Accuracy: 93.8%, Avg loss: 0.199948 \n",
      "\n",
      "Test Error for client 1: \n",
      " Accuracy: 94.3%, Avg loss: 0.184125 \n",
      "\n",
      "Test Error for client 2: \n",
      " Accuracy: 94.2%, Avg loss: 0.184488 \n",
      "\n",
      "Test Error for client 3: \n",
      " Accuracy: 94.6%, Avg loss: 0.170945 \n",
      "\n",
      "Test Error for client 4: \n",
      " Accuracy: 94.0%, Avg loss: 0.196233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clients)):\n",
    "    clients[i].test(test_dataloader, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801eec2e-9a80-40c7-9914-421724b96b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
