{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7744187e-9a74-440b-95b8-557b723fc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import fastai \n",
    "from torchvision.transforms import ToTensor\n",
    "# from fastai.data.core import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.vision.all import Learner, Metric\n",
    "from fastai import optimizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5849ab-a4ca-4515-97b5-35c90615be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c4d276-b524-46c7-b31a-8324a4b2b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([256, 1, 28, 28])\n",
      "Shape of y: torch.Size([256]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b180ad30-e4fe-4af6-9367-d3e5b03bc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af6c2a9-8714-4c3f-bf16-44b3b964ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 5\n",
    "# train_size = len(training_data)\n",
    "# indices = list(range(train_size))\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED)\n",
    "indices = torch.randperm(train_size).tolist()\n",
    "\n",
    "subset_size = train_size // num_clients\n",
    "client_subsets = [] \n",
    "for i in range(num_clients):\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = start_idx + subset_size\n",
    "\n",
    "    if i == num_clients - 1:\n",
    "        end_idx = train_size\n",
    "\n",
    "    subset_indices = indices[start_idx:end_idx]\n",
    "    client_subsets.append(Subset(training_data, subset_indices))\n",
    "\n",
    "client_loaders = [DataLoader(sub, batch_size=batch_size, shuffle=True) for sub in client_subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "831d6af4-3ad3-4d67-8681-472ba8624385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits \n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ab18bf1-90d6-4bde-a5fc-3ebb2766e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have 5 different datasets, each with some sort of representation of the data that is unknown, ie, we have no \n",
    "# statistical information on the data that each of these clients would have\n",
    "# We now need to implement variations of the 3 protocols, namely, the encoding protocol, the communication protocol and the decoding protocol\n",
    "\n",
    "\n",
    "# Encoders\n",
    "def variable_size_encoder(grad_vectors):\n",
    "    pass\n",
    "\n",
    "def fixed_size_encoder(grad_vectors):\n",
    "    pass\n",
    "\n",
    "# Decoders \n",
    "def averaging_decoder(grad_vectors_list):\n",
    "    if isinstance(grad_vectors_list, list):\n",
    "        grad_vectors_list = torch.stack(grad_vectors_list, dim=0)\n",
    "    return torch.mean(grad_vectors_list, dim=0)\n",
    "\n",
    "# Communication protocols\n",
    "def sparse_for_variable_size_encoder(grad_vectors):\n",
    "    pass\n",
    "\n",
    "def sparse_for_fixed_size_encoder(grad_vectors):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd3c6e93-87af-426a-8ad5-a81bcba62990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3333, 3.3333, 4.3333])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\n",
    "averaging_decoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "311d5661-e5fd-4efc-b2d9-f238953a7c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0110, -0.0096, -0.0194,  ...,  0.0244, -0.0186,  0.0118],\n",
       "         [-0.0061,  0.0233, -0.0160,  ...,  0.0348, -0.0215,  0.0044],\n",
       "         [-0.0071,  0.0019,  0.0007,  ...,  0.0242,  0.0239, -0.0050],\n",
       "         ...,\n",
       "         [ 0.0069, -0.0221, -0.0245,  ...,  0.0273,  0.0008, -0.0178],\n",
       "         [-0.0122,  0.0277, -0.0271,  ...,  0.0178, -0.0129, -0.0095],\n",
       "         [-0.0286, -0.0308, -0.0018,  ..., -0.0169,  0.0100, -0.0270]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-3.3647e-02, -1.2088e-02, -2.7336e-03,  3.4404e-02,  1.6939e-02,\n",
       "          6.6910e-03,  2.4960e-02,  3.4645e-02,  3.1078e-02, -3.3355e-02,\n",
       "          2.3618e-02,  1.1166e-02, -9.6607e-03, -3.2638e-02,  1.7812e-03,\n",
       "         -6.3383e-03, -1.6643e-02, -6.4174e-03, -1.7991e-02, -3.5636e-02,\n",
       "         -1.5705e-02,  3.0728e-02,  2.2389e-02,  3.8432e-05,  3.2346e-02,\n",
       "         -2.2608e-02,  2.6099e-02, -3.3211e-03,  1.2657e-02, -2.7012e-02,\n",
       "          3.2372e-02,  1.9401e-02,  3.2694e-02, -3.4613e-02, -1.1776e-02,\n",
       "          1.2823e-02,  4.5473e-03, -1.6268e-02,  2.0749e-02, -3.1338e-02,\n",
       "         -1.8611e-02,  5.2961e-03, -1.6406e-02, -6.8659e-03,  3.0734e-02,\n",
       "          1.7728e-02, -4.1262e-03, -1.1855e-02, -2.7751e-02, -1.1411e-02,\n",
       "          3.0407e-02,  1.0768e-03,  1.5882e-02, -3.1401e-02,  9.3615e-04,\n",
       "         -2.6010e-02,  1.2935e-02, -3.2131e-02, -1.0328e-02, -1.3001e-02,\n",
       "          2.4491e-02, -2.5146e-02, -1.1326e-02, -2.4058e-02,  2.3175e-02,\n",
       "         -1.9290e-02, -1.4052e-02, -3.4778e-02,  2.6757e-02,  2.3203e-02,\n",
       "         -3.4162e-02, -8.8653e-03, -2.3395e-02,  3.4891e-02,  3.3920e-02,\n",
       "         -2.8716e-02,  3.4332e-02, -9.8497e-03,  3.2809e-02,  2.3488e-03,\n",
       "          8.2244e-03,  1.9850e-02, -2.4199e-02,  3.0315e-02,  1.3715e-02,\n",
       "         -3.4785e-02,  8.3871e-03, -1.0816e-02, -2.5373e-03,  2.0287e-02,\n",
       "          1.0292e-02,  7.7726e-03,  3.0884e-02, -5.0375e-03, -2.7839e-02,\n",
       "         -2.9321e-02, -2.4636e-02, -5.3220e-03,  1.9380e-02,  1.8845e-02,\n",
       "          1.1648e-02, -2.5398e-02,  3.5559e-02, -8.3971e-03, -2.6736e-02,\n",
       "          2.5500e-02, -3.3845e-02, -1.3424e-02, -1.1659e-02, -3.4889e-02,\n",
       "          5.0482e-03,  5.9871e-03,  2.1884e-02,  3.0778e-02,  1.8074e-02,\n",
       "          1.3067e-02,  2.7150e-02,  2.6765e-02,  1.5829e-02,  2.8036e-02,\n",
       "         -1.4169e-02, -1.0928e-02,  1.1321e-02,  1.2608e-03, -1.6728e-02,\n",
       "         -2.6097e-02, -1.3430e-02, -3.0141e-02,  2.3650e-02, -2.0676e-02,\n",
       "         -1.2253e-02, -9.7087e-03,  2.6516e-02,  1.7298e-02,  1.8420e-02,\n",
       "         -4.3928e-03,  1.2379e-02,  2.3619e-02, -2.4884e-03,  2.6432e-02,\n",
       "          9.3156e-03,  2.4624e-02, -1.1937e-02,  3.1355e-02,  3.1644e-02,\n",
       "         -1.4354e-02,  1.5490e-03, -2.0854e-02,  1.3860e-02,  2.0574e-02,\n",
       "         -3.4857e-02,  2.9986e-02, -1.7333e-02, -3.3871e-02, -3.3176e-02,\n",
       "          3.2930e-02, -3.0763e-02, -3.3537e-02,  2.5459e-02,  2.5210e-03,\n",
       "         -4.2350e-03, -5.9777e-03, -1.3122e-03,  1.4297e-02,  2.6838e-02,\n",
       "         -1.8487e-02, -3.2101e-02,  1.1482e-02, -3.3124e-02, -8.6264e-03,\n",
       "         -2.9285e-02, -2.0363e-02, -1.5433e-02, -1.5758e-02, -2.1164e-02,\n",
       "         -1.6282e-04,  1.1069e-02,  2.8071e-02,  2.5931e-02,  3.1141e-02,\n",
       "         -2.8218e-02, -7.9474e-03,  2.9654e-02,  2.6523e-02, -3.3091e-02,\n",
       "         -1.9399e-02,  1.0875e-02, -3.3300e-02,  3.7680e-03,  2.5718e-02,\n",
       "         -5.2262e-03, -1.3544e-02, -3.7101e-03, -3.0731e-02,  1.7916e-02,\n",
       "         -2.9882e-02, -3.4152e-02, -6.4288e-03, -3.0672e-02,  3.5291e-03,\n",
       "         -3.3694e-02, -8.6153e-03,  1.6978e-02, -1.0406e-02,  2.2951e-02,\n",
       "         -1.9493e-02,  1.8481e-02, -2.2614e-02,  2.7868e-02, -3.4232e-03,\n",
       "         -2.0497e-02,  1.4076e-02,  1.9054e-02, -6.9433e-04,  1.0899e-02,\n",
       "          2.7597e-03,  3.5627e-02,  3.4988e-02,  2.8692e-02,  2.5845e-02,\n",
       "         -1.8210e-02, -2.5033e-02,  1.6301e-02, -4.5552e-03, -2.1499e-02,\n",
       "          2.5895e-02,  1.6421e-03, -2.2646e-02,  3.5623e-02,  3.5151e-03,\n",
       "         -2.7857e-02, -2.8659e-02,  3.5037e-02,  6.4306e-04,  1.4944e-02,\n",
       "          3.8937e-03, -3.9960e-03,  2.4372e-03, -9.8816e-03, -1.2356e-02,\n",
       "          2.6489e-02,  3.3595e-02,  3.8476e-04,  8.7432e-03, -2.3948e-02,\n",
       "         -2.8829e-02, -1.1378e-03, -1.5026e-02,  1.3289e-02, -1.1070e-02,\n",
       "         -2.1199e-02,  7.9134e-03, -1.1346e-02,  3.3240e-02, -3.4475e-02,\n",
       "         -3.5404e-02, -1.8541e-02, -2.4561e-03,  9.7439e-03, -1.6655e-02,\n",
       "          1.9711e-02, -1.2143e-02,  6.8041e-03, -3.2461e-02, -2.7837e-02,\n",
       "          9.1970e-04, -2.4446e-02,  1.2450e-02, -3.2647e-02, -1.9705e-02,\n",
       "         -2.6551e-02,  9.3482e-03,  2.6156e-02, -1.9071e-02,  1.2935e-02,\n",
       "         -1.1223e-02,  2.0951e-02, -2.5262e-02,  1.9851e-02, -3.4065e-02,\n",
       "         -3.9117e-03,  1.2708e-02, -2.3185e-02, -3.1326e-02, -1.3084e-02,\n",
       "         -4.4460e-03,  2.6391e-02, -3.4068e-02, -2.6581e-02, -2.7937e-02,\n",
       "          1.5700e-02, -5.2013e-03,  2.8289e-02, -1.6110e-02,  2.0233e-02,\n",
       "         -1.5190e-02,  2.3497e-02,  1.7866e-02, -3.0395e-02, -2.9257e-02,\n",
       "          3.0434e-02, -2.0378e-02, -1.0174e-02, -2.8600e-02, -6.1158e-03,\n",
       "         -3.3558e-02,  1.2070e-02, -2.5232e-02,  2.5609e-02, -1.9233e-03,\n",
       "         -1.0559e-02,  1.1979e-02, -3.2837e-02, -3.1404e-02, -2.1954e-02,\n",
       "         -3.4745e-02,  2.7728e-02, -2.0805e-02,  7.0257e-03,  1.1415e-02,\n",
       "          2.5900e-02, -1.4823e-02,  2.0651e-02, -3.0143e-02, -3.0704e-02,\n",
       "          3.0188e-02,  3.5373e-02,  3.2076e-02,  1.7926e-02, -2.9184e-02,\n",
       "          1.1933e-02,  1.5320e-02,  1.4550e-02,  1.0605e-02, -2.5607e-02,\n",
       "         -1.7998e-02,  3.2234e-02,  4.2482e-03, -1.6391e-02, -1.2033e-02,\n",
       "          3.2139e-02, -1.4062e-02,  3.1647e-02, -2.1256e-02, -1.4555e-02,\n",
       "          3.4473e-02, -3.0829e-02, -2.7926e-02, -1.2253e-02, -2.8074e-02,\n",
       "         -6.1749e-03,  9.0980e-03, -1.7147e-02,  1.6640e-02, -1.2731e-03,\n",
       "         -3.1840e-02, -3.2767e-02, -2.8710e-02, -3.3844e-02,  2.5113e-02,\n",
       "         -3.4925e-02,  3.1502e-02,  3.0343e-02,  2.6269e-02, -8.4514e-03,\n",
       "          2.6179e-02, -1.0525e-02, -1.6465e-02, -1.3751e-02,  1.1032e-02,\n",
       "          2.2961e-02,  2.5436e-04, -2.9504e-02, -1.7001e-02, -2.1865e-02,\n",
       "         -2.8493e-02, -1.3754e-02,  2.6606e-02, -2.9854e-02, -8.9109e-03,\n",
       "         -7.7981e-03, -4.4962e-03,  2.6623e-02,  5.8525e-03,  1.2151e-02,\n",
       "         -3.0651e-02,  7.0882e-03, -3.4875e-02, -2.8860e-02,  8.5371e-03,\n",
       "          1.4857e-02,  3.0053e-03, -2.1808e-02, -9.7153e-04,  1.7411e-02,\n",
       "          2.5361e-02,  4.5231e-03, -1.2913e-03,  2.1974e-02, -2.8379e-02,\n",
       "         -6.2704e-03,  7.8763e-03, -2.1724e-02, -3.5614e-02, -1.1740e-02,\n",
       "          3.1102e-03, -9.4855e-03, -1.1424e-02,  1.6232e-02,  1.7377e-02,\n",
       "         -4.7857e-03,  2.6987e-02,  1.6982e-02,  1.7500e-02, -9.6954e-03,\n",
       "          2.6254e-02, -2.1103e-02, -1.3149e-02,  1.0407e-02,  2.6108e-03,\n",
       "         -7.9886e-03,  1.8831e-02, -1.0913e-02, -1.0090e-03,  3.4599e-02,\n",
       "         -1.7205e-02, -2.9646e-02, -1.8981e-02,  2.6279e-02, -3.0859e-02,\n",
       "         -3.0743e-02, -1.2236e-02, -1.9674e-02, -5.0693e-03, -1.7271e-02,\n",
       "         -1.9750e-02, -2.8935e-02,  3.4166e-02,  1.4032e-02,  1.1191e-02,\n",
       "          3.0026e-02, -2.9643e-04, -7.2859e-03,  1.6915e-02,  1.5378e-02,\n",
       "         -2.3403e-03, -3.4484e-02, -4.7833e-03,  2.2609e-02, -2.8040e-03,\n",
       "          1.7115e-02, -3.2404e-02,  2.6812e-02, -3.7255e-03,  3.5019e-02,\n",
       "          4.8435e-03, -2.5249e-03, -1.2404e-02,  1.1861e-02,  6.0610e-03,\n",
       "          3.4125e-03, -1.9744e-02,  2.2952e-02, -1.7798e-02,  2.0428e-02,\n",
       "          2.7962e-02, -2.9021e-02,  4.2756e-03, -2.0384e-02, -1.1051e-02,\n",
       "          1.0687e-02,  1.4345e-02, -7.2156e-03, -1.8079e-02,  2.8658e-04,\n",
       "          2.0970e-02, -3.4680e-02,  2.2483e-02, -4.3067e-03,  2.4935e-02,\n",
       "          1.8835e-02, -1.0220e-02,  2.7816e-02,  3.3452e-03, -3.0563e-02,\n",
       "          1.5515e-02, -1.7492e-02,  2.6659e-03, -1.5685e-02, -3.1673e-03,\n",
       "          1.0627e-02, -2.1660e-02, -5.9817e-03,  2.6747e-02,  1.9535e-03,\n",
       "          2.2948e-02, -6.9121e-03,  3.4189e-03,  3.2724e-03,  2.6757e-02,\n",
       "          3.5577e-02, -3.5559e-02, -1.2862e-02,  2.0499e-02,  2.7042e-02,\n",
       "          1.8632e-02,  1.6483e-02, -3.4916e-02,  3.0827e-03, -1.9107e-03,\n",
       "         -3.3950e-02, -3.0256e-02], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0183,  0.0385,  0.0333,  ..., -0.0241,  0.0359,  0.0137],\n",
       "         [-0.0025,  0.0405, -0.0125,  ...,  0.0296,  0.0113,  0.0273],\n",
       "         [-0.0429,  0.0364, -0.0221,  ..., -0.0069, -0.0139, -0.0022],\n",
       "         ...,\n",
       "         [-0.0148, -0.0380, -0.0002,  ..., -0.0308, -0.0226, -0.0037],\n",
       "         [ 0.0178,  0.0327,  0.0087,  ...,  0.0043,  0.0395,  0.0320],\n",
       "         [ 0.0260,  0.0229,  0.0274,  ...,  0.0435, -0.0164, -0.0211]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0358, -0.0372, -0.0161,  0.0391, -0.0067, -0.0269, -0.0206, -0.0362,\n",
       "          0.0082, -0.0196,  0.0313,  0.0065, -0.0197,  0.0204, -0.0348, -0.0057,\n",
       "         -0.0098,  0.0307,  0.0332,  0.0333, -0.0084, -0.0294,  0.0100, -0.0379,\n",
       "          0.0238,  0.0297, -0.0399, -0.0309,  0.0113,  0.0105,  0.0388,  0.0408,\n",
       "          0.0304, -0.0218, -0.0354,  0.0071,  0.0387, -0.0253,  0.0057,  0.0073,\n",
       "          0.0313, -0.0369, -0.0226, -0.0222, -0.0142, -0.0159,  0.0210, -0.0440,\n",
       "         -0.0410,  0.0379,  0.0093, -0.0431, -0.0192,  0.0150,  0.0109, -0.0208,\n",
       "         -0.0355,  0.0215, -0.0332,  0.0197, -0.0096, -0.0180,  0.0109,  0.0153,\n",
       "          0.0092,  0.0170,  0.0312, -0.0103, -0.0310, -0.0273,  0.0293,  0.0416,\n",
       "         -0.0128,  0.0178, -0.0102, -0.0238, -0.0241, -0.0327,  0.0105, -0.0104,\n",
       "          0.0059,  0.0345,  0.0344, -0.0218, -0.0377, -0.0091, -0.0145,  0.0221,\n",
       "         -0.0386,  0.0207,  0.0182, -0.0139, -0.0330, -0.0095, -0.0285,  0.0176,\n",
       "         -0.0112,  0.0309,  0.0334,  0.0071,  0.0263,  0.0201, -0.0144, -0.0160,\n",
       "          0.0176, -0.0096,  0.0382, -0.0338, -0.0110, -0.0115,  0.0156, -0.0236,\n",
       "         -0.0014,  0.0296, -0.0093, -0.0081,  0.0126,  0.0244,  0.0253,  0.0401,\n",
       "          0.0126,  0.0131, -0.0012, -0.0266,  0.0233,  0.0155, -0.0225,  0.0184,\n",
       "          0.0275, -0.0058, -0.0433,  0.0323,  0.0111, -0.0397,  0.0160, -0.0349,\n",
       "          0.0318, -0.0314,  0.0137,  0.0347,  0.0026, -0.0309, -0.0120, -0.0097,\n",
       "         -0.0137,  0.0317,  0.0147,  0.0065, -0.0440,  0.0418, -0.0375,  0.0025,\n",
       "         -0.0153,  0.0135,  0.0290, -0.0142,  0.0071, -0.0012,  0.0051, -0.0321,\n",
       "          0.0269, -0.0269, -0.0402, -0.0020, -0.0369,  0.0256, -0.0271, -0.0419,\n",
       "         -0.0327, -0.0273,  0.0148,  0.0077, -0.0046, -0.0328,  0.0197, -0.0026,\n",
       "         -0.0213, -0.0419, -0.0057,  0.0042,  0.0419,  0.0315,  0.0250, -0.0100,\n",
       "          0.0128,  0.0257, -0.0381, -0.0132, -0.0252, -0.0051,  0.0199, -0.0176,\n",
       "         -0.0244, -0.0353,  0.0343, -0.0391, -0.0316, -0.0405, -0.0379, -0.0018,\n",
       "          0.0168, -0.0076,  0.0145, -0.0337, -0.0245,  0.0168, -0.0239,  0.0387,\n",
       "         -0.0108,  0.0354,  0.0259,  0.0332, -0.0089, -0.0008, -0.0300, -0.0192,\n",
       "          0.0412, -0.0282, -0.0110,  0.0390,  0.0421,  0.0228, -0.0422, -0.0269,\n",
       "         -0.0200,  0.0374,  0.0297,  0.0262, -0.0404, -0.0062,  0.0378,  0.0198,\n",
       "          0.0058, -0.0136, -0.0422, -0.0412, -0.0227,  0.0153,  0.0020, -0.0331,\n",
       "         -0.0192,  0.0327,  0.0080, -0.0176,  0.0436,  0.0344,  0.0219, -0.0285,\n",
       "         -0.0258,  0.0172, -0.0049, -0.0373, -0.0392, -0.0285,  0.0171, -0.0234,\n",
       "         -0.0427, -0.0314, -0.0417, -0.0046,  0.0242,  0.0255,  0.0334,  0.0255,\n",
       "         -0.0340, -0.0200, -0.0189, -0.0173,  0.0338,  0.0159, -0.0012,  0.0230,\n",
       "          0.0358,  0.0231, -0.0265, -0.0426,  0.0189, -0.0209,  0.0251, -0.0217,\n",
       "          0.0133, -0.0337,  0.0345, -0.0201, -0.0388, -0.0193,  0.0025, -0.0261,\n",
       "          0.0158, -0.0418,  0.0125,  0.0120, -0.0424, -0.0067, -0.0406, -0.0348,\n",
       "         -0.0392, -0.0114, -0.0419,  0.0350,  0.0383,  0.0350,  0.0418, -0.0144,\n",
       "         -0.0213, -0.0051, -0.0234,  0.0181, -0.0166, -0.0062, -0.0033, -0.0157,\n",
       "         -0.0061,  0.0332, -0.0434, -0.0403, -0.0353,  0.0390,  0.0172, -0.0221,\n",
       "          0.0350, -0.0109,  0.0418,  0.0160, -0.0282, -0.0114,  0.0004, -0.0164,\n",
       "         -0.0328,  0.0241, -0.0031, -0.0406, -0.0404, -0.0414,  0.0233,  0.0190,\n",
       "          0.0049,  0.0108, -0.0014, -0.0154,  0.0415, -0.0257, -0.0399,  0.0009,\n",
       "         -0.0015, -0.0301,  0.0085,  0.0366,  0.0067,  0.0064, -0.0380,  0.0427,\n",
       "          0.0281, -0.0410, -0.0321,  0.0266,  0.0015,  0.0065, -0.0316,  0.0153,\n",
       "         -0.0131, -0.0305,  0.0434,  0.0246, -0.0132, -0.0079, -0.0349,  0.0136,\n",
       "          0.0082, -0.0226,  0.0239, -0.0162,  0.0196,  0.0165,  0.0334,  0.0336,\n",
       "         -0.0288, -0.0165, -0.0016, -0.0063, -0.0120, -0.0335,  0.0167, -0.0385,\n",
       "          0.0356, -0.0153, -0.0294, -0.0282, -0.0216,  0.0106, -0.0207,  0.0337,\n",
       "         -0.0037, -0.0265, -0.0381, -0.0042,  0.0056, -0.0122,  0.0211,  0.0212,\n",
       "         -0.0101, -0.0026, -0.0092, -0.0154, -0.0212, -0.0310, -0.0227, -0.0354,\n",
       "          0.0263, -0.0104,  0.0269, -0.0419, -0.0122,  0.0382, -0.0418,  0.0308,\n",
       "          0.0071, -0.0067,  0.0154,  0.0413,  0.0313, -0.0056,  0.0196, -0.0345,\n",
       "         -0.0080, -0.0376,  0.0346, -0.0266,  0.0419,  0.0112,  0.0017, -0.0218,\n",
       "          0.0059,  0.0080,  0.0276, -0.0371,  0.0114, -0.0226, -0.0073,  0.0098,\n",
       "          0.0391, -0.0289, -0.0413,  0.0359,  0.0260,  0.0066, -0.0248, -0.0359,\n",
       "         -0.0167,  0.0416,  0.0058, -0.0125,  0.0123, -0.0365,  0.0210,  0.0395,\n",
       "         -0.0146, -0.0310,  0.0295, -0.0217, -0.0108, -0.0383, -0.0289,  0.0437,\n",
       "          0.0339,  0.0064,  0.0277,  0.0023, -0.0120,  0.0260,  0.0097, -0.0297,\n",
       "         -0.0436,  0.0374, -0.0206,  0.0170, -0.0108,  0.0219, -0.0280, -0.0233,\n",
       "          0.0061, -0.0222,  0.0441, -0.0072, -0.0180,  0.0016, -0.0223, -0.0047,\n",
       "         -0.0129,  0.0322,  0.0243, -0.0221,  0.0347,  0.0326, -0.0122, -0.0431,\n",
       "         -0.0417, -0.0373,  0.0378, -0.0161,  0.0208,  0.0305,  0.0254,  0.0195,\n",
       "         -0.0377, -0.0151,  0.0104, -0.0254, -0.0204,  0.0335,  0.0174,  0.0071],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0090,  0.0082,  0.0173,  ...,  0.0081,  0.0161, -0.0015],\n",
       "         [-0.0331, -0.0240, -0.0061,  ...,  0.0428,  0.0051,  0.0400],\n",
       "         [ 0.0126,  0.0416, -0.0009,  ..., -0.0417,  0.0058, -0.0255],\n",
       "         ...,\n",
       "         [-0.0040,  0.0273, -0.0419,  ..., -0.0006, -0.0305,  0.0132],\n",
       "         [ 0.0131, -0.0421,  0.0203,  ..., -0.0111, -0.0290, -0.0109],\n",
       "         [-0.0146,  0.0308, -0.0246,  ..., -0.0173,  0.0435,  0.0242]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0031,  0.0271,  0.0032, -0.0225, -0.0016, -0.0012, -0.0440, -0.0105,\n",
       "         -0.0177,  0.0355], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = list(model.parameters())\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c008223f-22d0-4b30-bf02-6ad83feccae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390563a7-8ac8-4947-8a2e-cbda1e90dd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
