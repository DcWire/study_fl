{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7744187e-9a74-440b-95b8-557b723fc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import fastai \n",
    "from torchvision.transforms import ToTensor\n",
    "# from fastai.data.core import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.vision.all import Learner, Metric\n",
    "from fastai import optimizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5849ab-a4ca-4515-97b5-35c90615be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c4d276-b524-46c7-b31a-8324a4b2b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([256, 1, 28, 28])\n",
      "Shape of y: torch.Size([256]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b180ad30-e4fe-4af6-9367-d3e5b03bc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af6c2a9-8714-4c3f-bf16-44b3b964ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 5\n",
    "train_size = len(training_data)\n",
    "# indices = list(range(train_size))\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED)\n",
    "indices = torch.randperm(train_size).tolist()\n",
    "\n",
    "subset_size = train_size // num_clients\n",
    "client_subsets = [] \n",
    "for i in range(num_clients):\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = start_idx + subset_size\n",
    "\n",
    "    if i == num_clients - 1:\n",
    "        end_idx = train_size\n",
    "\n",
    "    subset_indices = indices[start_idx:end_idx]\n",
    "    client_subsets.append(Subset(training_data, subset_indices))\n",
    "\n",
    "client_loaders = [DataLoader(sub, batch_size=batch_size, shuffle=True) for sub in client_subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831d6af4-3ad3-4d67-8681-472ba8624385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits \n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ab18bf1-90d6-4bde-a5fc-3ebb2766e207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[(tensor(23, device='cuda:0'), tensor(-627.2519, device='cuda:0')),\n",
       "   (tensor(28, device='cuda:0'), tensor(864.1521, device='cuda:0')),\n",
       "   (tensor(87, device='cuda:0'), tensor(977.1844, device='cuda:0')),\n",
       "   (tensor(166, device='cuda:0'), tensor(-1088.3890, device='cuda:0')),\n",
       "   (tensor(225, device='cuda:0'), tensor(1006.3676, device='cuda:0')),\n",
       "   (tensor(367, device='cuda:0'), tensor(-491.5223, device='cuda:0')),\n",
       "   (tensor(400, device='cuda:0'), tensor(302.8898, device='cuda:0')),\n",
       "   (tensor(584, device='cuda:0'), tensor(1104.7645, device='cuda:0')),\n",
       "   (tensor(600, device='cuda:0'), tensor(-789.7195, device='cuda:0')),\n",
       "   (tensor(694, device='cuda:0'), tensor(-803.2892, device='cuda:0'))],\n",
       "  [(tensor(53, device='cuda:0'), tensor(-1.5444, device='cuda:0')),\n",
       "   (tensor(181, device='cuda:0'), tensor(-0.3436, device='cuda:0')),\n",
       "   (tensor(208, device='cuda:0'), tensor(1.4901, device='cuda:0')),\n",
       "   (tensor(229, device='cuda:0'), tensor(0.2433, device='cuda:0')),\n",
       "   (tensor(249, device='cuda:0'), tensor(-0.5035, device='cuda:0')),\n",
       "   (tensor(321, device='cuda:0'), tensor(-0.6956, device='cuda:0')),\n",
       "   (tensor(347, device='cuda:0'), tensor(-1.3665, device='cuda:0')),\n",
       "   (tensor(460, device='cuda:0'), tensor(0.2380, device='cuda:0')),\n",
       "   (tensor(473, device='cuda:0'), tensor(-0.8623, device='cuda:0')),\n",
       "   (tensor(486, device='cuda:0'), tensor(-0.8323, device='cuda:0'))],\n",
       "  [(tensor(230, device='cuda:0'), tensor(311.4376, device='cuda:0')),\n",
       "   (tensor(309, device='cuda:0'), tensor(-273.8271, device='cuda:0')),\n",
       "   (tensor(337, device='cuda:0'), tensor(-162.6611, device='cuda:0')),\n",
       "   (tensor(395, device='cuda:0'), tensor(932.1395, device='cuda:0')),\n",
       "   (tensor(407, device='cuda:0'), tensor(-130.8276, device='cuda:0')),\n",
       "   (tensor(424, device='cuda:0'), tensor(-461.0716, device='cuda:0')),\n",
       "   (tensor(428, device='cuda:0'), tensor(181.7287, device='cuda:0')),\n",
       "   (tensor(478, device='cuda:0'), tensor(39.1145, device='cuda:0')),\n",
       "   (tensor(496, device='cuda:0'), tensor(701.0634, device='cuda:0')),\n",
       "   (tensor(509, device='cuda:0'), tensor(-632.3591, device='cuda:0'))],\n",
       "  [(tensor(59, device='cuda:0'), tensor(1.1152, device='cuda:0')),\n",
       "   (tensor(86, device='cuda:0'), tensor(-0.6356, device='cuda:0')),\n",
       "   (tensor(118, device='cuda:0'), tensor(1.4033, device='cuda:0')),\n",
       "   (tensor(142, device='cuda:0'), tensor(-0.5053, device='cuda:0')),\n",
       "   (tensor(264, device='cuda:0'), tensor(-1.6341, device='cuda:0')),\n",
       "   (tensor(287, device='cuda:0'), tensor(-1.2272, device='cuda:0')),\n",
       "   (tensor(292, device='cuda:0'), tensor(-2.0645, device='cuda:0')),\n",
       "   (tensor(347, device='cuda:0'), tensor(1.9835, device='cuda:0')),\n",
       "   (tensor(431, device='cuda:0'), tensor(-1.0096, device='cuda:0')),\n",
       "   (tensor(508, device='cuda:0'), tensor(-0.9370, device='cuda:0'))],\n",
       "  [(tensor(43, device='cuda:0'), tensor(1.3999, device='cuda:0')),\n",
       "   (tensor(47, device='cuda:0'), tensor(-9.9545, device='cuda:0')),\n",
       "   (tensor(73, device='cuda:0'), tensor(4.0121, device='cuda:0')),\n",
       "   (tensor(88, device='cuda:0'), tensor(17.2312, device='cuda:0')),\n",
       "   (tensor(188, device='cuda:0'), tensor(17.5654, device='cuda:0')),\n",
       "   (tensor(202, device='cuda:0'), tensor(-6.8004, device='cuda:0')),\n",
       "   (tensor(386, device='cuda:0'), tensor(2.8912, device='cuda:0')),\n",
       "   (tensor(409, device='cuda:0'), tensor(-18.7249, device='cuda:0')),\n",
       "   (tensor(413, device='cuda:0'), tensor(16.1302, device='cuda:0')),\n",
       "   (tensor(490, device='cuda:0'), tensor(0.0393, device='cuda:0'))],\n",
       "  [(tensor(0, device='cuda:0'), tensor(0.0031, device='cuda:0')),\n",
       "   (tensor(1, device='cuda:0'), tensor(0.0271, device='cuda:0')),\n",
       "   (tensor(2, device='cuda:0'), tensor(0.0032, device='cuda:0')),\n",
       "   (tensor(3, device='cuda:0'), tensor(-0.0225, device='cuda:0')),\n",
       "   (tensor(4, device='cuda:0'), tensor(-0.0016, device='cuda:0')),\n",
       "   (tensor(5, device='cuda:0'), tensor(-0.0012, device='cuda:0')),\n",
       "   (tensor(6, device='cuda:0'), tensor(-0.0440, device='cuda:0')),\n",
       "   (tensor(7, device='cuda:0'), tensor(-0.0105, device='cuda:0')),\n",
       "   (tensor(8, device='cuda:0'), tensor(-0.0177, device='cuda:0')),\n",
       "   (tensor(9, device='cuda:0'), tensor(0.0355, device='cuda:0'))]],\n",
       " [tensor(-4.9024e-05, device='cuda:0'),\n",
       "  tensor(-0.0013, device='cuda:0'),\n",
       "  tensor(5.9098e-05, device='cuda:0'),\n",
       "  tensor(-0.0022, device='cuda:0'),\n",
       "  tensor(-0.0003, device='cuda:0'),\n",
       "  tensor(-0.0029, device='cuda:0')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now have 5 different datasets, each with some sort of representation of the data that is unknown, ie, we have no \n",
    "# statistical information on the data that each of these clients would have\n",
    "# We now need to implement variations of the 3 protocols, namely, the encoding protocol, the communication protocol and the decoding protocol\n",
    "\n",
    "\n",
    "# Encoders\n",
    "def variable_size_encoder(grad_vectors, mu, p=0.1):\n",
    "    # Lets take p = 0.1\n",
    "    new_grad_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(grad_vectors)):\n",
    "            mask = torch.rand_like(grad_vectors[i], device=grad_vectors[i].device) < p\n",
    "            Y = torch.empty_like(grad_vectors[i], device=grad_vectors[i].device)\n",
    "            Y[mask] = (grad_vectors[i][mask] - mu[i] * (1-p))/p\n",
    "            Y[~mask] = mu[i]\n",
    "            new_grad_vectors.append(Y)\n",
    "    return new_grad_vectors\n",
    "\n",
    "def fixed_size_encoder(grad_vectors, mu, k=10):\n",
    "    # k can vary\n",
    "    new_grad_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(grad_vectors)):\n",
    "            shape = grad_vectors[i].shape\n",
    "            # Flattening the parameters to permutate over them\n",
    "            flat_grad = grad_vectors[i].view(-1)\n",
    "            C = shape[-1]\n",
    "            # Get the length of the flat_grad array\n",
    "            d = flat_grad.numel()\n",
    "            # Shuffle the list [1, 2, ... d] and get the first k elements\n",
    "            indices = torch.randperm(C, device=flat_grad.device)[:k]\n",
    "             \n",
    "            mask = torch.zeros(d, dtype=torch.bool, device=flat_grad.device)\n",
    "            mask[indices] = True\n",
    "            \n",
    "            Y = torch.empty_like(flat_grad)\n",
    "            # Encode the parameters\n",
    "            chosen_vals = (d/k)*flat_grad[mask] - ((d-k)/k)*mu[i]\n",
    "            Y[mask] = chosen_vals\n",
    "            Y[~mask] = mu[i]\n",
    "            Y = Y.view(shape)\n",
    "            new_grad_vectors.append(Y)\n",
    "    return new_grad_vectors\n",
    "            \n",
    "            \n",
    "# Decoders \n",
    "def averaging_decoder(grad_vectors_list):\n",
    "    if isinstance(grad_vectors_list, list):\n",
    "        grad_vectors_list = torch.stack(grad_vectors_list, dim=0)\n",
    "    return torch.mean(grad_vectors_list, dim=0)\n",
    "\n",
    "# Communication protocols\n",
    "def sparse_for_variable_size_encoder(encoded_vectors, mu):\n",
    "    final_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(encoded_vectors)):\n",
    "            flat_vector = encoded_vectors[i].view(-1)\n",
    "            mask = flat_vector != mu[i]\n",
    "            # vals = encoded_vectors[i][mask]\n",
    "            indices = torch.nonzero(mask, as_tuple=False).view(-1)\n",
    "            values = flat_vector[mask]\n",
    "            final_vectors.append(list(zip(indices, values)))\n",
    "\n",
    "    \n",
    "    return final_vectors, mu\n",
    "    \n",
    "def sparse_for_fixed_size_encoder(grad_vectors):\n",
    "    pass\n",
    "\n",
    "parameters = list(model.parameters())\n",
    "mu_1 = []\n",
    "with torch.no_grad():\n",
    "    for p in parameters:\n",
    "        mu_1.append(torch.mean(p))\n",
    "\n",
    "encoded_vectors = fixed_size_encoder(parameters, mu_1)\n",
    "sparse_for_variable_size_encoder(encoded_vectors, mu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3c6e93-87af-426a-8ad5-a81bcba62990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3333, 3.3333, 4.3333])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\n",
    "averaging_decoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "311d5661-e5fd-4efc-b2d9-f238953a7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 784])\n",
      "torch.Size([512, 784])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "parameters = list(model.parameters())\n",
    "variable_size_encoder(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c008223f-22d0-4b30-bf02-6ad83feccae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390563a7-8ac8-4947-8a2e-cbda1e90dd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
