{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7744187e-9a74-440b-95b8-557b723fc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import fastai \n",
    "from torchvision.transforms import ToTensor\n",
    "# from fastai.data.core import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.vision.all import Learner, Metric\n",
    "from fastai import optimizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5849ab-a4ca-4515-97b5-35c90615be8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 10.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 927kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 7.54MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.13MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c4d276-b524-46c7-b31a-8324a4b2b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([256, 1, 28, 28])\n",
      "Shape of y: torch.Size([256]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b180ad30-e4fe-4af6-9367-d3e5b03bc63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af6c2a9-8714-4c3f-bf16-44b3b964ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 5\n",
    "train_size = len(training_data)\n",
    "# indices = list(range(train_size))\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED)\n",
    "indices = torch.randperm(train_size).tolist()\n",
    "\n",
    "subset_size = train_size // num_clients\n",
    "client_subsets = [] \n",
    "for i in range(num_clients):\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = start_idx + subset_size\n",
    "\n",
    "    if i == num_clients - 1:\n",
    "        end_idx = train_size\n",
    "\n",
    "    subset_indices = indices[start_idx:end_idx]\n",
    "    client_subsets.append(Subset(training_data, subset_indices))\n",
    "\n",
    "client_loaders = [DataLoader(sub, batch_size=batch_size, shuffle=True) for sub in client_subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831d6af4-3ad3-4d67-8681-472ba8624385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits \n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ab18bf1-90d6-4bde-a5fc-3ebb2766e207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-4.9024e-05, -4.9024e-05, -4.9024e-05,  ..., -4.9024e-05,\n",
       "          -1.8604e-01, -4.9024e-05],\n",
       "         [-4.9024e-05, -4.9024e-05, -4.9024e-05,  ..., -4.9024e-05,\n",
       "          -4.9024e-05, -4.9024e-05],\n",
       "         [-4.9024e-05, -4.9024e-05, -4.9024e-05,  ..., -4.9024e-05,\n",
       "          -4.9024e-05, -4.9024e-05],\n",
       "         ...,\n",
       "         [-4.9024e-05, -4.9024e-05, -4.9024e-05,  ..., -4.9024e-05,\n",
       "          -4.9024e-05, -4.9024e-05],\n",
       "         [-4.9024e-05, -4.9024e-05, -4.9024e-05,  ..., -4.9024e-05,\n",
       "          -4.9024e-05, -4.9024e-05],\n",
       "         [-4.9024e-05, -4.9024e-05, -4.9024e-05,  ..., -4.9024e-05,\n",
       "           1.0015e-01, -4.9024e-05]], device='cuda:0'),\n",
       " tensor([-0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.0783, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.1686, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0219,  0.1379, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.1513, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.1527, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.3303, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013,  0.3547, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013,  0.2098, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.2496, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0326,\n",
       "         -0.0013, -0.0013, -0.0135, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.2171, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.2659, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0018, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.3079, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.2875, -0.0013, -0.0013, -0.2954, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013,  0.2409, -0.1836, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.2390,  0.1744, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.2752,\n",
       "         -0.0013, -0.0013, -0.0013,  0.0503, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.3438, -0.3334, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.1552, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.2331, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013,  0.1384, -0.0013, -0.0013, -0.0013, -0.0331, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.1498, -0.0013, -0.0013,\n",
       "          0.2463, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0942, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013,  0.0538, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.2694, -0.0013,  0.1023,\n",
       "         -0.0013, -0.0013, -0.0014, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.1533,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.2059, -0.0013, -0.1061,  0.0425, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.1863, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.2851, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.3335, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.1861, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0317, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.1665, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0203, -0.0013, -0.2053, -0.0485, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
       "         -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.2912],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 5.9098e-05,  3.8452e-01,  5.9098e-05,  ...,  5.9098e-05,\n",
       "           5.9098e-05,  5.9098e-05],\n",
       "         [-2.5616e-02,  5.9098e-05,  5.9098e-05,  ...,  5.9098e-05,\n",
       "           1.1264e-01,  5.9098e-05],\n",
       "         [ 5.9098e-05,  5.9098e-05,  5.9098e-05,  ..., -6.9161e-02,\n",
       "           5.9098e-05,  5.9098e-05],\n",
       "         ...,\n",
       "         [ 5.9098e-05,  5.9098e-05,  5.9098e-05,  ...,  5.9098e-05,\n",
       "           5.9098e-05,  5.9098e-05],\n",
       "         [ 5.9098e-05,  5.9098e-05,  8.6400e-02,  ...,  5.9098e-05,\n",
       "           3.9426e-01,  5.9098e-05],\n",
       "         [ 5.9098e-05,  5.9098e-05,  5.9098e-05,  ...,  5.9098e-05,\n",
       "           5.9098e-05, -2.1193e-01]], device='cuda:0'),\n",
       " tensor([-0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0375,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.1189, -0.0022,\n",
       "         -0.0022,  0.3169, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.4276,\n",
       "         -0.0022, -0.0022, -0.0022,  0.0908, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.4203,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.1082, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.1244, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.1957,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.1408,\n",
       "         -0.0022, -0.0022, -0.0022, -0.3184, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022,  0.1504, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "          0.2941, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022,  0.1668, -0.0022, -0.0022, -0.0022, -0.3558, -0.0022,\n",
       "         -0.0022,  0.1544, -0.0022, -0.0022,  0.0904, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.2535, -0.0022,  0.0962, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.3336, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022,  0.2782, -0.0022, -0.0022,  0.0115, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.2471, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022,  0.2811, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022,  0.4550, -0.0022, -0.0022, -0.2659,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.2658, -0.0022, -0.2145,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022,  0.1442, -0.0022, -0.0022, -0.0474, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.3993, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.0233, -0.0022,\n",
       "         -0.0022,  0.2606, -0.0116, -0.0022, -0.0022, -0.0022,  0.2524, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.3792, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.3608, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.1252, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.3620, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0064, -0.0022, -0.0022, -0.1925, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022,  0.1729, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022,  0.3655, -0.0022, -0.0022, -0.0022,  0.0362, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "          0.4100, -0.0022, -0.0022, -0.0022,  0.2791, -0.0022, -0.0022, -0.0022,\n",
       "         -0.1472, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022,  0.0838, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.1868, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022,  0.3415, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.2736, -0.0022,\n",
       "         -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.0904],\n",
       "        device='cuda:0'),\n",
       " tensor([[-3.2347e-04, -3.2347e-04, -3.2347e-04,  ..., -3.2347e-04,\n",
       "          -3.2347e-04, -3.2347e-04],\n",
       "         [-3.2347e-04, -3.2347e-04, -3.2347e-04,  ...,  4.3129e-01,\n",
       "          -3.2347e-04, -3.2347e-04],\n",
       "         [-3.2347e-04, -3.2347e-04, -3.2347e-04,  ..., -3.2347e-04,\n",
       "          -3.2347e-04, -3.2347e-04],\n",
       "         ...,\n",
       "         [-3.2347e-04, -3.2347e-04, -3.2347e-04,  ..., -3.2347e-04,\n",
       "          -3.2347e-04, -3.2347e-04],\n",
       "         [-3.2347e-04, -3.2347e-04, -3.2347e-04,  ..., -1.0763e-01,\n",
       "          -3.2347e-04, -3.2347e-04],\n",
       "         [-3.2347e-04, -3.2347e-04, -3.2347e-04,  ..., -3.2347e-04,\n",
       "          -3.2347e-04, -3.2347e-04]], device='cuda:0'),\n",
       " tensor([-0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029, -0.0029,\n",
       "         -0.0029, -0.0029], device='cuda:0')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now have 5 different datasets, each with some sort of representation of the data that is unknown, ie, we have no \n",
    "# statistical information on the data that each of these clients would have\n",
    "# We now need to implement variations of the 3 protocols, namely, the encoding protocol, the communication protocol and the decoding protocol\n",
    "\n",
    "\n",
    "# Encoders\n",
    "def variable_size_encoder(grad_vectors, mu, p=0.1):\n",
    "    # Lets take p = 0.1\n",
    "    new_grad_vectors = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(grad_vectors)):\n",
    "            mask = torch.rand_like(grad_vectors[i]) < p\n",
    "            Y = torch.empty_like(grad_vectors[i])\n",
    "            Y[mask] = (grad_vectors[i][mask] - mu[i] * (1-p))/p\n",
    "            Y[~mask] = mu[i]\n",
    "            new_grad_vectors.append(Y)\n",
    "    return new_grad_vectors\n",
    "\n",
    "def fixed_size_encoder(grad_vectors):\n",
    "    pass\n",
    "\n",
    "# Decoders \n",
    "def averaging_decoder(grad_vectors_list):\n",
    "    if isinstance(grad_vectors_list, list):\n",
    "        grad_vectors_list = torch.stack(grad_vectors_list, dim=0)\n",
    "    return torch.mean(grad_vectors_list, dim=0)\n",
    "\n",
    "# Communication protocols\n",
    "def sparse_for_variable_size_encoder(grad_vectors):\n",
    "    pass\n",
    "\n",
    "def sparse_for_fixed_size_encoder(grad_vectors):\n",
    "    pass\n",
    "\n",
    "parameters = list(model.parameters())\n",
    "mu_1 = []\n",
    "with torch.no_grad():\n",
    "    for p in parameters:\n",
    "        mu_1.append(torch.mean(p))\n",
    "\n",
    "variable_size_encoder(parameters, mu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3c6e93-87af-426a-8ad5-a81bcba62990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3333, 3.3333, 4.3333])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\n",
    "averaging_decoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "311d5661-e5fd-4efc-b2d9-f238953a7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 784])\n",
      "torch.Size([512, 784])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "parameters = list(model.parameters())\n",
    "variable_size_encoder(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c008223f-22d0-4b30-bf02-6ad83feccae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390563a7-8ac8-4947-8a2e-cbda1e90dd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
